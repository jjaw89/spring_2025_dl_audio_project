{"cells":[{"cell_type":"markdown","metadata":{"id":"4qxrWZHYxV36"},"source":["Here we train our first version of the GAN.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vARIOK_HxV36"},"source":["## Initialize Wave-U-Net\n","\n","We start by loading the necessary packages\n","\n","Wave-U-Net is named ``generator``"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_3vGK4LxV37","outputId":"5e6711f4-c3cd-4ad0-fa5d-6798d1f0e502","executionInfo":{"status":"ok","timestamp":1743777689254,"user_tz":420,"elapsed":42085,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sktime\n","  Downloading sktime-0.36.0-py3-none-any.whl.metadata (34 kB)\n","Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.4.2)\n","Requirement already satisfied: numpy<2.3,>=1.21 in /usr/local/lib/python3.11/dist-packages (from sktime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from sktime) (24.2)\n","Requirement already satisfied: pandas<2.3.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from sktime) (2.2.2)\n","Collecting scikit-base<0.13.0,>=0.6.1 (from sktime)\n","  Downloading scikit_base-0.12.2-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: scikit-learn<1.7.0,>=0.24 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.6.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from sktime) (1.14.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=0.24->sktime) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime) (1.17.0)\n","Downloading sktime-0.36.0-py3-none-any.whl (36.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_base-0.12.2-py3-none-any.whl (142 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-base, sktime\n","Successfully installed scikit-base-0.12.2 sktime-0.36.0\n","Mounted at /content/drive\n","/content/drive/My Drive/git_projects/spring_2025_dl_audio_project\n","GPU: False\n"]}],"source":["# Import same packages as the train script in Wave-U-Net-Pytorch\n","import argparse\n","import os\n","import time\n","from functools import partial\n","\n","import torch\n","import pickle\n","import numpy as np\n","\n","import torch.nn as nn\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.optim import Adam\n","from torch.nn import L1Loss\n","from tqdm import tqdm\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","# install torchaudio if not already installed\n","# ! pip install torchaudio\n","import torchaudio\n","\n","import matplotlib.pyplot as plt\n","from typing import Tuple, List, Dict, Optional\n","\n","!pip install sktime\n","from sktime.transformations.panel.rocket import MiniRocketMultivariate\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/git_projects/spring_2025_dl_audio_project\n","\n","\n","# add a path to Wave-U-Net\n","import sys\n","sys.path.append('Wave-U-Net-Pytorch')\n","\n","import model.utils as model_utils\n","import utils\n","from model.waveunet import Waveunet\n","\n","# Check to see if we have a GPU available\n","print(\"GPU:\", torch.cuda.is_available())"]},{"cell_type":"code","source":["# I run these commands in the terminal that you get when you pay for Colab.\n","\n","# %pip install musdb  # has some helpful data structures, also installs ffmpeg and stempeg\n","# %pip uninstall stempeg    # musdb installs the wrong version of stempeg'"],"metadata":{"id":"yfjgCEsl31aK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rok6FpDgxV37"},"source":["We define the parameters of the model."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"H755Zr5RxV37","executionInfo":{"status":"ok","timestamp":1743777975402,"user_tz":420,"elapsed":12,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[],"source":["model_config = {\n","    \"num_inputs\": 256,               # 128 mel bins per spectrogram, but we have to spectrograms\n","    \"num_outputs\": 128,              # Output also has 128 mel bins\n","    \"num_channels\": [32*2, 32*4, 32*8],    # Example channel progression\n","    \"instruments\": [\"vocal\"],        # Only output vocal, so no music branch\n","    \"kernel_size\": 3,                # Must be odd\n","    \"target_output_size\": 256,       # Desired output time frames (post-processing may crop)\n","    \"conv_type\": \"normal\",           # Set to \"normal\" to meet assertion requirements\n","    \"res\": \"fixed\",                  # Use fixed resampling\n","    \"separate\": False,                # Separate branch for vocal\n","    \"depth\": 1,                      # Number of conv layers per block\n","    \"strides\": 2                   # Down/up-sampling stride\n","}"]},{"cell_type":"markdown","metadata":{"id":"dFFCD4BRxV38"},"source":["Load the model, check how much GPU memory it will use during training, and print a summary of the model."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"wCkCtLVZxV38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743778315324,"user_tz":420,"elapsed":20,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}},"outputId":"f4f55b92-f72a-493a-910f-45babbd364dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using valid convolutions with 289 inputs and 257 outputs\n"]}],"source":["# Ensure that you have a CUDA-enabled device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instantiate and move the model to GPU\n","generator = Waveunet(**model_config).to(device)\n","\n","# # Set up a dummy optimizer and loss function\n","# optimizer = Adam(generator.parameters(), lr=1e-3)\n","# loss_fn = L1Loss()\n","\n","# # Define a dummy batch size\n","# batch_size = 256\n","\n","# # Create a dummy input tensor with the required shape\n","# # model.num_inputs corresponds to the number of channels (256 in your config)\n","# # model.input_size is the computed length (353, for instance)\n","# dummy_input = torch.randn(batch_size, generator.num_inputs, generator.input_size, device=device)\n","\n","# # Create a dummy target tensor with the shape that your model outputs.\n","# # For a single output branch (vocal), the output shape should be:\n","# # (batch_size, num_outputs, model.output_size)\n","# # model.num_outputs is 128 and model.output_size is computed (257 in your case)\n","# dummy_target = torch.randn(batch_size, generator.num_outputs, generator.output_size, device=device)\n","\n","# # Reset GPU peak memory stats\n","# torch.cuda.reset_peak_memory_stats(device)\n","\n","# # Run a single forward and backward pass\n","# optimizer.zero_grad()\n","# # If separate is False, the model returns a dictionary; pass the correct key.\n","# output = generator(dummy_input)[\"vocal\"]\n","# loss = loss_fn(output, dummy_target)\n","# loss.backward()\n","# optimizer.step()\n","\n","# # Retrieve GPU memory stats\n","# peak_memory = torch.cuda.max_memory_allocated(device)\n","# current_memory = torch.cuda.memory_allocated(device)\n","# print(\"Peak GPU memory allocated (bytes):\", peak_memory)\n","# print(\"Current GPU memory allocated (bytes):\", current_memory)\n","\n","# # Optionally, print a detailed memory summary\n","# print(torch.cuda.memory_summary(device=device))\n","\n","\n","# summary(generator, input_size=(generator.num_inputs,  generator.input_size))\n"]},{"cell_type":"markdown","metadata":{"id":"J3urQe1yxV38"},"source":["Optionally compile the model to potentially decrease training time."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7srOJSNJxV38","executionInfo":{"status":"ok","timestamp":1743777977819,"user_tz":420,"elapsed":12,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Txk2TxUixV38"},"source":["If we compile the model, to save it after training, we have to uncompile it using the following code:\n","\n","```python\n","orig_generator = generator._orig_mod\n","path = \"\"\n","torch.save(orig_generator.state_dict(), path + \"generator_state_dict.pt\")\n"]},{"cell_type":"markdown","metadata":{"id":"mjCddsoTxV39"},"source":["## Initialize miniRocket\n","We start by loading the necessary packages"]},{"cell_type":"markdown","metadata":{"id":"Hg5T7Os6xV39"},"source":["### CPU Core Allocation for MiniRocketMultivariate\n","\n","- The implementation of `MiniRocketMultivariate` runs on the **CPU**.\n","- We need to decide how many cores to allocate for it.\n","- Some cores will be used by MiniRocket itself, while others are needed for data preparation (e.g., generating spectrograms).\n","- This allocation likely needs to be **tuned for optimal performance**.\n","- As a starting point, we detect the number of available cores and split them evenly.\n","- Note: We avoid using *all* available cores to leave some resources for the operating system and other background processes.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"XwscObQrxV39","colab":{"base_uri":"https://localhost:8080/"},"outputId":"35b44288-d2e5-4114-80b6-1c97440be6a3","executionInfo":{"status":"ok","timestamp":1743777978911,"user_tz":420,"elapsed":9,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["8\n"]}],"source":["import multiprocessing\n","num_cores = multiprocessing.cpu_count()\n","print(num_cores)\n","minirocket_n_jobs = num_cores // 2 - 1\n","dataloader_n_jobs = num_cores - minirocket_n_jobs - 1"]},{"cell_type":"markdown","metadata":{"id":"X6ZXiPhWxV39"},"source":["Create the MiniRocket model"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"NhG7_-VlxV39","executionInfo":{"status":"ok","timestamp":1743781359104,"user_tz":420,"elapsed":13,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[],"source":["\n","# MiniRocket Discriminator using tsai library\n","class TsaiMiniRocketDiscriminator(nn.Module):\n","    def __init__(\n","        self,\n","        freq_bins=256,\n","        time_frames=256,\n","        num_kernels=10000,  # number of convolutional kernels\n","        hidden_dim=1024,    # Increased to handle larger feature dimension\n","        output_dim=1\n","    ):\n","        super(TsaiMiniRocketDiscriminator, self).__init__()\n","\n","        # This is the mini rocket transformer which extracts features\n","        self.rocket = MiniRocketMultivariate(num_kernels=num_kernels, n_jobs=minirocket_n_jobs)\n","        # tsai's miniRocketClassifier is implemented with MiniRocketMultivariate as well\n","        self.fitted = False   # fit before training\n","        self.freq_bins = freq_bins\n","        self.time_frames = time_frames\n","        self.num_kernels = num_kernels\n","\n","        # For 2D data handling - process each sample with proper dimensions\n","        self.example_input = np.zeros((1, freq_bins, time_frames))\n","\n","        feature_dim = num_kernels * 2  # For vocals + accompaniment\n","\n","        # Example feature reducing layers\n","        self.classifier = nn.Sequential(\n","            # First reduce the massive dimension to something manageable\n","            nn.Linear(feature_dim, hidden_dim),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3),\n","\n","            # Second hidden layer\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3),\n","\n","            # Final classification layer\n","            nn.Linear(hidden_dim // 2, output_dim),\n","            nn.Sigmoid()\n","        )\n","\n","    def fit_rocket(self, spectrograms):\n","        \"\"\"\n","            Fit MiniRocket with just one piece of vocal training data (not the entire training dataset)\n","        \"\"\"\n","        if not self.fitted:\n","            try:\n","                # Reshape for MiniRocket - it expects (n_instances, n_dimensions, series_length)\n","                # flatten the freq_bins dimension to create a multivariate time series\n","                batch_size = spectrograms.shape[0]\n","\n","                # Convert first to numpy for sktime processing\n","                sample_data = spectrograms.detach().cpu().numpy()\n","\n","                # Reshape to sktime's expected format - reduce to single sample for fitting\n","                sample_data = sample_data[:, 0]  # Take one sample, remove channel dim\n","\n","                # Fit on this sample\n","                self.rocket.fit(sample_data)\n","                self.fitted = True\n","\n","                # Test transform to get feature dimension\n","                test_transform = self.rocket.transform(sample_data)\n","                self.feature_dim = test_transform.shape[1]\n","\n","                print(f\"MiniRocket fitted. Feature dimension: {self.feature_dim}\")\n","\n","            except Exception as e:\n","                print(f\"Error fitting MiniRocket: {e}\")\n","                # Use a fallback if fitting fails\n","                self.fitted = True  # Mark as fitted to avoid repeated attempts\n","\n","    def extract_features(self, spectrogram):\n","        \"\"\"Extract MiniRocket features from a spectrogram\"\"\"\n","        try:\n","            # Ensure rocket is fitted\n","            if not self.fitted:\n","                self.fit_rocket(spectrogram)\n","\n","            # Convert to numpy for sktime\n","            spec_np = spectrogram.detach().cpu().numpy()\n","\n","            # Remove channel dimension expected by sktime\n","            spec_np = spec_np[:, 0]  # [batch_size, freq_bins, time_frames]\n","\n","            # This step extracts features using the convolutional kernels, numbers specified by num_kernels\n","            features = self.rocket.transform(spec_np)\n","\n","            # Convert back to torch tensor\n","            features = torch.tensor(features, dtype=torch.float32).to(spectrogram.device)\n","\n","            return features\n","\n","        except Exception as e:\n","            print(f\"Error in feature extraction: {e}\")\n","            # Return zeros as fallback\n","            return torch.zeros((spectrogram.shape[0], self.num_kernels),\n","                              device=spectrogram.device)\n","\n","    def forward(self, vocals, accompaniment):\n","        \"\"\"\n","        Forward pass of the discriminator\n","\n","        Args:\n","            vocals: Spectrograms of shape [batch_size, channels, freq_bins, time_frames]\n","            accompaniment: Spectrograms of shape [batch_size, channels, freq_bins, time_frames]\n","        \"\"\"\n","        # Extract features from both spectrograms\n","        vocal_features = self.extract_features(vocals)\n","        accomp_features = self.extract_features(accompaniment)\n","\n","        # Concatenate features (conditional GAN)\n","        combined_features = torch.cat([vocal_features, accomp_features], dim=1)\n","\n","        # Classify as real/fake\n","        validity = self.classifier(combined_features)\n","\n","        return validity\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"b6ACeYdNxV39","executionInfo":{"status":"ok","timestamp":1743777979785,"user_tz":420,"elapsed":178,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[],"source":["discriminator = TsaiMiniRocketDiscriminator()\n","# We probably do not need to compile the model"]},{"cell_type":"markdown","source":["# Import Data into Session\n","\n","First, we run the code that defines the custom Dataset objects. The Datasets were compiled previously and saved in .pt files. In the next cell, we load those Dataset objects."],"metadata":{"id":"YEaNx9F0Hnwa"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"bpu-Q2zGxV39","executionInfo":{"status":"ok","timestamp":1743777980122,"user_tz":420,"elapsed":22,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[],"source":["class MusdbDataset(Dataset):\n","\n","  def __init__(self, musDB, steps = 256):\n","    self.mel_specs = torch.zeros(1, 2, 128, steps)\n","    self.sample_rates = torch.tensor([0])\n","\n","    print(\"Tracks in MusDB:\", len(musDB))\n","\n","    for track in musDB:\n","      stems, rate = track.stems, track.rate\n","\n","      # separate the vocal from other instruments and conver to mono signal\n","      audio_novocal = librosa.to_mono(np.transpose(stems[1] + stems[2] + stems[3]))\n","      audio_vocal = librosa.to_mono(np.transpose(stems[4]))\n","\n","      # compute log mel spectrogram and convert to pytorch tensor\n","      logmelspec_novocal = torch.from_numpy(self._mel_spectrogram(audio_novocal, rate))\n","      logmelspec_vocal = torch.from_numpy(self._mel_spectrogram(audio_vocal, rate))\n","\n","      num_slices = logmelspec_novocal.shape[1] // steps\n","\n","      # chop off the last bit so that number of stft steps is a multiple of step size\n","      logmelspec_novocal = logmelspec_novocal[0:128 , 0:num_slices*steps]\n","      logmelspec_vocal = logmelspec_vocal[0:128, 0:num_slices*steps]\n","\n","      logmelspec_novocal = torch.reshape(logmelspec_novocal, (num_slices, 128, steps))\n","      logmelspec_vocal = torch.reshape(logmelspec_vocal, (num_slices, 128, steps))\n","\n","      # unsqueeze and concatenate these tensors. Then concatenate to the big tensor\n","      logmels = torch.cat((logmelspec_novocal.unsqueeze(1), logmelspec_vocal.unsqueeze(1)), 1)\n","      self.mel_specs = torch.cat((self.mel_specs, logmels), 0)\n","      self.sample_rates = torch.cat((self.sample_rates, torch.Tensor([rate])), 0)\n","\n","    # remove the all zeros slice that we initialized with\n","    self.mel_specs = self.mel_specs[1: , : , : , :]\n","    self.sample_rates = self.sample_rates[1:]\n","\n","  def __len__(self):\n","    return self.mel_specs.shape[0]\n","\n","  def __getitem__(self, ndx):\n","    # returns tuple (mel spectrogram of accompaniment, mel spectrogram of vocal, rate)\n","    return self.mel_specs[ndx, 0], self.mel_specs[ndx, 1], self.sample_rates[ndx]\n","\n","  def _mel_spectrogram(self, audio, rate):\n","    # compute the log-mel-spectrogram of the audio at the given sample rate\n","    return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))\n","\n","\n","class LibriSpeechDataset(Dataset):\n","\n","  def __init__(self, path, steps = 256, num_specs = 7647):\n","    self.mel_specs = self.mel_specs = torch.zeros(1, 128, steps)\n","    self.sample_rates = torch.tensor([0])\n","\n","    num_files_opened = 0\n","\n","    for speaker_dir in os.listdir(path):\n","      speaker_path = path + \"/\" + speaker_dir\n","      for chapter_dir in os.listdir(speaker_path):\n","        chapter_path = speaker_path + \"/\" + chapter_dir\n","        for file in os.listdir(chapter_path):\n","          # checks file extension and stops when we hit desired number of spectrograms (num_specs)\n","          if file.endswith('.flac') and self.mel_specs.shape[0] - 1 < num_specs:\n","\n","            try:\n","              # get audio file and convert to log mel spectrogram\n","              speech, rate = librosa.load(chapter_path + \"/\" + file, sr = 44100)\n","              mel_spec = torch.from_numpy(self._mel_spectrogram(speech, rate))\n","\n","              # Saves the total number of 128 x (steps) spectrograms\n","              num_slices = mel_spec.shape[1] // steps\n","\n","              # chop off the last bit so that number of stft steps is a multiple of step size\n","              mel_spec = mel_spec[ : , 0 : num_slices*steps]\n","\n","              # reshape the tensor to have many spectrograms of size 128 x (steps)\n","              mel_spec = torch.transpose(torch.reshape(mel_spec, (128, num_slices, steps)), 0, 1)\n","\n","              # concatenate tensor to the full tensor in the Dataset object\n","              self.mel_specs = torch.cat((self.mel_specs, mel_spec), 0)\n","              self.sample_rates = torch.cat((self.sample_rates, torch.Tensor([rate])), 0)\n","              num_files_opened += 1\n","\n","            except:\n","              print(\"failed to open \" + file)\n","\n","\n","    # chop off the zero layer we initialized with\n","    self.mel_specs = self.mel_specs[1:]\n","    self.sample_rates = self.sample_rates[1:]\n","    print(\"opened \" + str(num_files_opened) + \" files\")\n","    print(\"collected \" + str(self.mel_specs.shape[0]) + \" chunks\")\n","\n","  def __len__(self):\n","    return self.mel_specs.shape[0]\n","\n","  def __getitem__(self, ndx):\n","    return self.mel_specs[ndx], self.sample_rates[ndx]\n","\n","  def _mel_spectrogram(self, audio, rate):\n","    # compute the log-mel-spectrogram of the audio at the given sample rate\n","    return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))"]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/\"\n","\n","# The string below is the path to the saved MusdbDataset in your Drive\n","musdbDataset_path = path + \"musdb18_DatasetObject.pt\"\n","\n","# The string below is the path to the saved LibriSpeechDataset in your Drive\n","librispeechDataset_path = path + \"LibriSpeechDatasetObject.pt\"\n","\n","musdb_dataset = torch.load(musdbDataset_path, weights_only=False)\n","librispeech_dataset = torch.load(librispeechDataset_path, weights_only=False)\n","\n","\n"],"metadata":{"id":"JHlmMGgzGqb-","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1743778064893,"user_tz":420,"elapsed":84593,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}},"outputId":"ed1e9f8a-2b3b-412c-b9f6-1e6d8052ad49"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'musdb' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-bc946628f727>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# This fixes the problem with the sample rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmusdb_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mlibrispeech_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'musdb' is not defined"]}]},{"cell_type":"code","source":["# This fixes the problem with the sample rates\n","musdb_dataset.sample_rates = torch.full((len(musdb_dataset),), 44100)\n","librispeech_dataset.sample_rates = torch.full((len(musdb_dataset),), 44100)\n","\n","# Because of the way the librispeech dataset was constructed, it is slightly longer\n","# than the musbd dataset. Crop the librispeech dataset with these lines\n","librispeech_dataset.mel_specs = librispeech_dataset.mel_specs[0:len(musdb_dataset)]\n","librispeech_dataset.sample_rates = librispeech_dataset.sample_rates[0:len(musdb_dataset)]"],"metadata":{"id":"DUHwFy2jR2JY","executionInfo":{"status":"ok","timestamp":1743778179430,"user_tz":420,"elapsed":25,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Explore these datasets"],"metadata":{"id":"Peiksp9NuMGX"}},{"cell_type":"code","source":["# --- Explore the Datasets ---\n","print(\"=== MusDB Dataset Exploration ===\")\n","print(\"Length:\", len(musdb_dataset))\n","print(\"mel_specs shape:\", musdb_dataset.mel_specs.shape)\n","print(\"sample_rates shape:\", musdb_dataset.sample_rates.shape)\n","print()\n","accompaniment, vocal, sample_rate = musdb_dataset[0]\n","print(\"Sample 0 - Accompaniment shape:\", accompaniment.size())\n","print(\"Sample 0 - Vocal shape:\", vocal.size())\n","print(\"Sample 0 - Sample rate:\", sample_rate)\n","print()\n","\n","print(\"=== LibriSpeech Dataset Exploration ===\")\n","print(\"Length:\", len(librispeech_dataset))\n","print(\"mel_specs shape:\", librispeech_dataset.mel_specs.shape)\n","print(\"sample_rates shape:\", librispeech_dataset.sample_rates.shape)\n","print()\n","speech, sample_rate = librispeech_dataset[0]\n","print(\"Sample 0 - Speech shape:\", speech.size())\n","print(\"Sample 0 - Sample rate:\", sample_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpREtcq0mYd8","outputId":"66c52112-780a-44fa-8ba8-fd186bfb1585","executionInfo":{"status":"ok","timestamp":1743778215207,"user_tz":420,"elapsed":13,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["=== MusDB Dataset Exploration ===\n","Length: 7647\n","mel_specs shape: torch.Size([7647, 2, 128, 256])\n","sample_rates shape: torch.Size([7647])\n","\n","Sample 0 - Accompaniment shape: torch.Size([128, 256])\n","Sample 0 - Vocal shape: torch.Size([128, 256])\n","Sample 0 - Sample rate: tensor(44100)\n","\n","=== LibriSpeech Dataset Exploration ===\n","Length: 7647\n","mel_specs shape: torch.Size([7647, 128, 256])\n","sample_rates shape: torch.Size([7647])\n","\n","Sample 0 - Speech shape: torch.Size([128, 256])\n","Sample 0 - Sample rate: tensor(44100)\n"]}]},{"cell_type":"markdown","source":["## Dataset Helpers Explanation\n","Why New Dataset Helpers?\n","\n","We have created new dataset helper classes (i.e., AccompanimentData, VocalData, and SpeechData) so that we can control how the data is padded and later shuffled.\n","\n","- **Separation of Data:**\n","We separated the vocal and accompaniment data from the MusDB dataset. In our experiments, we might want to shuffle the speech data independently of the combined music data.\n","\n","- **Shuffling Considerations:**\n","For the vocal and accompaniment data, we want to maintain their pairing so that they are shuffled in the same order. In contrast, we want the speech data to be shuffled independently.\n","\n","- **Future Extensions:**\n","In the future, we may add another helper class that combines the vocal and accompaniment data to ensure synchronized shuffling in our data loaders.\n","\n","This modular approach gives us flexibility in handling and preprocessing the data for our GAN training."],"metadata":{"id":"OK8WbDmTjkNH"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","class AccompanimentData(Dataset):\n","    def __init__(self, musdb_dataset, output_length=289):\n","        self.musdb_dataset = musdb_dataset\n","        self.output_length = output_length\n","\n","    def __len__(self):\n","        return len(self.musdb_dataset)\n","\n","    def __getitem__(self, index):\n","        accompaniment, _, _ = self.musdb_dataset[index]  # shape: [128, 256]\n","        current_len = accompaniment.size(-1)             # 256\n","        delta = self.output_length - current_len         # 289 - 256 = 33\n","\n","        # If delta is positive, pad. Otherwise, you might want to crop or handle differently.\n","        if delta > 0:\n","            # Half the remainder goes to the front\n","            left_pad_len = (delta // 2) + (delta % 2)  # 17\n","            right_pad_len = delta // 2                # 16\n","            accompaniment_pad = F.pad(accompaniment,\n","                                  (left_pad_len, right_pad_len),\n","                                  \"constant\", 0)\n","        return {\"no_pad\" : accompaniment, \"pad\" : accompaniment_pad}\n","\n","\n","class VocalData(Dataset):\n","    def __init__(self, musdb_dataset, output_length=289):\n","        self.musdb_dataset = musdb_dataset\n","        self.output_length = output_length\n","\n","    def __len__(self):\n","        return len(self.musdb_dataset)\n","\n","    def __getitem__(self, index):\n","        _, vocal, _ = self.musdb_dataset[index]  # shape: [128, 256]\n","        current_len = vocal.size(-1)\n","        delta = self.output_length - current_len\n","\n","        if delta > 0:\n","            left_pad_len = (delta // 2) + (delta % 2)\n","            right_pad_len = delta // 2\n","            vocal_pad = F.pad(vocal, (left_pad_len, right_pad_len), \"constant\", 0)\n","        return {\"no_pad\" : vocal, \"pad\" : vocal_pad}\n","\n","\n","\n","class SpeechData(Dataset):\n","    def __init__(self, librispeech_dataset, output_length=289):\n","        self.librispeech_dataset = librispeech_dataset\n","        self.output_length = output_length\n","\n","    def __len__(self):\n","        return len(self.librispeech_dataset)\n","\n","    def __getitem__(self, index):\n","        speech, _ = self.librispeech_dataset[index]\n","        # If speech has multiple slices, pick the first slice\n","        if speech.dim() == 3:\n","            speech = speech[0]  # shape: [128, 256]\n","        current_len = speech.size(-1)\n","        delta = self.output_length - current_len\n","\n","        if delta > 0:\n","            left_pad_len = (delta // 2) + (delta % 2)\n","            right_pad_len = delta // 2\n","            speech_pad = F.pad(speech, (left_pad_len, right_pad_len), \"constant\", 0)\n","        return {\"no_pad\" : speech, \"pad\" : speech_pad}\n"],"metadata":{"id":"O7OGNnS8XMVd","executionInfo":{"status":"ok","timestamp":1743780243660,"user_tz":420,"elapsed":5,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# print(AccompanimentData(musdb_dataset)[0])\n","# print(VocalData(musdb_dataset)[0])\n","# print(SpeechData(librispeech_dataset)[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gW1Twbo8lWY0","outputId":"1e330051-a3b8-4752-b1c7-c46e486b7f66","executionInfo":{"status":"ok","timestamp":1743780244455,"user_tz":420,"elapsed":13,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["{'no_pad': tensor([[-19.2006, -20.1596, -18.4185,  ...,   4.8409,   5.8388,   5.0587],\n","        [-14.1719, -16.2701, -11.7729,  ...,  23.1452,  22.4078,  22.8359],\n","        [-11.4245, -10.2783, -11.2832,  ...,  26.5597,  26.6617,  26.2935],\n","        ...,\n","        [-51.2818, -51.2818, -51.2818,  ..., -51.2818, -51.2818, -51.2818],\n","        [-51.2818, -51.2818, -51.2818,  ..., -51.2818, -51.2818, -51.2818],\n","        [-51.2818, -51.2818, -51.2818,  ..., -51.2818, -51.2818, -51.2818]],\n","       dtype=torch.float64), 'pad': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)}\n","{'no_pad': tensor([[-21.4368, -25.1658, -25.9449,  ..., -27.2409, -25.9030, -24.8514],\n","        [-22.2802, -30.6110, -30.3607,  ..., -32.9396, -31.6368, -30.1405],\n","        [-20.0262, -28.0743, -39.1246,  ..., -37.4505, -41.4596, -39.0840],\n","        ...,\n","        [-57.1708, -57.1708, -57.1708,  ..., -57.1708, -57.1708, -57.1708],\n","        [-57.1708, -57.1708, -57.1708,  ..., -57.1708, -57.1708, -57.1708],\n","        [-57.1708, -57.1708, -57.1708,  ..., -57.1708, -57.1708, -57.1708]],\n","       dtype=torch.float64), 'pad': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)}\n","{'no_pad': tensor([[-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549],\n","        [-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549],\n","        [-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549],\n","        ...,\n","        [-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549],\n","        [-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549],\n","        [-46.7549, -46.7549, -46.7549,  ..., -46.7549, -46.7549, -46.7549]]), 'pad': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])}\n"]}]},{"cell_type":"markdown","source":["### DataLoader Explanation\n","What is a DataLoader and Why Do We Need It?\n","\n","A DataLoader in PyTorch is a utility that wraps a dataset and provides:\n","\n","- **Batching:** It divides your dataset into batches so that you can train your models with mini-batch gradient descent.\n","\n","- **Shuffling:** It shuffles the data at every epoch (if specified) to help reduce overfitting and ensure the model sees a diverse set of examples.\n","\n","- **Parallel Data Loading:** It can load data in parallel using multiple worker processes, speeding up training.\n","\n","In our case, we create separate DataLoaders for:\n","\n","- The accompaniment data (paired with vocals) from the MusDB dataset.\n","\n","- The vocal data (paired with accompaniment) from the MusDB dataset.\n","\n","- The speech data from the LibriSpeech dataset.\n","\n","This lets us shuffle the speech data independently, while keeping the vocal/accompaniment pairs synchronized during training."],"metadata":{"id":"suMDmB62yS_N"}},{"cell_type":"code","source":["# Define batch size\n","batch_size = 32  # Change as needed\n","\n","# Create data loaders\n","accompaniment_loader = DataLoader(\n","    AccompanimentData(musdb_dataset),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=True\n",")\n","vocal_loader = DataLoader(\n","    VocalData(musdb_dataset),\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=True\n",")\n","speech_loader = DataLoader(\n","    SpeechData(librispeech_dataset),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    drop_last=True\n",")\n","\n","# # Print how many batches each DataLoader contains\n","# print(\"Accompaniment loader length:\", len(accompaniment_loader))\n","# print(\"Vocal loader length:\", len(vocal_loader))\n","# print(\"Speech loader length:\", len(speech_loader))\n","\n","# # Optionally, fetch and print the shape of the first batch\n","# accompaniment_batch = next(iter(accompaniment_loader))\n","# vocal_batch = next(iter(vocal_loader))\n","# speech_batch = next(iter(speech_loader))\n","# print(accompaniment_batch[\"pad\"])\n","\n","# print(\"Accompaniment first batch shape:\", accompaniment_batch.shape)\n","# print(\"Vocal first batch shape:\", vocal_batch.shape)\n","# print(\"Speech first batch shape:\", speech_batch.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLcvcILSlW3C","outputId":"76358248-2bcb-4dd6-eab6-d86f64799a18","executionInfo":{"status":"ok","timestamp":1743780425577,"user_tz":420,"elapsed":10,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Accompaniment loader length: 238\n","Vocal loader length: 238\n","Speech loader length: 238\n","tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        ...,\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]],\n","\n","        [[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         ...,\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2jg9I_4qxV3-"},"source":["## Train the GAN\n","The models are ``generator`` and ``discriminator``.\n","\n","This code was generated by AI. Feel free to try running it to see if it's right. If you don't do it or don't want to, I will take over tomorrow and hopefully have the training loop done by our meeting."]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","def train_epoch(generator, discriminator, optimizer_D, optimizer_G, accompaniment_loader, vocal_loader, speech_loader, l1_loss, adversarial_loss, device):\n","\n","    train_loader = tqdm(enumerate(zip(zip(accompaniment_loader, vocal_loader), speech_loader)))\n","\n","    for batch_number, ((accompaniment, vocal), speech) in train_loader:\n","        # Move data to device and CAST TO FLOAT32\n","        accompaniment_pad_device = accompaniment[\"pad\"].type(torch.float32).to(device)  # [B, 128, 289]\n","        speech_pad_device = speech[\"pad\"].type(torch.float32).to(device)                # [B, 128, 289]\n","\n","        # Prepare generator input by concatenating speech and accompaniment along channel dimension.\n","        # Resulting shape: [B, 256, 289]\n","        generator_input = torch.cat([speech_pad_device, accompaniment_pad_device], dim=1)\n","\n","        # ---------------------\n","        # Train the Discriminator\n","        # ---------------------\n","        optimizer_D.zero_grad()\n","\n","        # Real labels (optionally with label smoothing)\n","        B = accompaniment_pad_device.size(0)\n","        real_labels = torch.full((B, 1), real_label_val, device=device)\n","        fake_labels = torch.zeros((B, 1), device=device)\n","\n","\n","        # Discriminator output for real pairs: (vocal, accompaniment)\n","        accompaniment_no_pad = accompaniment[\"no_pad\"]\n","        vocal_no_pad = vocal[\"no_pad\"].type(torch.float32).to(device)\n","        pred_real = discriminator(vocal_no_pad, accompaniment_no_pad)\n","        loss_D_real = adversarial_loss(pred_real, real_labels)\n","\n","        # Generate fake singing using the generator\n","        fake_singing = generator(generator_input)[\"vocal\"]\n","        fake_singing = fake_singing[:, :, :256]\n","        # print(\"vocal size:\", vocal.size())\n","        print(\"fake_singing size:\", fake_singing.size())\n","\n","        # Discriminator output for fake pairs: (generated singing, accompaniment)\n","\n","        pred_fake = discriminator(fake_singing, accompaniment_no_pad)\n","        loss_D_fake = adversarial_loss(pred_fake, fake_labels)\n","\n","        # Total discriminator loss and update\n","        loss_D = 0.5 * (loss_D_real + loss_D_fake)\n","        loss_D.backward()\n","        optimizer_D.step()\n","\n","        # ---------------------\n","        # Train the Generator\n","        # ---------------------\n","        optimizer_G.zero_grad()\n","\n","        # Generator wants the discriminator to output \"real\" for its fake singing.\n","        pred_fake_for_G = discriminator(fake_singing, accompaniment_no_pad)\n","        loss_G_adv = adversarial_loss(pred_fake_for_G, real_labels)\n","\n","        # Optionally add an L1 reconstruction loss to encourage generated singing to resemble the target vocal.\n","        lambda_l1 = 10  # Weight for L1 loss\n","        loss_G_L1 = l1_loss(fake_singing, vocal_no_pad)\n","\n","        loss_G = loss_G_adv + lambda_l1 * loss_G_L1\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","        # End of epoch logging\n","        train_loader.set_description(f\"Epoch [{epoch+1}/{num_epochs}]  Loss_D: {loss_D.item():.4f}  Loss_G: {loss_G.item():.4f}\")\n"],"metadata":{"id":"A_oMQsfWSlJX","executionInfo":{"status":"ok","timestamp":1743781597495,"user_tz":420,"elapsed":7,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = generator.to(device)\n","\n","# Optional\n","# generator = torch.compile(generator, mode='max-autotune')\n","\n","discriminator = discriminator.to(device)\n","\n","# Loss functions: Adversarial (BCE) and reconstruction (L1)\n","adversarial_loss = nn.BCELoss().to(device)\n","l1_loss = nn.L1Loss().to(device)\n","\n","# Optimizers for generator and discriminator\n","optimizer_G = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n","\n","# Number of training epochs\n","num_epochs = 1\n","\n","train_epoch(generator, discriminator, optimizer_D, optimizer_G, accompaniment_loader, vocal_loader, speech_loader, l1_loss, adversarial_loss, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IrrtFAj8Tjlv","executionInfo":{"status":"error","timestamp":1743781632126,"user_tz":420,"elapsed":32236,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}},"outputId":"0b071108-7a18-44c9-dc2f-61e96aab416b"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6889  Loss_G: 190.1571: : 1it [00:00,  2.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6889  Loss_G: 250.0746: : 2it [00:00,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6886  Loss_G: 172.4284: : 3it [00:00,  3.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6888  Loss_G: 208.0072: : 4it [00:01,  3.39it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6889  Loss_G: 205.1357: : 5it [00:01,  3.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 168.1909: : 6it [00:01,  3.59it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6892  Loss_G: 174.3576: : 7it [00:02,  3.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6888  Loss_G: 206.6407: : 8it [00:02,  3.68it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6892  Loss_G: 205.7072: : 9it [00:02,  3.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 161.8577: : 10it [00:02,  3.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6890  Loss_G: 158.7676: : 11it [00:03,  3.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6879  Loss_G: 153.7092: : 12it [00:03,  3.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 172.6737: : 13it [00:03,  3.72it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6881  Loss_G: 210.7114: : 14it [00:03,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6879  Loss_G: 161.2142: : 15it [00:04,  3.58it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6889  Loss_G: 269.5918: : 16it [00:04,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 202.1201: : 17it [00:04,  3.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6892  Loss_G: 204.1390: : 18it [00:05,  3.48it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6888  Loss_G: 225.0156: : 19it [00:05,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 234.8763: : 20it [00:05,  3.57it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6873  Loss_G: 245.8013: : 21it [00:05,  3.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6872  Loss_G: 203.0072: : 22it [00:06,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 180.0224: : 23it [00:06,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6873  Loss_G: 201.5632: : 24it [00:06,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6894  Loss_G: 174.4101: : 25it [00:07,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6890  Loss_G: 207.6495: : 26it [00:07,  3.58it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 192.9014: : 27it [00:07,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6874  Loss_G: 189.7421: : 28it [00:07,  3.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 171.0073: : 29it [00:08,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 171.4473: : 30it [00:08,  3.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 162.4492: : 31it [00:08,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 177.6729: : 32it [00:08,  3.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6893  Loss_G: 227.0113: : 33it [00:09,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6869  Loss_G: 184.1888: : 34it [00:09,  3.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6881  Loss_G: 167.5222: : 35it [00:09,  3.68it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6891  Loss_G: 173.3778: : 36it [00:10,  3.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6872  Loss_G: 197.7221: : 37it [00:10,  3.58it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6893  Loss_G: 183.6906: : 38it [00:10,  3.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 181.4870: : 39it [00:11,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 182.6356: : 40it [00:11,  2.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 198.3099: : 41it [00:11,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6882  Loss_G: 202.7299: : 42it [00:12,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6893  Loss_G: 166.4151: : 43it [00:12,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 217.9507: : 44it [00:12,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6877  Loss_G: 208.9196: : 45it [00:13,  3.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6889  Loss_G: 194.8687: : 46it [00:13,  3.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 160.0144: : 47it [00:13,  3.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 175.7107: : 48it [00:13,  3.29it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6879  Loss_G: 164.1581: : 49it [00:14,  3.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6877  Loss_G: 156.3253: : 50it [00:14,  3.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6893  Loss_G: 150.6191: : 51it [00:14,  3.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 149.9783: : 52it [00:15,  3.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 148.4826: : 53it [00:15,  3.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 171.8401: : 54it [00:15,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 169.9238: : 55it [00:16,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6873  Loss_G: 204.5205: : 56it [00:16,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6873  Loss_G: 207.5944: : 57it [00:16,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 212.1209: : 58it [00:17,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 188.0265: : 59it [00:17,  3.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6868  Loss_G: 171.9617: : 60it [00:17,  3.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6868  Loss_G: 215.6146: : 61it [00:18,  3.30it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6874  Loss_G: 169.8250: : 62it [00:18,  3.29it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 183.1376: : 63it [00:18,  3.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6874  Loss_G: 162.1790: : 64it [00:18,  3.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 142.8225: : 65it [00:19,  3.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 142.1416: : 66it [00:19,  3.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6867  Loss_G: 136.6762: : 67it [00:19,  3.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6881  Loss_G: 147.7481: : 68it [00:20,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6891  Loss_G: 134.9851: : 69it [00:20,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6876  Loss_G: 148.4333: : 70it [00:20,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6895  Loss_G: 150.3840: : 71it [00:21,  3.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 121.5381: : 72it [00:21,  3.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6869  Loss_G: 131.0863: : 73it [00:21,  3.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6896  Loss_G: 153.3027: : 74it [00:22,  3.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6876  Loss_G: 151.5093: : 75it [00:22,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6882  Loss_G: 151.2416: : 76it [00:22,  2.73it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 169.0556: : 77it [00:23,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6881  Loss_G: 166.9658: : 78it [00:23,  2.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6874  Loss_G: 143.2092: : 79it [00:24,  2.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 171.2523: : 80it [00:24,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 132.9766: : 81it [00:24,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 181.1809: : 82it [00:24,  3.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6880  Loss_G: 167.4312: : 83it [00:25,  3.35it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6887  Loss_G: 152.5140: : 84it [00:25,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6879  Loss_G: 176.8249: : 85it [00:25,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6890  Loss_G: 236.7268: : 86it [00:26,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 162.0967: : 87it [00:26,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6885  Loss_G: 156.6703: : 88it [00:26,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6872  Loss_G: 130.4019: : 89it [00:26,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6881  Loss_G: 139.1420: : 90it [00:27,  3.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 196.1373: : 91it [00:27,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6901  Loss_G: 228.8698: : 92it [00:27,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6886  Loss_G: 202.9500: : 93it [00:28,  3.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6877  Loss_G: 145.3206: : 94it [00:28,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6877  Loss_G: 138.7930: : 95it [00:28,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6886  Loss_G: 190.8824: : 96it [00:28,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 152.6423: : 97it [00:29,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 157.6919: : 98it [00:29,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6884  Loss_G: 140.1160: : 99it [00:29,  3.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 134.6724: : 100it [00:30,  3.57it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6875  Loss_G: 137.9317: : 101it [00:30,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6875  Loss_G: 130.6238: : 102it [00:30,  3.40it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6878  Loss_G: 155.2431: : 103it [00:30,  3.39it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6872  Loss_G: 137.6826: : 104it [00:31,  3.35it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6888  Loss_G: 139.6169: : 105it [00:31,  3.33it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/1]  Loss_D: 0.6883  Loss_G: 122.6291: : 106it [00:31,  3.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","fake_singing size: torch.Size([32, 128, 256])\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch [1/1]  Loss_D: 0.6883  Loss_G: 122.6291: : 106it [00:32,  3.30it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-e60b92cae9b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccompaniment_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocal_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-93-43e7b92d2398>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(generator, discriminator, optimizer_D, optimizer_G, accompaniment_loader, vocal_loader, speech_loader, l1_loss, adversarial_loss, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_G_adv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_l1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_G_L1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["discriminator.fitted"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sESr-brVW-Jb","executionInfo":{"status":"ok","timestamp":1743780708635,"user_tz":420,"elapsed":5,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}},"outputId":"ec8992eb-8df1-4aba-bf24-39371a7a7868"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"lbLNj0VUxV3-","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"cd22c847-2786-44e1-cb27-fd60fe3d8e39","executionInfo":{"status":"error","timestamp":1743778343705,"user_tz":420,"elapsed":23200,"user":{"displayName":"Jaspar Wiart","userId":"09145650281217596223"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Error fitting MiniRocket: n_timepoints must be >= 9, but found 1; zero pad shorter series so that n_timepoints == 9\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n","Error in feature extraction: This instance of MiniRocketMultivariate has not been fitted yet. Please call `fit` first.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Input type (double) and bias type (float) should be the same","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-a4350a123a43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Generate fake singing using the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfake_singing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Discriminator output for fake pairs: (generated singing, accompaniment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project/Wave-U-Net-Pytorch/model/waveunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, inst)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveunets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveunets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ALL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project/Wave-U-Net-Pytorch/model/waveunet.py\u001b[0m in \u001b[0;36mforward_module\u001b[0;34m(self, x, module)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# DOWNSAMPLING BLOCKS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsampling_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mshortcuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project/Wave-U-Net-Pytorch/model/waveunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_shortcut_convs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# PREPARING FOR DOWNSAMPLING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project/Wave-U-Net-Pytorch/model/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Add your own variations here with elifs conditioned on \"conv_type\" parameter!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Assume that:\n","# - generator is your Wave-U-Net (or adapted model) that takes an input of shape [B, 256, 289]\n","#   and outputs a tensor of shape [B, 128, 289] representing singing vocals.\n","# - discriminator is your MiniRocket-based discriminator (or another architecture) that takes a pair:\n","#   (vocals, accompaniment), each of shape [B, 128, 289] (or you can concatenate along the channel dimension).\n","#\n","# Both should already be defined and moved to the correct device.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = generator.to(device)\n","\n","# Optional\n","# generator = torch.compile(generator, mode='max-autotune')\n","\n","discriminator = discriminator.to(device)\n","\n","# Loss functions: Adversarial (BCE) and reconstruction (L1)\n","adversarial_loss = nn.BCELoss().to(device)\n","l1_loss = nn.L1Loss().to(device)\n","\n","# Optimizers for generator and discriminator\n","optimizer_G = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n","\n","# Number of training epochs\n","num_epochs = 1\n","\n","# Optional: Set up label smoothing factor for real labels (e.g., 0.9 instead of 1.0)\n","real_label_val = 0.9\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Use zip to iterate over the three loaders together.\n","    # Note: We assume that musdb_dataset and librispeech_dataset have been pre-cropped to the same length.\n","    for (accompaniment, vocal), speech in zip(zip(accompaniment_loader, vocal_loader), speech_loader):\n","        # Move data to device\n","        accompaniment = accompaniment.to(device)  # [B, 128, 289]\n","        vocal = vocal.to(device)                  # [B, 128, 289]\n","        speech = speech.to(device)                # [B, 128, 289]\n","\n","        # Prepare generator input by concatenating speech and accompaniment along channel dimension.\n","        # Resulting shape: [B, 256, 289]\n","        generator_input = torch.cat([speech, accompaniment], dim=1)\n","\n","        # ---------------------\n","        # Train the Discriminator\n","        # ---------------------\n","        optimizer_D.zero_grad()\n","\n","        # Real labels (optionally with label smoothing)\n","        B = accompaniment.size(0)\n","        real_labels = torch.full((B, 1), real_label_val, device=device)\n","        fake_labels = torch.zeros((B, 1), device=device)\n","\n","        # Discriminator output for real pairs: (vocal, accompaniment)\n","        pred_real = discriminator(vocal, accompaniment)\n","        loss_D_real = adversarial_loss(pred_real, real_labels)\n","\n","        # Generate fake singing using the generator\n","        fake_singing = generator(generator_input)\n","\n","        # Discriminator output for fake pairs: (generated singing, accompaniment)\n","        pred_fake = discriminator(fake_singing.detach(), accompaniment)\n","        loss_D_fake = adversarial_loss(pred_fake, fake_labels)\n","\n","        # Total discriminator loss and update\n","        loss_D = 0.5 * (loss_D_real + loss_D_fake)\n","        loss_D.backward()\n","        optimizer_D.step()\n","\n","        # ---------------------\n","        # Train the Generator\n","        # ---------------------\n","        optimizer_G.zero_grad()\n","\n","        # Generator wants the discriminator to output \"real\" for its fake singing.\n","        pred_fake_for_G = discriminator(fake_singing, accompaniment)\n","        loss_G_adv = adversarial_loss(pred_fake_for_G, real_labels)\n","\n","        # Optionally add an L1 reconstruction loss to encourage generated singing to resemble the target vocal.\n","        lambda_l1 = 10  # Weight for L1 loss\n","        loss_G_L1 = l1_loss(fake_singing, vocal)\n","\n","        loss_G = loss_G_adv + lambda_l1 * loss_G_L1\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","    # End of epoch logging\n","    print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss_D: {loss_D.item():.4f}  Loss_G: {loss_G.item():.4f}\")\n","\n","    # Optionally save model checkpoints every few epochs\n","    if (epoch + 1) % 10 == 0:\n","        torch.save(generator.state_dict(), f\"generator_epoch_{epoch+1}.pth\")\n","        torch.save(discriminator.state_dict(), f\"discriminator_epoch_{epoch+1}.pth\")\n"]},{"cell_type":"markdown","metadata":{"id":"dWffnPNExV3-"},"source":["## Save the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6dDyxJmxV3-"},"outputs":[],"source":["# Assuming we have compiled the generator\n","orig_generator = generator._orig_mod\n","path = \"\"\n","torch.save(orig_generator.state_dict(), path + \"generator_state_dict.pt\")\n","# Save the discriminator state dict\n","torch.save(discriminator.state_dict(), path + \"discriminator_state_dict.pt\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}