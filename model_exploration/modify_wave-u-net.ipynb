{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we modify Wave-U-Net for our purposes. We need it to take as input a 256x256 tensor and output a 256x256 tensor. \n",
    "\n",
    "We start by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import same packages as the train script in Wave-U-Net-Pytorch\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# add a path to Wave-U-Net\n",
    "import sys\n",
    "sys.path.append('../Wave-U-Net-Pytorch')\n",
    "\n",
    "import model.utils as model_utils\n",
    "import utils\n",
    "from model.waveunet import Waveunet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using valid convolutions with 289 inputs and 257 outputs\n",
      "input_size (length of input): 289\n",
      "num_inputs (number of channels in the input): 256\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"num_inputs\": 256,               # 128 mel bins per spectrogram, but we have to spectrograms\n",
    "    \"num_outputs\": 128,              # Output also has 128 mel bins\n",
    "    \"num_channels\": [64, 128, 256],    # Example channel progression\n",
    "    \"instruments\": [\"vocal\"],        # Only output vocal, so no music branch\n",
    "    \"kernel_size\": 3,                # Must be odd\n",
    "    \"target_output_size\": 256,       # Desired output time frames (post-processing may crop)\n",
    "    \"conv_type\": \"normal\",           # Set to \"normal\" to meet assertion requirements\n",
    "    \"res\": \"fixed\",                  # Use fixed resampling\n",
    "    \"separate\": False,                # Separate branch for vocal\n",
    "    \"depth\": 1,                      # Number of conv layers per block\n",
    "    \"strides\": 2                   # Down/up-sampling stride\n",
    "}\n",
    "\n",
    "model = Waveunet(**model_config)\n",
    "print(\"input_size (length of input):\", model.input_size)\n",
    "print(\"num_inputs (number of channels in the input):\", model.num_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the model is working by running it on a random tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 289])\n",
      "Output shape: torch.Size([2, 128, 257])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_tensor = torch.randn(2, model.num_inputs,  model.input_size)\n",
    "print(input_tensor.shape)\n",
    "vocal_output = model(input_tensor)\n",
    "print(\"Output shape:\", vocal_output[\"vocal\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the amount of GPU memory the model and a training batch takes up. Print a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using valid convolutions with 289 inputs and 257 outputs\n",
      "Peak GPU memory allocated (bytes): 956684288\n",
      "Current GPU memory allocated (bytes): 154541568\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 150919 KiB |    912 MiB |   9429 MiB |   9282 MiB |\n",
      "|       from large pool | 139776 KiB |    909 MiB |   9332 MiB |   9195 MiB |\n",
      "|       from small pool |  11143 KiB |     13 MiB |     96 MiB |     86 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 150919 KiB |    912 MiB |   9429 MiB |   9282 MiB |\n",
      "|       from large pool | 139776 KiB |    909 MiB |   9332 MiB |   9195 MiB |\n",
      "|       from small pool |  11143 KiB |     13 MiB |     96 MiB |     86 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 150916 KiB |    909 MiB |   9393 MiB |   9246 MiB |\n",
      "|       from large pool | 139776 KiB |    905 MiB |   9296 MiB |   9160 MiB |\n",
      "|       from small pool |  11140 KiB |     13 MiB |     96 MiB |     85 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1226 MiB |   1226 MiB |   1226 MiB |      0 B   |\n",
      "|       from large pool |   1208 MiB |   1208 MiB |   1208 MiB |      0 B   |\n",
      "|       from small pool |     18 MiB |     18 MiB |     18 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   6776 KiB | 206474 KiB |   2088 MiB |   2082 MiB |\n",
      "|       from large pool |   5632 KiB | 199488 KiB |   1958 MiB |   1952 MiB |\n",
      "|       from small pool |   1144 KiB |  10505 KiB |    130 MiB |    129 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      89    |     109    |     941    |     852    |\n",
      "|       from large pool |       3    |      33    |     314    |     311    |\n",
      "|       from small pool |      86    |     106    |     627    |     541    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      89    |     109    |     941    |     852    |\n",
      "|       from large pool |       3    |      33    |     314    |     311    |\n",
      "|       from small pool |      86    |     106    |     627    |     541    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      42    |      42    |      42    |       0    |\n",
      "|       from large pool |      33    |      33    |      33    |       0    |\n",
      "|       from small pool |       9    |       9    |       9    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       8    |      39    |     343    |     335    |\n",
      "|       from large pool |       3    |      23    |     214    |     211    |\n",
      "|       from small pool |       5    |      19    |     129    |     124    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 287]          49,216\n",
      "         ConvLayer-2              [-1, 64, 287]               0\n",
      "            Conv1d-3             [-1, 128, 285]          24,704\n",
      "         ConvLayer-4             [-1, 128, 285]               0\n",
      "        Resample1d-5             [-1, 128, 143]               0\n",
      " DownsamplingBlock-6  [[-1, 128, 143], [-1, 64, 287]]               0\n",
      "            Conv1d-7             [-1, 128, 141]          49,280\n",
      "         ConvLayer-8             [-1, 128, 141]               0\n",
      "            Conv1d-9             [-1, 256, 139]          98,560\n",
      "        ConvLayer-10             [-1, 256, 139]               0\n",
      "       Resample1d-11              [-1, 256, 70]               0\n",
      "DownsamplingBlock-12  [[-1, 256, 70], [-1, 128, 141]]               0\n",
      "           Conv1d-13              [-1, 256, 68]         196,864\n",
      "        ConvLayer-14              [-1, 256, 68]               0\n",
      "       Resample1d-15             [-1, 256, 135]               0\n",
      "           Conv1d-16             [-1, 128, 133]          98,432\n",
      "        ConvLayer-17             [-1, 128, 133]               0\n",
      "           Conv1d-18             [-1, 128, 131]          98,432\n",
      "        ConvLayer-19             [-1, 128, 131]               0\n",
      "  UpsamplingBlock-20             [-1, 128, 131]               0\n",
      "       Resample1d-21             [-1, 128, 261]               0\n",
      "           Conv1d-22              [-1, 64, 259]          24,640\n",
      "        ConvLayer-23              [-1, 64, 259]               0\n",
      "           Conv1d-24              [-1, 64, 257]          24,640\n",
      "        ConvLayer-25              [-1, 64, 257]               0\n",
      "  UpsamplingBlock-26              [-1, 64, 257]               0\n",
      "           Conv1d-27             [-1, 128, 257]           8,320\n",
      "================================================================\n",
      "Total params: 673,088\n",
      "Trainable params: 673,088\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.28\n",
      "Forward/backward pass size (MB): 5028.32\n",
      "Params size (MB): 2.57\n",
      "Estimated Total Size (MB): 5031.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import L1Loss\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# Ensure that you have a CUDA-enabled device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate and move the model to GPU\n",
    "model = Waveunet(**model_config).to(device)\n",
    "\n",
    "# Set up a dummy optimizer and loss function\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = L1Loss()\n",
    "\n",
    "# Define a dummy batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Create a dummy input tensor with the required shape\n",
    "# model.num_inputs corresponds to the number of channels (256 in your config)\n",
    "# model.input_size is the computed length (353, for instance)\n",
    "dummy_input = torch.randn(batch_size, model.num_inputs, model.input_size, device=device)\n",
    "\n",
    "# Create a dummy target tensor with the shape that your model outputs.\n",
    "# For a single output branch (vocal), the output shape should be:\n",
    "# (batch_size, num_outputs, model.output_size)\n",
    "# model.num_outputs is 128 and model.output_size is computed (257 in your case)\n",
    "dummy_target = torch.randn(batch_size, model.num_outputs, model.output_size, device=device)\n",
    "\n",
    "# Reset GPU peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "# Run a single forward and backward pass\n",
    "optimizer.zero_grad()\n",
    "# If separate is False, the model returns a dictionary; pass the correct key.\n",
    "output = model(dummy_input)[\"vocal\"]\n",
    "loss = loss_fn(output, dummy_target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Retrieve GPU memory stats\n",
    "peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "current_memory = torch.cuda.memory_allocated(device)\n",
    "print(\"Peak GPU memory allocated (bytes):\", peak_memory)\n",
    "print(\"Current GPU memory allocated (bytes):\", current_memory)\n",
    "\n",
    "# Optionally, print a detailed memory summary\n",
    "print(torch.cuda.memory_summary(device=device))\n",
    "\n",
    "\n",
    "summary(model, input_size=(model.num_inputs,  model.input_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try padding the input with 17 zeros on the front annd 16 at the back. So that we can pass the model a 256 length tensor. It outputs a 257 tensor, so we will delete the 257th value of the output tensor.\n",
    "\n",
    "We need to modify line 221 of the waveunet file:\n",
    "        if not self.training:  # At test time clip predictions to valid amplitude range\n",
    "            out = out.clamp(min=-1.0, max=1.0)\n",
    "        return out\n",
    "because the mel spectrogram has a different min value (I believe it has values ranging from 0-1.\n",
    "\n",
    "We might try increasing the number of channels in the channel progression to account for inputing 256 channels instead of 1 or 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
