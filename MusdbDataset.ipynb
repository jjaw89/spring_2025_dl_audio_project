{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjaw89/spring_2025_dl_audio_project/blob/main/MusdbDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5oHxPG08sHd",
        "outputId": "535246fb-038e-4061-a129-2cd960157748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: musdb in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from musdb) (2.0.2)\n",
            "Requirement already satisfied: stempeg>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from musdb) (0.2.3)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (from musdb) (25.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from musdb) (4.67.1)\n",
            "Requirement already satisfied: ffmpeg-python>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from stempeg>=0.2.3->musdb) (0.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->musdb) (6.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (1.0.0)\n",
            "Found existing installation: stempeg 0.2.3\n",
            "Uninstalling stempeg-0.2.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/stem2files\n",
            "    /usr/local/lib/python3.11/dist-packages/stempeg-0.2.3.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/stempeg/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled stempeg-0.2.3\n",
            "/content/drive/MyDrive/DeepLearningBootcamp\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# when you install musdb, pip automatically installs a version of stempeg that\n",
        "# contains a small bug. To work around this, download the stempeg folder from\n",
        "# the github to your drive.\n",
        "\n",
        "%pip install musdb  # has some helpful data structures, also installs ffmpeg and stempeg\n",
        "%pip uninstall stempeg    # musdb installs the wrong version of stempeg'\n",
        "\n",
        "# The path below should be changed to the location of the stempeg package in\n",
        "# your Drive\n",
        "%cd '/content/drive/MyDrive/DeepLearningBootcamp'\n",
        "\n",
        "import stempeg\n",
        "import musdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MusdbDataset(Dataset):\n",
        "\n",
        "  def __init__(self, musDB, steps = 256):\n",
        "    self.mel_specs = torch.zeros(1, 2, 128, steps)\n",
        "    self.sample_rates = torch.tensor([0])\n",
        "\n",
        "    for track in musDB:\n",
        "      stems, rate = track.stems, track.rate\n",
        "\n",
        "      # separate the vocal from other instruments and conver to mono signal\n",
        "      audio_novocal = librosa.to_mono(np.transpose(stems[1] + stems[2] + stems[3]))\n",
        "      audio_vocal = librosa.to_mono(np.transpose(stems[4]))\n",
        "\n",
        "      # compute log mel spectrogram and convert to pytorch tensor\n",
        "      logmelspec_novocal = torch.from_numpy(self._mel_spectrogram(audio_novocal, rate))\n",
        "      logmelspec_vocal = torch.from_numpy(self._mel_spectrogram(audio_vocal, rate))\n",
        "\n",
        "      num_slices = logmelspec_novocal.shape[1] // steps\n",
        "\n",
        "      # chop off the last bit so that number of stft steps is a multiple of step size\n",
        "      logmelspec_novocal = logmelspec_novocal[0:128 , 0:num_slices*steps]\n",
        "      logmelspec_vocal = logmelspec_vocal[0:128, 0:num_slices*steps]\n",
        "\n",
        "      logmelspec_novocal = torch.reshape(logmelspec_novocal, (num_slices, 128, steps))\n",
        "      logmelspec_vocal = torch.reshape(logmelspec_vocal, (num_slices, 128, steps))\n",
        "\n",
        "      # unsqueeze and concatenate these tensors. Then concatenate to the big tensor\n",
        "      logmels = torch.cat((logmelspec_novocal.unsqueeze(1), logmelspec_vocal.unsqueeze(1)), 1)\n",
        "      self.mel_specs = torch.cat((self.mel_specs, logmels), 0)\n",
        "      self.sample_rates = torch.cat((self.sample_rates, torch.Tensor([rate])), 0)\n",
        "\n",
        "    # remove the all zeros slice that we initialized with\n",
        "    self.mel_specs = self.mel_specs[1: , : , : , :]\n",
        "    self.sample_rates = self.sample_rates[1:]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.mel_specs.shape[0]\n",
        "\n",
        "  def __getitem__(self, ndx):\n",
        "    # returns tuple (mel spectrogram of accompaniment, mel spectrogram of vocal, rate)\n",
        "    return self.mel_specs[ndx, 0], self.mel_specs[ndx, 1], self.sample_rates[ndx]\n",
        "\n",
        "  def _mel_spectrogram(self, audio, rate):\n",
        "    # compute the log-mel-spectrogram of the audio at the given sample rate\n",
        "    return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))"
      ],
      "metadata": {
        "id": "q0Gfxp1J_sLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the full data set into the workspace\n",
        "music = musdb.DB(\"/content/drive/MyDrive/DeepLearningBootcamp/musdb18_data\", subsets=\"train\")"
      ],
      "metadata": {
        "id": "woM0vis0AyST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataset out of the first 10 tracks, see how many slices of audio we have\n",
        "data = MusdbDataset(music[0:10])\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Ol8Ev7XknV",
        "outputId": "d599675f-b145-417b-d98d-676023be656b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing returns a tuple of 3 items: (no_vocal, vocal, sample_rate)\n",
        "# no_vocal and vocal are both log-mel-spectrograms (so are tenors of shape (128, steps = 256)).\n",
        "no_vocal, vocal, rate = data[5]"
      ],
      "metadata": {
        "id": "6oQwAOSbYTI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(no_vocal.shape)\n",
        "print(vocal.shape)\n",
        "print(rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj83xUMeYuV9",
        "outputId": "22fc5438-897a-47c6-f55c-6fc1ec2553c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 256])\n",
            "torch.Size([128, 256])\n",
            "tensor(44100.)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdvo+GiLvqCcJ5De9H9Rsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}