{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjaw89/spring_2025_dl_audio_project/blob/main/cycle_GAN_train4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qxrWZHYxV36"
      },
      "source": [
        "Here we train our first version of the GAN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vARIOK_HxV36"
      },
      "source": [
        "## Initialize Wave-U-Net\n",
        "\n",
        "We start by loading the necessary packages\n",
        "\n",
        "Wave-U-Net is named ``generator``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZW_oS5ciVzd"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_3vGK4LxV37",
        "outputId": "99bf5619-dd1d-4cc3-ca26-21420b774714"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU: NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "# === Check to see if we are in colab ===\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    colab = True\n",
        "else:\n",
        "    colab = False\n",
        "if colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "#    !{sys.executable} -m pip install musdb\n",
        "    %cd /content/drive/My\\ Drive/git_projects/spring_2025_dl_audio_project\n",
        "\n",
        "# === Built-in modules ===\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import pickle\n",
        "from functools import partial\n",
        "from datetime import datetime\n",
        "from typing import Tuple, List, Dict, Optional\n",
        "\n",
        "# === Third-party modules ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === PyTorch ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn import L1Loss\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "# import torch.multiprocessing as mp\n",
        "\n",
        "# # force the 'spawn' start method for all child processes\n",
        "# mp.set_start_method('spawn', force=True)\n",
        "\n",
        "\n",
        "\n",
        "# === Colab-specific installation (only run if in Colab) ===\n",
        "if colab:\n",
        "    !pip install sktime\n",
        "    !{sys.executable} -m pip install musdb\n",
        "    !{sys.executable} -m pip uninstall -y stempeg  # musdb installs the wrong version of stempeg\n",
        "\n",
        "# === Audio/MIR ===\n",
        "if colab:\n",
        "  %cd /content/drive/My Drive/git_projects/\n",
        "import stempeg\n",
        "import musdb\n",
        "\n",
        "# === Time series transforms ===\n",
        "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
        "\n",
        "if colab:\n",
        "  %cd /content/drive/My\\ Drive/git_projects/spring_2025_dl_audio_project/Wave-U-Net-Pytorch\n",
        "\n",
        "# === Local module imports ===\n",
        "if not colab:\n",
        "  sys.path.append('Wave-U-Net-Pytorch')\n",
        "  sys.path.append(\"workspace/hdd_project_data\")\n",
        "\n",
        "\n",
        "import model.utils as model_utils\n",
        "import utils\n",
        "from model.waveunet import Waveunet\n",
        "\n",
        "# === Device setup ===\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda:\n",
        "    device = torch.device('cuda')\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise Exception(\"GPU not available. Please check your setup.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCddsoTxV39"
      },
      "source": [
        "## Initialize miniRocket\n",
        "We start by loading the necessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg5T7Os6xV39"
      },
      "source": [
        "### CPU Core Allocation for MiniRocketMultivariate\n",
        "\n",
        "- The implementation of `MiniRocketMultivariate` runs on the **CPU**.\n",
        "- We need to decide how many cores to allocate for it.\n",
        "- Some cores will be used by MiniRocket itself, while others are needed for data preparation (e.g., generating spectrograms).\n",
        "- This allocation likely needs to be **tuned for optimal performance**.\n",
        "- As a starting point, we detect the number of available cores and split them evenly.\n",
        "- Note: We avoid using *all* available cores to leave some resources for the operating system and other background processes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ZXiPhWxV39"
      },
      "source": [
        "Create the MiniRocket model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NhG7_-VlxV39"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# MiniRocket Discriminator using tsai library\n",
        "class TsaiMiniRocketDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        freq_bins=256,\n",
        "        time_frames=256,\n",
        "        num_kernels=10000,  # number of convolutional kernels\n",
        "        hidden_dim=1024,    # Increased to handle larger feature dimension\n",
        "        output_dim=1,\n",
        "        accompaniment = True   # whether or not we feed accompaniment\n",
        "    ):\n",
        "        super(TsaiMiniRocketDiscriminator, self).__init__()\n",
        "\n",
        "        # This is the mini rocket transformer which extracts features\n",
        "        self.rocket = MiniRocketMultivariate(num_kernels=num_kernels, n_jobs=minirocket_n_jobs)\n",
        "        # tsai's miniRocketClassifier is implemented with MiniRocketMultivariate as well\n",
        "        self.fitted = False   # fit before training\n",
        "        self.freq_bins = freq_bins\n",
        "        self.time_frames = time_frames\n",
        "        self.num_kernels = num_kernels\n",
        "        self.accompaniment = accompaniment\n",
        "\n",
        "        # For 2D data handling - process each sample with proper dimensions\n",
        "        self.example_input = np.zeros((1, freq_bins, time_frames))\n",
        "\n",
        "        self.feature_dim = num_kernels  # For vocals + accompaniment\n",
        "\n",
        "        classifier_input_dim = 9996\n",
        "\n",
        "        # Example feature reducing layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            # First reduce the massive dimension to something manageable\n",
        "            # nn.Dropout(0.3),\n",
        "            spectral_norm(nn.Linear(classifier_input_dim, hidden_dim)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Second hidden layer\n",
        "            # nn.Dropout(0.3),\n",
        "            spectral_norm(nn.Linear(hidden_dim, hidden_dim // 2)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            # Final classification layer\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim // 2, output_dim),\n",
        "            nn.Sigmoid()\n",
        "            # nn.Tanh()\n",
        "        )\n",
        "        #         # Example feature reducing layers\n",
        "        # self.classifier = nn.Sequential(\n",
        "        #     # First reduce the massive dimension to something manageable\n",
        "        #     nn.Linear(19992, hidden_dim),\n",
        "        #     nn.LeakyReLU(0.2),\n",
        "        #     nn.Dropout(0.3),\n",
        "\n",
        "        #     # Second hidden layer\n",
        "        #     nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "        #     nn.LeakyReLU(0.2),\n",
        "        #     nn.Dropout(0.3),\n",
        "\n",
        "        #     # Final classification layer\n",
        "        #     nn.Linear(hidden_dim // 2, output_dim),\n",
        "        #     nn.Sigmoid()\n",
        "        # )\n",
        "\n",
        "    def fit_rocket(self, vocals, accompaniment = None):\n",
        "        \"\"\"\n",
        "            Fit MiniRocket with just one piece of vocal training data (not the entire training dataset)\n",
        "        \"\"\"\n",
        "        if not self.fitted:\n",
        "            try:\n",
        "                if accompaniment:\n",
        "                    spectrograms = torch.cat((vocals, accompaniment), dim = 1)\n",
        "                else:\n",
        "                    spectrograms = vocals\n",
        "\n",
        "                # Reshape for MiniRocket - it expects (n_instances, n_dimensions, series_length)\n",
        "                # flatten the freq_bins dimension to create a multivariate time series\n",
        "                batch_size = spectrograms.shape[0]\n",
        "\n",
        "                # Convert first to numpy for sktime processing\n",
        "                sample_data = spectrograms.detach().cpu().numpy()\n",
        "                # print(sample_data.shape)\n",
        "                # Reshape to sktime's expected format - reduce to single sample for fitting\n",
        "                # sample_data = sample_data[:, 0]  # Take one sample, remove channel dim\n",
        "\n",
        "                # Fit on this sample\n",
        "                self.rocket.fit(sample_data)\n",
        "                self.fitted = True\n",
        "\n",
        "                # Test transform to get feature dimension\n",
        "                test_transform = self.rocket.transform(sample_data)\n",
        "                self.feature_dim = test_transform.shape[1]\n",
        "\n",
        "                print(f\"MiniRocket fitted. Feature dimension: {self.feature_dim}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fitting MiniRocket: {e}\")\n",
        "                # Use a fallback if fitting fails\n",
        "                self.fitted = True  # Mark as fitted to avoid repeated attempts\n",
        "\n",
        "    def extract_features(self, spectrogram):\n",
        "        \"\"\"Extract MiniRocket features from a spectrogram\"\"\"\n",
        "        try:\n",
        "            # Ensure rocket is fitted\n",
        "            if not self.fitted:\n",
        "                self.fit_rocket(spectrogram)\n",
        "\n",
        "            # Convert to numpy for sktime\n",
        "            spec_np = spectrogram.detach().cpu().numpy()\n",
        "\n",
        "            # Remove channel dimension expected by sktime\n",
        "            # print(spec_np.shape)\n",
        "            # spec_np = spec_np[:, 0]  # [batch_size, freq_bins, time_frames]\n",
        "            # print(spec_np.shape)\n",
        "\n",
        "            # This step extracts features using the convolutional kernels, numbers specified by num_kernels\n",
        "            # print(\"1\")\n",
        "            features = self.rocket.transform(spec_np)\n",
        "            # print(\"2\")\n",
        "            # Convert back to torch tensor\n",
        "            # print(\"features:\", features.shape)\n",
        "            # print(features.head())\n",
        "            features_tensor = torch.tensor(features.values).to(spectrogram.device)\n",
        "            # print(\"features:\", features.shape)\n",
        "            # print(\"3\")\n",
        "            return features_tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in feature extraction: {e}\")\n",
        "            # Return zeros as fallback\n",
        "            return torch.zeros((spectrogram.shape[0], self.num_kernels),\n",
        "                              device=spectrogram.device)\n",
        "\n",
        "    def forward(self, vocals, accompaniment = None):\n",
        "        \"\"\"\n",
        "        Forward pass of the discriminator\n",
        "\n",
        "        Args:\n",
        "            vocals: Spectrograms of shape [batch_size, channels, freq_bins, time_frames]\n",
        "            accompaniment: Spectrograms of shape [batch_size, channels, freq_bins, time_frames]\n",
        "        \"\"\"\n",
        "        # Extract features from both spectrograms\n",
        "        # start_time = time()\n",
        "#        vocal_features = self.extract_features(vocals)\n",
        "\n",
        "        if self.accompaniment:\n",
        "          input = torch.cat((vocals, accompaniment), dim=1)\n",
        "          # print(combined_features.size())\n",
        "        else:\n",
        "          input = vocals\n",
        "\n",
        "        # Classify as real/fake\n",
        "        # print(combined_features.size())\n",
        "        output_features = self.extract_features(input)\n",
        "        validity = self.classifier(output_features)\n",
        "\n",
        "        return validity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEaNx9F0Hnwa"
      },
      "source": [
        "# Import Data into Session\n",
        "\n",
        "First, we run the code that defines the custom Dataset objects. The Datasets were compiled previously and saved in .pt files. In the next cell, we load those Dataset objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpu-Q2zGxV39",
        "outputId": "fd9e4195-fc3a-452c-e6af-1762543d8e55"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "  %cd /content/drive/My Drive/git_projects/\n",
        "else:\n",
        "  sys.path.append('/workspace/hdd_project_data/stempeg')\n",
        "\n",
        "import stempeg\n",
        "\n",
        "\n",
        "class MusdbDataset(Dataset):\n",
        "\n",
        "  def __init__(self, musDB, window_size = 256, step_size = 128):\n",
        "    self.mel_specs = torch.zeros(1, 2, 128, window_size)\n",
        "    self.sample_rates = torch.tensor([0])\n",
        "\n",
        "    num_songs = 0\n",
        "\n",
        "    for track in musDB:\n",
        "      stems, rate = track.stems, track.rate\n",
        "\n",
        "      num_songs += 1\n",
        "\n",
        "      # separate the vocal from other instruments and conver to mono signal\n",
        "      audio_novocal = librosa.to_mono(np.transpose(stems[1] + stems[2] + stems[3]))\n",
        "      audio_vocal = librosa.to_mono(np.transpose(stems[4]))\n",
        "\n",
        "      # compute log mel spectrogram and convert to pytorch tensor\n",
        "      logmelspec_novocal = torch.from_numpy(self._mel_spectrogram(audio_novocal, rate))\n",
        "      logmelspec_vocal = torch.from_numpy(self._mel_spectrogram(audio_vocal, rate))\n",
        "\n",
        "      start_ndx = 0\n",
        "\n",
        "      for step in range(window_size // step_size):\n",
        "        cropped_logmelspec_novocal = logmelspec_novocal[:, start_ndx:]\n",
        "        cropped_logmelspec_vocal = logmelspec_vocal[:, start_ndx:]\n",
        "        num_slices = cropped_logmelspec_novocal.shape[1] // window_size\n",
        "\n",
        "        # chop off the last bit so that number of stft steps is a multiple of window_size\n",
        "        cropped_logmelspec_novocal = cropped_logmelspec_novocal[: , 0:num_slices*window_size]\n",
        "        cropped_logmelspec_vocal = cropped_logmelspec_vocal[:, 0:num_slices*window_size]\n",
        "\n",
        "        # reshape tensors into chunks of size 128x(window_size)\n",
        "        # first dimension is number of chunks\n",
        "        cropped_logmelspec_novocal = torch.transpose(torch.reshape(cropped_logmelspec_novocal, (128, num_slices, window_size)), 0, 1)\n",
        "        cropped_logmelspec_vocal = torch.transpose(torch.reshape(cropped_logmelspec_vocal, (128, num_slices, window_size)), 0, 1)\n",
        "\n",
        "        # unsqueeze and concatenate these tensors. Then concatenate to the big tensor\n",
        "        logmels = torch.cat((cropped_logmelspec_novocal.unsqueeze(1), cropped_logmelspec_vocal.unsqueeze(1)), 1)\n",
        "        self.mel_specs = torch.cat((self.mel_specs, logmels), 0)\n",
        "        self.sample_rates = torch.cat((self.sample_rates, torch.full((num_slices,), rate)), 0)\n",
        "\n",
        "        if num_songs % 5 == 0:\n",
        "          print(str(num_songs) + \" songs processed; produced \" + str(self.mel_specs.shape[0]) + \" spectrograms\")\n",
        "\n",
        "    # remove the all zeros slice that we initialized with\n",
        "    self.mel_specs = self.mel_specs[1: , : , : , :]\n",
        "    self.sample_rates = self.sample_rates[1:]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.mel_specs.shape[0]\n",
        "\n",
        "  def __getitem__(self, ndx):\n",
        "    # returns tuple (mel spectrogram of accompaniment, mel spectrogram of vocal, rate)\n",
        "    return self.mel_specs[ndx, 0], self.mel_specs[ndx, 1], self.sample_rates[ndx]\n",
        "\n",
        "  def _mel_spectrogram(self, audio, rate):\n",
        "    # compute the log-mel-spectrogram of the audio at the given sample rate\n",
        "    return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))\n",
        "\n",
        "  def cat(self, other_ds):\n",
        "    self.mel_specs = torch.cat((self.mel_specs, other_ds.mel_specs), 0)\n",
        "    self.sample_rates = torch.cat((self.sample_rates, other_ds.sample_rates), 0)\n",
        "\n",
        "\n",
        "\n",
        "class SingingDataset(Dataset):\n",
        "\n",
        "  def __init__(self, musDB, window_size = 256, step_size = 128):\n",
        "    self.mel_specs = torch.zeros(1, 128, window_size)\n",
        "    self.sample_rates = torch.tensor([0])\n",
        "\n",
        "    num_songs = 0\n",
        "\n",
        "    for track in musDB:\n",
        "      stems, rate = track.stems, track.rate\n",
        "\n",
        "      num_songs += 1\n",
        "\n",
        "      # load the vocal\n",
        "      vocal = librosa.to_mono(np.transpose(stems[4]))\n",
        "\n",
        "      # compute log mel spectrogram and convert to pytorch tensor\n",
        "      mel_spec = torch.from_numpy(self._mel_spectrogram(vocal, rate))\n",
        "\n",
        "      start_ndx = 0\n",
        "      for step in range(window_size // step_size):\n",
        "        cropped_mel_spec = mel_spec[:, start_ndx:]\n",
        "        num_slices = cropped_mel_spec.shape[1] // window_size\n",
        "\n",
        "        # chop off the last bit so that number of stft steps is a multiple of window_size\n",
        "        cropped_mel_spec = cropped_mel_spec[:, 0:num_slices*window_size]\n",
        "\n",
        "        # reshape tensors into chunks of size 128x(window_size)\n",
        "        # first dimension is number of chunks\n",
        "        cropped_mel_spec = torch.transpose(torch.reshape(cropped_mel_spec, (128, num_slices, window_size)), 0, 1)\n",
        "\n",
        "        # concatenate to the big tensor\n",
        "        self.mel_specs = torch.cat((self.mel_specs, cropped_mel_spec), 0)\n",
        "        self.sample_rates = torch.cat((self.sample_rates, torch.full((num_slices,), rate)), 0)\n",
        "\n",
        "\n",
        "    if num_songs % 5 == 0:\n",
        "        print(str(num_songs) + \" songs processed; produced \" + str(self.mel_specs.shape[0]) + \" spectrograms\")\n",
        "\n",
        "    # remove the all zeros slice that we initialized with\n",
        "    self.mel_specs = self.mel_specs[1: , : , :]\n",
        "    self.sample_rates = self.sample_rates[1:]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.mel_specs.shape[0]\n",
        "\n",
        "  def __getitem__(self, ndx):\n",
        "    # returns tuple (mel spectrogram of accompaniment, mel spectrogram of vocal, rate)\n",
        "    return self.mel_specs[ndx], self.sample_rates[ndx]\n",
        "\n",
        "  def _mel_spectrogram(self, audio, rate):\n",
        "    # compute the log-mel-spectrogram of the audio at the given sample rate\n",
        "    return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))\n",
        "\n",
        "\n",
        "\n",
        "class LibriSpeechDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, window_size = 256, step_size = 128, num_specs = 7647*2):\n",
        "        self.mel_specs = self.mel_specs = torch.zeros(1, 128, window_size)\n",
        "        self.sample_rates = torch.tensor([0])\n",
        "\n",
        "        num_files_opened = 0\n",
        "\n",
        "        for speaker_dir in os.listdir(path):\n",
        "            speaker_path = path + \"/\" + speaker_dir\n",
        "            for chapter_dir in os.listdir(speaker_path):\n",
        "                chapter_path = speaker_path + \"/\" + chapter_dir\n",
        "                for file in os.listdir(chapter_path):\n",
        "                    # checks file extension and stops when we hit desired number of spectrograms (num_specs)\n",
        "                    if file.endswith('.flac') and self.mel_specs.shape[0] - 1 < num_specs:\n",
        "                        # get audio file and convert to log mel spectrogram\n",
        "                        speech, rate = librosa.load(chapter_path + \"/\" + file, sr = 44100)\n",
        "                        mel_spec = torch.from_numpy(self._mel_spectrogram(speech, rate))\n",
        "                        start_ndx = 0\n",
        "\n",
        "                        num_files_opened += 1\n",
        "\n",
        "                        for step in range(window_size // step_size):\n",
        "                            cropped_mel_spec = mel_spec[:, start_ndx:]\n",
        "\n",
        "                            # Saves the total number of 128 x (window_size) spectrograms\n",
        "                            num_slices = cropped_mel_spec.shape[1] // window_size\n",
        "\n",
        "                            # chop off the last bit so that number of stft steps is a multiple of window_size\n",
        "                            cropped_mel_spec = cropped_mel_spec[ : , 0 : num_slices*window_size]\n",
        "\n",
        "                            # reshape the tensor to have many spectrograms of size 128 x (steps)\n",
        "                            cropped_mel_spec = torch.transpose(torch.reshape(cropped_mel_spec, (128, num_slices, window_size)), 0, 1)\n",
        "\n",
        "                            # concatenate tensor to the full tensor in the Dataset object\n",
        "                            self.mel_specs = torch.cat((self.mel_specs, cropped_mel_spec), 0)\n",
        "                            self.sample_rates = torch.cat((self.sample_rates, torch.full((num_slices,), rate)), 0)\n",
        "\n",
        "                            # increment start_ndx\n",
        "                            start_ndx += step_size\n",
        "\n",
        "\n",
        "                        if num_files_opened % 50 == 0:\n",
        "                            print(\"opened \" + str(num_files_opened) + \" files and produced \" + str(self.mel_specs.shape[0]) + \" spectrograms\")\n",
        "\n",
        "\n",
        "        # chop off the zero layer we initialized with\n",
        "        self.mel_specs = self.mel_specs[1:]\n",
        "        self.sample_rates = self.sample_rates[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mel_specs.shape[0]\n",
        "\n",
        "    def __getitem__(self, ndx):\n",
        "        return self.mel_specs[ndx], self.sample_rates[ndx]\n",
        "\n",
        "    def _mel_spectrogram(self, audio, rate):\n",
        "        # compute the log-mel-spectrogram of the audio at the given sample rate\n",
        "        return librosa.power_to_db(librosa.feature.melspectrogram(y = audio, sr = rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peiksp9NuMGX"
      },
      "source": [
        "### Explore these datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK8WbDmTjkNH"
      },
      "source": [
        "## Dataset Helpers Explanation\n",
        "Why New Dataset Helpers?\n",
        "\n",
        "We have created new dataset helper classes (i.e., AccompanimentData, VocalData, and SpeechData) so that we can control how the data is padded and later shuffled.\n",
        "\n",
        "- **Separation of Data:**\n",
        "We separated the vocal and accompaniment data from the MusDB dataset. In our experiments, we might want to shuffle the speech data independently of the combined music data.\n",
        "\n",
        "- **Shuffling Considerations:**\n",
        "For the vocal and accompaniment data, we want to maintain their pairing so that they are shuffled in the same order. In contrast, we want the speech data to be shuffled independently.\n",
        "\n",
        "- **Future Extensions:**\n",
        "In the future, we may add another helper class that combines the vocal and accompaniment data to ensure synchronized shuffling in our data loaders.\n",
        "\n",
        "This modular approach gives us flexibility in handling and preprocessing the data for our GAN training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O7OGNnS8XMVd"
      },
      "outputs": [],
      "source": [
        "class AccompanimentVocalData(Dataset):\n",
        "  def __init__(self, musdb_dataset, output_length = 289):\n",
        "    self.musdb = musdb_dataset\n",
        "    self.out_len = output_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.musdb)\n",
        "\n",
        "  def __getitem__(self, ndx):\n",
        "    acc, voc, _ = self.musdb[ndx]\n",
        "    delta = self.out_len - acc.size(-1)\n",
        "\n",
        "    if delta > 0:\n",
        "      # Half the remainder goes to the front\n",
        "      left_pad_len = (delta // 2) + (delta % 2)  # 17\n",
        "      right_pad_len = delta // 2                # 16\n",
        "      acc_pad = F.pad(acc, (left_pad_len, right_pad_len), \"constant\", -80)\n",
        "      voc_pad = F.pad(voc, (left_pad_len, right_pad_len), \"constant\", -80)\n",
        "\n",
        "    else:\n",
        "      acc_pad = acc\n",
        "      voc_pad = voc\n",
        "\n",
        "    return {\"acc_no_pad\" : acc,\n",
        "            \"voc_no_pad\" : voc,\n",
        "            \"acc_pad\": acc_pad,\n",
        "            \"voc_pad\" : voc_pad}\n",
        "\n",
        "class SpeechData(Dataset):\n",
        "    def __init__(self, librispeech_dataset, output_length=289):\n",
        "        self.librispeech_dataset = librispeech_dataset\n",
        "        self.output_length = output_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.librispeech_dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        speech, _ = self.librispeech_dataset[index]\n",
        "        # If speech has multiple slices, pick the first slice\n",
        "        if speech.dim() == 3:\n",
        "            speech = speech[0]  # shape: [128, 256]\n",
        "        current_len = speech.size(-1)\n",
        "        delta = self.output_length - current_len\n",
        "\n",
        "        if delta > 0:\n",
        "            left_pad_len = (delta // 2) + (delta % 2)\n",
        "            right_pad_len = delta // 2\n",
        "            speech_pad = F.pad(speech, (left_pad_len, right_pad_len), \"constant\", -80)\n",
        "        else:\n",
        "            speech_pad = speech\n",
        "        return {\"no_pad\" : speech, \"pad\" : speech_pad}\n",
        "\n",
        "\n",
        "class AccompanimentData(Dataset):\n",
        "  def __init__(self, musdb_dataset, output_length = 289):\n",
        "    self.musdb = musdb_dataset\n",
        "    self.out_len = output_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.musdb)\n",
        "\n",
        "  def __getitem__(self, ndx):\n",
        "    acc, _, _ = self.musdb[ndx]\n",
        "    delta = self.out_len - acc.size(-1)\n",
        "\n",
        "    if delta > 0:\n",
        "      # Half the remainder goes to the front\n",
        "      left_pad_len = (delta // 2) + (delta % 2)  # 17\n",
        "      right_pad_len = delta // 2                # 16\n",
        "      acc_pad = F.pad(acc, (left_pad_len, right_pad_len), \"constant\", -80)\n",
        "    else:\n",
        "      acc_pad = acc\n",
        "\n",
        "    return {\"acc_no_pad\" : acc, \"acc_pad\": acc_pad,}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transform_for_gen_2(batch, output_length = 289):\n",
        "  current_len = batch.size(-1)\n",
        "  delta = output_length - current_len\n",
        "\n",
        "  if delta > 0:\n",
        "      left_pad_len = (delta // 2) + (delta % 2)\n",
        "      right_pad_len = delta // 2\n",
        "      batch = F.pad(batch, (left_pad_len, right_pad_len), \"constant\", 0)\n",
        "  return batch\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suMDmB62yS_N"
      },
      "source": [
        "### DataLoader Explanation\n",
        "What is a DataLoader and Why Do We Need It?\n",
        "\n",
        "A DataLoader in PyTorch is a utility that wraps a dataset and provides:\n",
        "\n",
        "- **Batching:** It divides your dataset into batches so that you can train your models with mini-batch gradient descent.\n",
        "\n",
        "- **Shuffling:** It shuffles the data at every epoch (if specified) to help reduce overfitting and ensure the model sees a diverse set of examples.\n",
        "\n",
        "- **Parallel Data Loading:** It can load data in parallel using multiple worker processes, speeding up training.\n",
        "\n",
        "In our case, we create separate DataLoaders for:\n",
        "\n",
        "- The accompaniment data (paired with vocals) from the MusDB dataset.\n",
        "\n",
        "- The vocal data (paired with accompaniment) from the MusDB dataset.\n",
        "\n",
        "- The speech data from the LibriSpeech dataset.\n",
        "\n",
        "This lets us shuffle the speech data independently, while keeping the vocal/accompaniment pairs synchronized during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vLcvcILSlW3C"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Print how many batches each DataLoader contains\n",
        "# print(\"Accompaniment loader length:\", len(accompaniment_loader))\n",
        "# print(\"Vocal loader length:\", len(vocal_loader))\n",
        "# print(\"Speech loader length:\", len(speech_loader))\n",
        "\n",
        "# # Optionally, fetch and print the shape of the first batch\n",
        "# accompaniment_batch = next(iter(accompaniment_loader))\n",
        "# vocal_batch = next(iter(vocal_loader))\n",
        "# speech_batch = next(iter(speech_loader))\n",
        "# print(accompaniment_batch[\"pad\"])\n",
        "\n",
        "# print(\"Accompaniment first batch shape:\", accompaniment_batch.shape)\n",
        "# print(\"Vocal first batch shape:\", vocal_batch.shape)\n",
        "# print(\"Speech first batch shape:\", speech_batch.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xUqt-HDRxKB"
      },
      "source": [
        "## Second Generator Model\n",
        "Here we initialize the second generator model whose purpose is to convert the generated vocals back to normal speach for the cycle GAN. We again use Wave-U-Net, but with a different configuration. The main difference is that we will not input the music along with the vocal track."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ql5ZsesRvvd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd1FQ3ZdSymH"
      },
      "source": [
        "## Transform Input to generator_2\n",
        "\n",
        "The output of the generator model is a (batch_size, 128, 257) tensor. The model expects a tensor of size (batch_size, 128, 289). We need to pad the last dimension with 16 zeros on each size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQn9K5nVSu-c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jg9I_4qxV3-"
      },
      "source": [
        "## Train the Cycle GAN\n",
        "The models are ``generator`` and ``discriminator`` and ``generator_2``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f3MBnVQYjpBB"
      },
      "outputs": [],
      "source": [
        "##### Code to convert spectrograms to audio and play audio ######\n",
        "\n",
        "import IPython.display as ipd\n",
        "def convert_to_audio(mel_spectrograms, n_fft=2048, hop_length=512, power=2.0, n_iter=32):\n",
        "    audio_files = []\n",
        "    sr = 44100\n",
        "\n",
        "    for mel_spec in mel_spectrograms:\n",
        "        # Convert Mel spectrogram back to linear spectrogram\n",
        "        # mel_s\n",
        "        mel_spec = mel_spec.detach().cpu().numpy() # Remove batch dimension\n",
        "        print(mel_spec)\n",
        "        # print(mel_spec.shape)\n",
        "        linear_spec = librosa.feature.inverse.mel_to_stft(\n",
        "            mel_spec, sr=sr, n_fft=n_fft, power=power\n",
        "        )\n",
        "\n",
        "        # Apply Griffin-Lim algorithm for phase reconstruction\n",
        "        audio = librosa.griffinlim(\n",
        "            linear_spec, hop_length=hop_length, n_iter=n_iter\n",
        "        )\n",
        "        print(audio)\n",
        "        audio_files.append(audio)\n",
        "        # break\n",
        "\n",
        "    return audio_files\n",
        "\n",
        "def display_audio(audio_file):\n",
        "    # y, sr = librosa.load(audio_file, sr=44100)\n",
        "    ipd.display(ipd.Audio(audio_file, rate=44100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH5IRnDiMlFm"
      },
      "source": [
        "# A Different Architecture\n",
        "\n",
        "The code below defines a training loop with a slightly different cycle GAN architecture. In this model, we have\n",
        "- generator_1 - a Wave-U-Net model trained to accept speech and an accompaniment to produce a fake vocal performance\n",
        "- generator_2 - a Wave-U-Net model trained to acced singing and produce fake speech\n",
        "- discriminator_1 - a MiniRocket classifier that determines real vs fake vocal performances\n",
        "- discriminator_2 - a MiniRocket classifier that determines real vs fake speech.\n",
        "\n",
        "The training loop iterates the following process on a triple of (vocal, accompaniment, and speech).\n",
        "\n",
        "\n",
        "A. Speech + Accompaniment --> Vocal --> Reconstructed Speech\n",
        "1.   Feed the speech and accompaniment into generator_1 to produce a fake vocal\n",
        "2.   discriminator_1 distinguishes between real vocals and the output of generator_1\n",
        "3.   generator_2 takes the fake singing output and generates reconstructed speech\n",
        "4.   Compute L_1 loss between the input speech and the reconstructed speech\n",
        "\n",
        "B. Vocal --> Fake Speech + Real Accompaniment --> Reconstructed Vocal\n",
        "\n",
        "\n",
        "1. A real vocal is fed into generator_2 which produces fake speech (the corresponding accompaniment is used later)\n",
        "2. discriminator_2 distinguishes between real speech and the fake speech produced by generator_2\n",
        "3. generator_1 takes the fake speech and the real accompaniment and produces a reconstructed vocal\n",
        "4. Compute L_1 loss between input vocal and the reconstructed vocal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mTZRQAwjWGFr"
      },
      "outputs": [],
      "source": [
        "# # ----- Single Epoch Training Function -----\n",
        "# def cycle_train_epoch(\n",
        "#     generator_vocal,\n",
        "#     generator_speech,\n",
        "#     discriminator_vocal,\n",
        "#     discriminator_speech,\n",
        "#     optimizer_GV,\n",
        "#     optimizer_GS,\n",
        "#     optimizer_DV,\n",
        "#     optimizer_DS,\n",
        "#     accompaniment_loader,\n",
        "#     vocal_loader,\n",
        "#     speech_loader,\n",
        "#     l1_loss,\n",
        "#     lambda_l1,\n",
        "#     lambda_cycle,\n",
        "#     adversarial_loss,\n",
        "#     device,\n",
        "#     virtual_batch_size,\n",
        "#     clip_length,\n",
        "#     input_size_generators,\n",
        "#     save_output=False,\n",
        "#     smart_discriminator=False\n",
        "# ):\n",
        "#     total_loss_DV = total_loss_DS = total_loss_GV = total_loss_GS = 0\n",
        "#     total_loss_GV_adv = total_loss_GS_adv = total_loss_cycle_vocal = total_loss_cycle_speech = 0.0\n",
        "#     # Optionally record gradient norms per batch for diagnosing vanishing gradients.\n",
        "#     grad_norms_DV = []\n",
        "#     grad_norms_DS = []\n",
        "#     grad_norms_GV = []\n",
        "#     grad_norms_GS = []\n",
        "#     num_batches = 0\n",
        "\n",
        "#     # ---- batch loop ----\n",
        "#     for ((accomp, voc), speech) in tqdm(\n",
        "#         zip(zip(accompaniment_loader, vocal_loader), speech_loader),\n",
        "#         desc=\"Training Batches\"\n",
        "#     ):\n",
        "#         # Move data to device\n",
        "#         x_acc = accomp[\"pad\"].float().to(device)       # [B,128,289]\n",
        "#         x_speech = speech[\"pad\"].float().to(device)    # [B,128,289]\n",
        "#         x_voc = voc[\"pad\"].float().to(device)\n",
        "#         x_in = torch.cat([x_speech, x_acc], dim=1)     # [B,256,289]\n",
        "\n",
        "#         # Discriminator real/fake labels\n",
        "#         B = x_acc.size(0)\n",
        "#         # real_labels = torch.ones(B, 1, device=device)\n",
        "#         # fake_labels = torch.zeros(B, 1, device=device)\n",
        "\n",
        "#         real_labels = torch.rand(B,1, device=device) * 0.2 + 0.8  # [0.8,1.0]\n",
        "#         fake_labels = torch.rand(B,1, device=device) * 0.2        # [0.0,0.2]\n",
        "\n",
        "#         # real_labels = torch.ones(B, 1, device=device)\n",
        "#         # fake_labels = -torch.ones(B, 1, device=device)\n",
        "\n",
        "#         # 1) Train disciminator_vocal\n",
        "#         optimizer_DV.zero_grad()\n",
        "#         acc_np = accomp[\"no_pad\"].float().to(device)\n",
        "#         voc_np = voc[\"no_pad\"].float().to(device)\n",
        "#         speech_np = speech[\"no_pad\"].float().to(device)\n",
        "\n",
        "#         pred_real = discriminator_vocal(voc_np, acc_np)\n",
        "#         loss_DV_real = adversarial_loss(pred_real, real_labels)\n",
        "\n",
        "#         raw_fake_vocal = generator_vocal(x_in)[\"vocal\"]\n",
        "#         fake_vocal = raw_fake_vocal.clone()\n",
        "#         fake_vocal_crop = torch.narrow(fake_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "#         pred_fake_vocal = discriminator_vocal(fake_vocal_crop, acc_np)\n",
        "#         loss_DV_fake = adversarial_loss(pred_fake_vocal, fake_labels)\n",
        "\n",
        "#         ################ I THINK WE ARE USING THE WRONG LOSS FUNCTION FOR ADVERSARIAL LOSS #########\n",
        "#         loss_DV = 0.5 * (loss_DV_real + loss_DV_fake)\n",
        "#         if loss_DV.item() > 0.5  or smart_discriminator:\n",
        "#             loss_DV.backward()\n",
        "#             optimizer_DV.step()\n",
        "\n",
        "#         # 2) Train GV\n",
        "#         if virtual_batch_size == 1:\n",
        "#             optimizer_GV.zero_grad()\n",
        "#             optimizer_GS.zero_grad()\n",
        "\n",
        "\n",
        "#         pred_for_GV = discriminator_vocal(fake_vocal, acc_np)\n",
        "#         loss_GV_adv = adversarial_loss(pred_for_GV, real_labels)\n",
        "\n",
        "\n",
        "#         # cycle‑consistency\n",
        "#         fake_vocal_pad = transform_for_gen_2(fake_vocal, input_size_generators)  # you must define this\n",
        "#         raw_rec_speech = generator_speech(fake_vocal_pad)[\"speech\"]\n",
        "#         rec_speech = raw_rec_speech.clone()\n",
        "#         rec_speech_crop = torch.narrow(rec_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "\n",
        "#         loss_cycle_speech = l1_loss(rec_speech_crop, speech_np)\n",
        "\n",
        "#         # convex combination\n",
        "#         loss_GV = (loss_GV_adv + lambda_cycle * loss_cycle_speech) / (1 + lambda_cycle)\n",
        "#         loss_GV.backward()\n",
        "\n",
        "\n",
        "#         # 3) Train discriminator_speech\n",
        "#         optimizer_DS.zero_grad()\n",
        "#         # pred_real = discriminator_speech(speech_np, acc_np)\n",
        "#         pred_real_speech = discriminator_speech(speech_np)\n",
        "#         loss_DS_real = adversarial_loss(pred_real_speech, real_labels)\n",
        "\n",
        "#         raw_fake_speech = generator_speech(x_voc)[\"speech\"]\n",
        "#         fake_speech = raw_fake_speech.clone()\n",
        "#         fake_speech_crop = torch.narrow(fake_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "#         # pred_fake_speech = discriminator_speech(fake_speech_crop, acc_np)\n",
        "#         pred_fake_speech = discriminator_speech(fake_speech_crop)\n",
        "#         loss_DS_fake = adversarial_loss(pred_fake_speech, fake_labels)\n",
        "\n",
        "#         loss_DS = 0.5 * (loss_DS_real + loss_DS_fake)\n",
        "#         if loss_DS.item() > 0.5 or smart_discriminator:\n",
        "#             loss_DS.backward()\n",
        "#             optimizer_DS.step()\n",
        "\n",
        "\n",
        "#         # 4) Train GS\n",
        "\n",
        "#         # pred_for_GS = discriminator_speech(fake_speech, acc_np)\n",
        "#         pred_for_GS = discriminator_speech(fake_speech)\n",
        "#         loss_GS_adv = adversarial_loss(pred_for_GS, real_labels)\n",
        "\n",
        "#         # cycle‑consistency\n",
        "#         fake_speech_pad = transform_for_gen_2(fake_speech, output_length=input_size_generators)  # you must define this\n",
        "#         fake_speech_with_acc = torch.cat([fake_speech_pad, x_acc], dim=1)\n",
        "#         raw_rec_vocal = generator_vocal(fake_speech_with_acc)[\"vocal\"]\n",
        "#         rec_vocal = raw_rec_vocal.clone()\n",
        "#         rec_vocal_crop = torch.narrow(rec_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "#         loss_cycle_vocal = l1_loss(rec_vocal_crop, voc_np)\n",
        "\n",
        "#         # convex combination\n",
        "#         loss_GS = (loss_GS_adv + lambda_cycle * loss_cycle_vocal) / (1 + lambda_cycle)\n",
        "#         loss_GS.backward()\n",
        "\n",
        "\n",
        "\n",
        "#         # Record discriminator gradient norms.\n",
        "#         grad_norm = 0.0\n",
        "#         count = 0\n",
        "#         for p in discriminator_vocal.parameters():\n",
        "#             if p.grad is not None:\n",
        "#                 grad_norm += p.grad.norm().item()\n",
        "#                 count += 1\n",
        "#         if count > 0:\n",
        "#             grad_norms_DV.append(grad_norm / count)\n",
        "\n",
        "#         grad_norm = 0.0\n",
        "#         count = 0\n",
        "#         for p in discriminator_speech.parameters():\n",
        "#             if p.grad is not None:\n",
        "#                 grad_norm += p.grad.norm().item()\n",
        "#                 count += 1\n",
        "#         if count > 0:\n",
        "#             grad_norms_DS.append(grad_norm / count)\n",
        "\n",
        "\n",
        "#         grad_norm = 0.0\n",
        "#         count = 0\n",
        "\n",
        "#         for p in generator_vocal.parameters():\n",
        "#             if p.grad is not None:\n",
        "#                 grad_norm += p.grad.norm().item()\n",
        "#                 count += 1\n",
        "#         if count > 0:\n",
        "#             grad_norms_GV.append(grad_norm / count)\n",
        "\n",
        "#         grad_norm = 0.0\n",
        "#         count = 0\n",
        "#         for p in generator_speech.parameters():\n",
        "#             if p.grad is not None:\n",
        "#                 grad_norm += p.grad.norm().item()\n",
        "#                 count += 1\n",
        "#         if count > 0:\n",
        "#             grad_norms_GS.append(grad_norm / count)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         if (num_batches + 1) % virtual_batch_size == 0:\n",
        "#             optimizer_GV.step()\n",
        "#             optimizer_GS.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         # Accumulate metrics\n",
        "#         total_loss_DV     += loss_DV.item()\n",
        "#         total_loss_DS     += loss_DS.item()\n",
        "#         total_loss_GV_adv  += loss_GV_adv.item()\n",
        "#         total_loss_GS_adv += loss_GS_adv.item()\n",
        "#         total_loss_cycle_vocal += loss_cycle_vocal.item()\n",
        "#         total_loss_cycle_speech += loss_cycle_speech.item()\n",
        "#         total_loss_GV      += loss_GV.item()\n",
        "#         total_loss_GS   += loss_GS.item()\n",
        "#         num_batches       += 1\n",
        "#         # audio_files = []\n",
        "#         # if save_output:\n",
        "#         #     fake_singing_list = [fake_crop[i] for i in range(fake_crop.shape[0])]\n",
        "#         #     audio_files = convert_to_audio(fake_singing_list)\n",
        "#     return {\n",
        "#         \"loss_DV\":      total_loss_DV / num_batches,\n",
        "#         \"loss_DS\":      total_loss_DS / num_batches,\n",
        "#         \"loss_GV\":      total_loss_GV / num_batches,\n",
        "#         \"loss_GS\":      total_loss_GS / num_batches,\n",
        "#         \"loss_GV_adv\":  total_loss_GV_adv / num_batches,\n",
        "#         \"loss_GS_adv\":  total_loss_GS_adv / num_batches,\n",
        "#         \"loss_cycle_vocal\":  total_loss_cycle_vocal / num_batches,\n",
        "#         \"loss_cycle_speech\":  total_loss_cycle_speech / num_batches,\n",
        "#         \"avg_grad_norm_DV\": sum(grad_norms_DV) / len(grad_norms_DV) if grad_norms_DV else 0.0,\n",
        "#         \"avg_grad_norm_DS\": sum(grad_norms_DS) / len(grad_norms_DS) if grad_norms_DS else 0.0,\n",
        "#         \"avg_grad_norm_GV\": sum(grad_norms_GV) / len(grad_norms_GV) if grad_norms_GV else 0.0,\n",
        "#         \"avg_grad_norm_GS\": sum(grad_norms_GS) / len(grad_norms_GS) if grad_norms_GS else 0.0\n",
        "#     }#, audio_files\n",
        "\n",
        "# # ----- Multi-Epoch Training Function -----\n",
        "# def cycle_train(\n",
        "#     generator_vocal,\n",
        "#     generator_speech,\n",
        "#     discriminator_vocal,\n",
        "#     discriminator_speech,\n",
        "#     optimizer_DV,\n",
        "#     optimizer_DS,\n",
        "#     optimizer_GV,\n",
        "#     optimizer_GS,\n",
        "#     accompaniment_loader,\n",
        "#     vocal_loader,\n",
        "#     speech_loader,\n",
        "#     l1_loss,\n",
        "#     lambda_l1,\n",
        "#     lambda_cycle,\n",
        "#     adversarial_loss,\n",
        "#     device,\n",
        "#     num_epochs,\n",
        "#     virtual_batch_size,\n",
        "#     log_dir,\n",
        "#     clip_length,\n",
        "#     input_size_generators,\n",
        "#     save_audio = True,\n",
        "#     smart_discriminator = False\n",
        "# ):\n",
        "#     writer = SummaryWriter(log_dir=log_dir)\n",
        "#     global_step = 0\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         save_audio = True if epoch == num_epochs-1 else False\n",
        "#         print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
        "#         epoch_metrics = cycle_train_epoch(\n",
        "#             generator_vocal,\n",
        "#             generator_speech,\n",
        "#             discriminator_vocal,\n",
        "#             discriminator_speech,\n",
        "#             optimizer_DV,\n",
        "#             optimizer_DS,\n",
        "#             optimizer_GV,\n",
        "#             optimizer_GS,\n",
        "#             accompaniment_loader,\n",
        "#             vocal_loader,\n",
        "#             speech_loader,\n",
        "#             l1_loss,\n",
        "#             lambda_l1,\n",
        "#             lambda_cycle,\n",
        "#             adversarial_loss,\n",
        "#             device,\n",
        "#             virtual_batch_size,\n",
        "#             clip_length,\n",
        "#             input_size_generators,\n",
        "#             save_output = save_audio,\n",
        "#             smart_discriminator = smart_discriminator\n",
        "#         )\n",
        "#         print(f\"Epoch {epoch+1} Metrics:\")\n",
        "#         print(f\"  Loss_DV:         {epoch_metrics['loss_DV']:.4f}\")\n",
        "#         print(f\"  Loss_DS:         {epoch_metrics['loss_DS']:.4f}\")\n",
        "#         # print(f\"  Loss_GV_total:   {epoch_metrics['loss_GV']:.4f}\")\n",
        "#         # print(f\"  Loss_GS_total:   {epoch_metrics['loss_GS']:.4f}\")\n",
        "#         print(f\"  Loss_GV_adv:     {epoch_metrics['loss_GV_adv']:.4f}\")\n",
        "#         print(f\"  Loss_GS_adv:     {epoch_metrics['loss_GS_adv']:.4f}\")\n",
        "#         print(f\"  Loss_Cycle Vocal:     {epoch_metrics['loss_cycle_vocal']:.4f}\")\n",
        "#         print(f\"  Loss_Cycle Speech:     {epoch_metrics['loss_cycle_speech']:.4f}\")\n",
        "#         print(f\"  Grad Norm DV:    {epoch_metrics['avg_grad_norm_DV']:.4f}\")\n",
        "#         print(f\"  Grad Norm DS:    {epoch_metrics['avg_grad_norm_DS']:.4f}\")\n",
        "#         print(f\"  Grad Norm GV:    {epoch_metrics['avg_grad_norm_GV']:.4f}\")\n",
        "#         print(f\"  Grad Norm GS:    {epoch_metrics['avg_grad_norm_GS']:.4f}\")\n",
        "\n",
        "#         # Log metrics to TensorBoard.\n",
        "#         writer.add_scalar(\"Loss/Discriminator\", epoch_metrics[\"loss_DV\"], epoch)\n",
        "#         # writer.add_scalar(\"Loss/Generator_total\", epoch_metrics[\"loss_G_total\"], epoch)\n",
        "#         writer.add_scalar(\"Loss/Generator_adversarial\", epoch_metrics[\"loss_GV_adv\"], epoch)\n",
        "#         # writer.add_scalar(\"Loss/Generator_L1\", epoch_metrics[\"loss_G_L1\"], epoch)\n",
        "#         writer.add_scalar(\"Loss/Cycle\", epoch_metrics[\"loss_cycle_vocal\"], epoch)\n",
        "#         writer.add_scalar(\"Gradients/Discriminator\", epoch_metrics[\"avg_grad_norm_DV\"], epoch)\n",
        "#         writer.add_scalar(\"Gradients/Generator\", epoch_metrics[\"avg_grad_norm_GV\"], epoch)\n",
        "\n",
        "#         global_step += 1\n",
        "\n",
        "#     writer.close()\n",
        "#     return #audio_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y2_2Oqh9PPGK"
      },
      "outputs": [],
      "source": [
        "# ----- Single Epoch Training Function -----\n",
        "def cycle_train_epoch_rand_accomp(\n",
        "    generator_vocal,\n",
        "    generator_speech,\n",
        "    discriminator_vocal,\n",
        "    discriminator_speech,\n",
        "    optimizer_DV,\n",
        "    optimizer_DS,\n",
        "    optimizer_GV,\n",
        "    optimizer_GS,\n",
        "    acc_voc_loader,\n",
        "    speech_loader,\n",
        "    acc_loader,\n",
        "    l1_loss,\n",
        "    mse_loss,\n",
        "    lambda_l1,\n",
        "    lambda_cycle,\n",
        "    lambda_identity,\n",
        "    bce_loss,\n",
        "    device,\n",
        "    virtual_batch_size,\n",
        "    clip_length,\n",
        "    input_size_generators,\n",
        "    save_output=False,\n",
        "    smart_discriminator=False,\n",
        "    batch_size = 32,\n",
        "):\n",
        "\n",
        "    total_loss_DV = total_loss_DS = total_loss_GV = total_loss_GS  = 0\n",
        "    total_loss_GV_identity = total_loss_GS_identity = 0\n",
        "    total_loss_adv_vocal = total_loss_adv_speech = total_loss_cycle_vocal = total_loss_cycle_speech = total_loss_GV_identity = total_loss_GS_identity =  0.0\n",
        "    # Optionally record gradient norms per batch for diagnosing vanishing gradients.\n",
        "    grad_norms_DV = []\n",
        "    grad_norms_DS = []\n",
        "    grad_norms_GV = []\n",
        "    grad_norms_GS = []\n",
        "    num_batches = 0\n",
        "\n",
        "\n",
        "    alpha = 0.9      # Tuneable constant to gate the discriminator training\n",
        "    running_loss_DV = 0.0\n",
        "    running_loss_DS = 0.0\n",
        "    dv_threshold = 0.6\n",
        "    ds_threshold = 0.6\n",
        "\n",
        "    optimizer_DV.zero_grad()\n",
        "    optimizer_DS.zero_grad()\n",
        "    optimizer_GV.zero_grad()\n",
        "    optimizer_GS.zero_grad()\n",
        "\n",
        "    # real_labels = torch.ones(batch_size, 1, device=device, requires_grad = False)\n",
        "    # fake_labels = torch.zeros(batch_size, 1, device=device, requires_grad = False)\n",
        "\n",
        "    num_DV_backwards = num_DS_backwards = 0\n",
        "\n",
        "    loaders = tqdm(zip(acc_voc_loader, speech_loader, acc_loader), desc = \"Training Batches\")\n",
        "\n",
        "    # ---- batch loop ----\n",
        "    for data in loaders:\n",
        "        # Read in data\n",
        "        acc_voc = data[0]\n",
        "        speech = data[1]\n",
        "        x_acc = acc_voc[\"acc_pad\"].float().to(device)       # [B,128,289]\n",
        "        x_voc = acc_voc[\"voc_pad\"].float().to(device)\n",
        "        x_speech = speech[\"pad\"].float().to(device)    # [B,128,289]\n",
        "        accomp = data[2]\n",
        "        x_accomp = accomp[\"acc_pad\"].float().to(device)\n",
        "        x_in = torch.cat([x_speech, x_accomp], dim=1)\n",
        "\n",
        "        real_labels = torch.ones(batch_size, 1, device=device, requires_grad = False)\n",
        "        fake_labels = torch.zeros(batch_size, 1, device=device, requires_grad = False)\n",
        "\n",
        "        ############ START COPIED CODE ######################\n",
        "        acc_np = acc_voc[\"acc_no_pad\"].float().to(device)\n",
        "        voc_np = acc_voc[\"voc_no_pad\"].float().to(device)\n",
        "        speech_np = speech[\"no_pad\"].float().to(device)\n",
        "\n",
        "        # Compute transformations with generators\n",
        "        raw_fake_vocal = generator_vocal(x_in)[\"vocal\"]\n",
        "        fake_vocal = raw_fake_vocal.clone()\n",
        "        fake_vocal_crop = torch.narrow(fake_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        raw_fake_speech = generator_speech(x_voc)[\"speech\"]\n",
        "        fake_speech = raw_fake_speech.clone()\n",
        "        fake_speech_crop = torch.narrow(fake_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Generate reconstructed speech/vocal\n",
        "        fake_vocal_pad = transform_for_gen_2(fake_vocal, input_size_generators)  # you must define this\n",
        "        raw_rec_speech = generator_speech(fake_vocal_pad)[\"speech\"]\n",
        "        rec_speech = raw_rec_speech.clone()\n",
        "        rec_speech_crop = torch.narrow(rec_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        fake_speech_pad = transform_for_gen_2(fake_speech, input_size_generators)  # you must define this\n",
        "        fake_speech_with_acc = torch.cat([fake_speech_pad, x_acc], dim=1)\n",
        "        raw_rec_vocal = generator_vocal(fake_speech_with_acc)[\"vocal\"]\n",
        "        rec_vocal = raw_rec_vocal.clone()\n",
        "        rec_vocal_crop = torch.narrow(rec_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Identity generation\n",
        "        identity_vocal = generator_vocal(torch.cat([x_voc, x_acc], dim=1))[\"vocal\"]\n",
        "        identity_vocal_crop = torch.narrow(identity_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        identity_speech = generator_speech(x_speech)[\"speech\"]\n",
        "        identity_speech_crop = torch.narrow(identity_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Compute losses\n",
        "        pred_real_vocal = discriminator_vocal(voc_np, acc_np)\n",
        "        pred_fake_vocal_D = discriminator_vocal(fake_vocal_crop.detach(), acc_np)\n",
        "        pred_real_speech = discriminator_speech(speech_np)\n",
        "        pred_fake_speech_D = discriminator_speech(fake_speech_crop.detach())\n",
        "\n",
        "        loss_DV_fake = bce_loss(pred_fake_vocal_D, fake_labels)\n",
        "        loss_DV_real = bce_loss(pred_real_vocal, real_labels)\n",
        "        loss_DS_fake = bce_loss(pred_fake_speech_D, fake_labels)\n",
        "        loss_DS_real = bce_loss(pred_real_speech, real_labels)\n",
        "\n",
        "        # Minimizing adv losses is teaching the gens to trick the discs (labels are swapped)\n",
        "        pred_fake_vocal = discriminator_vocal(fake_vocal_crop, acc_np)\n",
        "        pred_fake_speech = discriminator_speech(fake_speech_crop)\n",
        "        loss_adv_vocal = mse_loss(pred_fake_vocal, real_labels)\n",
        "        loss_adv_speech = mse_loss(pred_fake_speech, real_labels)\n",
        "\n",
        "        loss_cycle_vocal = l1_loss(rec_vocal_crop, voc_np)\n",
        "        loss_cycle_speech = l1_loss(rec_speech_crop, speech_np)\n",
        "\n",
        "        loss_identity_vocal = l1_loss(identity_vocal_crop, voc_np)\n",
        "        loss_identity_speech = l1_loss(identity_speech_crop, speech_np)\n",
        "\n",
        "        # NOTE: COULD INCLUDE IDENTITY LOSS\n",
        "\n",
        "        loss_DV = 0.5 * (loss_DV_real + loss_DV_fake)\n",
        "        loss_DS = 0.5 * (loss_DS_real + loss_DS_fake)\n",
        "        loss_GV = (loss_adv_vocal + lambda_cycle * loss_cycle_vocal + lambda_identity * loss_identity_vocal) / (1 + lambda_cycle + lambda_identity)\n",
        "        loss_GS = (loss_adv_speech + lambda_cycle * loss_cycle_speech + lambda_identity * loss_identity_speech) / (1 + lambda_cycle + lambda_identity)\n",
        "\n",
        "#\n",
        "        running_loss_DV = alpha * running_loss_DV + (1 - alpha) * loss_DV.item()\n",
        "        running_loss_DS = alpha * running_loss_DS + (1 - alpha) * loss_DS.item()\n",
        "        \n",
        "        # for p in discriminator_vocal.parameters():   p.requires_grad_(False)\n",
        "        # for p in discriminator_speech.parameters():  p.requires_grad_(False)\n",
        "        # Update generators\n",
        "        ((loss_GV + loss_GS) / virtual_batch_size).backward()\n",
        "\n",
        "\n",
        "        # Record gradients & take steps\n",
        "        if (num_batches + 1) % virtual_batch_size == 0:\n",
        "          # Record gradients\n",
        "          grad_norm = 0.0\n",
        "          count = 0\n",
        "          for p in generator_vocal.parameters():\n",
        "              if p.grad is not None:\n",
        "                  grad_norm += p.grad.norm().item()\n",
        "                  count += 1\n",
        "          if count > 0:\n",
        "              grad_norms_GV.append(grad_norm / count)\n",
        "\n",
        "          grad_norm = 0.0\n",
        "          count = 0\n",
        "          for p in generator_speech.parameters():\n",
        "              if p.grad is not None:\n",
        "                  grad_norm += p.grad.norm().item()\n",
        "                  count += 1\n",
        "          if count > 0:\n",
        "              grad_norms_GS.append(grad_norm / count)\n",
        "\n",
        "          # Take steps\n",
        "          optimizer_GV.step()\n",
        "          optimizer_GS.step()\n",
        "          optimizer_GV.zero_grad()\n",
        "          optimizer_GS.zero_grad()\n",
        "          \n",
        "        # for p in discriminator_vocal.parameters():   p.requires_grad_(True)\n",
        "        # for p in discriminator_speech.parameters():  p.requires_grad_(True)\n",
        "\n",
        "        # Update discriminators\n",
        "        if running_loss_DV > dv_threshold or smart_discriminator:\n",
        "          (loss_DV / virtual_batch_size).backward()\n",
        "          num_DV_backwards += 1\n",
        "          if (num_DV_backwards+1) % virtual_batch_size == 0:\n",
        "            grad_norm = 0.0\n",
        "            count = 0\n",
        "            for p in discriminator_vocal.parameters():\n",
        "                if p.grad is not None:\n",
        "                    grad_norm += p.grad.norm().item()\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                grad_norms_DV.append(grad_norm / count)\n",
        "\n",
        "            optimizer_DV.step()\n",
        "            optimizer_DV.zero_grad()\n",
        "            num_DV_backwards = 0\n",
        "\n",
        "        if running_loss_DS > ds_threshold or smart_discriminator:\n",
        "          (loss_DS / virtual_batch_size).backward()\n",
        "          num_DS_backwards += 1\n",
        "          if (num_DS_backwards+1) % virtual_batch_size == 0:\n",
        "            # record gradients\n",
        "            grad_norm = 0.0\n",
        "            count = 0\n",
        "            for p in discriminator_speech.parameters():\n",
        "                if p.grad is not None:\n",
        "                    grad_norm += p.grad.norm().item()\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                grad_norms_DS.append(grad_norm / count)\n",
        "\n",
        "            optimizer_DS.step()\n",
        "            optimizer_DS.zero_grad()\n",
        "            num_DS_backwards = 0\n",
        "\n",
        "        # Accumulate metrics\n",
        "        total_loss_DV     += loss_DV.item()\n",
        "        total_loss_DS     += loss_DS.item()\n",
        "        total_loss_adv_vocal  += loss_adv_vocal.item()\n",
        "        total_loss_adv_speech += loss_adv_speech.item()\n",
        "        total_loss_cycle_vocal += loss_cycle_vocal.item()\n",
        "        total_loss_cycle_speech += loss_cycle_speech.item()\n",
        "        total_loss_GV_identity += loss_identity_vocal.item()\n",
        "        total_loss_GS_identity += loss_identity_speech.item()\n",
        "        total_loss_GV      += loss_GV.item()\n",
        "        total_loss_GS   += loss_GS.item()\n",
        "        num_batches       += 1\n",
        "        # audio_files = []\n",
        "        # if save_output:\n",
        "        #     fake_singing_list = [fake_crop[i] for i in range(fake_crop.shape[0])]\n",
        "        #     audio_files = convert_to_audio(fake_singing_list)\n",
        "    return {\n",
        "        \"loss_DV\":      total_loss_DV / num_batches,\n",
        "        \"loss_DS\":      total_loss_DS / num_batches,\n",
        "        \"loss_GV\":      total_loss_GV / num_batches,\n",
        "        \"loss_GS\":      total_loss_GS / num_batches,\n",
        "        \"loss_adv_vocal\":  total_loss_adv_vocal / num_batches,\n",
        "        \"loss_adv_speech\":  total_loss_adv_speech / num_batches,\n",
        "        \"loss_cycle_vocal\":  total_loss_cycle_vocal / num_batches,\n",
        "        \"loss_cycle_speech\":  total_loss_cycle_speech / num_batches,\n",
        "        \"loss_identity_vocal\":  total_loss_GV_identity / num_batches,\n",
        "        \"loss_identity_speech\":  total_loss_GS_identity / num_batches,\n",
        "        \"avg_grad_norm_DV\": sum(grad_norms_DV) / len(grad_norms_DV) if grad_norms_DV else 0.0,\n",
        "        \"avg_grad_norm_DS\": sum(grad_norms_DS) / len(grad_norms_DS) if grad_norms_DS else 0.0,\n",
        "        \"avg_grad_norm_GV\": sum(grad_norms_GV) / len(grad_norms_GV) if grad_norms_GV else 0.0,\n",
        "        \"avg_grad_norm_GS\": sum(grad_norms_GS) / len(grad_norms_GS) if grad_norms_GS else 0.0,\n",
        "        \"num_DV_updates\" : len(grad_norms_DV),\n",
        "        \"num_DS_updates\" : len(grad_norms_DS)\n",
        "    }#, audio_files\n",
        "\n",
        "# ----- Multi-Epoch Training Function -----\n",
        "def cycle_train_rand_accomp(\n",
        "    generator_vocal,\n",
        "    generator_speech,\n",
        "    discriminator_vocal,\n",
        "    discriminator_speech,\n",
        "    optimizer_DV,\n",
        "    optimizer_DS,\n",
        "    optimizer_GV,\n",
        "    optimizer_GS,\n",
        "    acc_voc_loader,\n",
        "    speech_loader,\n",
        "    acc_loader,\n",
        "    l1_loss,\n",
        "    mse_loss,\n",
        "    lambda_l1,\n",
        "    lambda_cycle,\n",
        "    lambda_identity,\n",
        "    bce_loss,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    virtual_batch_size,\n",
        "    clip_length,\n",
        "    input_size_generators,\n",
        "    log_dir,\n",
        "    save_audio = True,\n",
        "    smart_discriminator = False,\n",
        "    batch_size = 32,\n",
        "):\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        save_audio = True if epoch == num_epochs-1 else False\n",
        "        print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
        "        epoch_metrics = cycle_train_epoch_rand_accomp(\n",
        "            generator_vocal,\n",
        "            generator_speech,\n",
        "            discriminator_vocal,\n",
        "            discriminator_speech,\n",
        "            optimizer_DV,\n",
        "            optimizer_DS,\n",
        "            optimizer_GV,\n",
        "            optimizer_GS,\n",
        "            acc_voc_loader,\n",
        "            speech_loader,\n",
        "            acc_loader,\n",
        "            l1_loss,\n",
        "            mse_loss,\n",
        "            lambda_l1,\n",
        "            lambda_cycle,\n",
        "            lambda_identity,\n",
        "            bce_loss,\n",
        "            device,\n",
        "            virtual_batch_size,\n",
        "            clip_length,\n",
        "            input_size_generators,\n",
        "            save_output = save_audio,\n",
        "            smart_discriminator = smart_discriminator,\n",
        "            batch_size = batch_size,\n",
        "        )\n",
        "        print(f\"Epoch {epoch+1} Metrics:\")\n",
        "        print(f\"  Loss_DV:         {epoch_metrics['loss_DV']:.4f}\")\n",
        "        print(f\"  Loss_DS:         {epoch_metrics['loss_DS']:.4f}\")\n",
        "        # print(f\"  Loss_GV_total:   {epoch_metrics['loss_GV']:.4f}\")\n",
        "        # print(f\"  Loss_GS_total:   {epoch_metrics['loss_GS']:.4f}\")\n",
        "        print(f\"  Loss_adv_vocal:     {epoch_metrics['loss_adv_vocal']:.4f}\")\n",
        "        print(f\"  Loss_adv_speech:     {epoch_metrics['loss_adv_speech']:.4f}\")\n",
        "        print(f\"  Loss_Cycle Vocal:     {epoch_metrics['loss_cycle_vocal']:.4f}\")\n",
        "        print(f\"  Loss_Cycle Speech:     {epoch_metrics['loss_cycle_speech']:.4f}\")\n",
        "        print(f\"  Loss_Identity Vocal:     {epoch_metrics['loss_identity_vocal']:.4f}\")\n",
        "        print(f\"  Loss_Identity Speech:     {epoch_metrics['loss_identity_speech']:.4f}\")\n",
        "        print(f\"  Grad Norm DV:    {epoch_metrics['avg_grad_norm_DV']:.4f}\")\n",
        "        print(f\"  Grad Norm DS:    {epoch_metrics['avg_grad_norm_DS']:.4f}\")\n",
        "        print(f\"  Grad Norm GV:    {epoch_metrics['avg_grad_norm_GV']:.4f}\")\n",
        "        print(f\"  Grad Norm GS:    {epoch_metrics['avg_grad_norm_GS']:.4f}\")\n",
        "        print(f\"  num_DV_updates:    {epoch_metrics['num_DV_updates']:.4f}\")\n",
        "        print(f\"  num_DS_updates:    {epoch_metrics['num_DS_updates']:.4f}\")\n",
        "\n",
        "        # Log metrics to TensorBoard.\n",
        "        writer.add_scalar(\"Loss/Discriminator\", epoch_metrics[\"loss_DV\"], epoch)\n",
        "        # writer.add_scalar(\"Loss/Generator_total\", epoch_metrics[\"loss_G_total\"], epoch)\n",
        "        writer.add_scalar(\"Loss/Generator_adversarial\", epoch_metrics[\"loss_adv_vocal\"], epoch)\n",
        "        # writer.add_scalar(\"Loss/Generator_L1\", epoch_metrics[\"loss_G_L1\"], epoch)\n",
        "        writer.add_scalar(\"Loss/Cycle\", epoch_metrics[\"loss_cycle_vocal\"], epoch)\n",
        "        writer.add_scalar(\"Gradients/Discriminator\", epoch_metrics[\"avg_grad_norm_DV\"], epoch)\n",
        "        writer.add_scalar(\"Gradients/Generator\", epoch_metrics[\"avg_grad_norm_GV\"], epoch)\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "    writer.close()\n",
        "    return #audio_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y7fEPMaGeMk0"
      },
      "outputs": [],
      "source": [
        "# ----- Single Epoch Training Function -----\n",
        "def cycle_train_epoch(\n",
        "    generator_vocal,\n",
        "    generator_speech,\n",
        "    discriminator_vocal,\n",
        "    discriminator_speech,\n",
        "    optimizer_DV,\n",
        "    optimizer_DS,\n",
        "    optimizer_GV,\n",
        "    optimizer_GS,\n",
        "    acc_voc_loader,\n",
        "    speech_loader,\n",
        "    l1_loss,\n",
        "    mse_loss,\n",
        "    lambda_l1,\n",
        "    lambda_cycle,\n",
        "    lambda_identity,\n",
        "    bce_loss,\n",
        "    device,\n",
        "    virtual_batch_size,\n",
        "    clip_length,\n",
        "    input_size_generators,\n",
        "    save_output=False,\n",
        "    smart_discriminator=False,\n",
        "    batch_size = 32,\n",
        "):\n",
        "\n",
        "    total_loss_DV = total_loss_DS = total_loss_GV = total_loss_GS  = 0\n",
        "    total_loss_GV_identity = total_loss_GS_identity = 0\n",
        "    total_loss_adv_vocal = total_loss_adv_speech = total_loss_cycle_vocal = total_loss_cycle_speech = total_loss_GV_identity = total_loss_GS_identity =  0.0\n",
        "    # Optionally record gradient norms per batch for diagnosing vanishing gradients.\n",
        "    grad_norms_DV = []\n",
        "    grad_norms_DS = []\n",
        "    grad_norms_GV = []\n",
        "    grad_norms_GS = []\n",
        "    num_batches = 0\n",
        "\n",
        "\n",
        "    alpha = 0.9      # Tuneable constant to gate the discriminator training\n",
        "    running_loss_DV = 0.0\n",
        "    running_loss_DS = 0.0\n",
        "    dv_threshold = 0.6\n",
        "    ds_threshold = 0.6\n",
        "\n",
        "    optimizer_DV.zero_grad()\n",
        "    optimizer_DS.zero_grad()\n",
        "    optimizer_GV.zero_grad()\n",
        "    optimizer_GS.zero_grad()\n",
        "\n",
        "    # real_labels = torch.ones(batch_size, 1, device=device, requires_grad = False)\n",
        "    # fake_labels = torch.zeros(batch_size, 1, device=device, requires_grad = False)\n",
        "\n",
        "    num_DV_backwards = num_DS_backwards = 0\n",
        "\n",
        "\n",
        "    loaders = tqdm(zip(acc_voc_loader, speech_loader), desc = \"Training Batches\")\n",
        "\n",
        "    # ---- batch loop ----\n",
        "    for data in loaders:\n",
        "        # Read in data\n",
        "        acc_voc = data[0]\n",
        "        speech = data[1]\n",
        "        x_acc = acc_voc[\"acc_pad\"].float().to(device)       # [B,128,289]\n",
        "        x_voc = acc_voc[\"voc_pad\"].float().to(device)\n",
        "        x_speech = speech[\"pad\"].float().to(device)    # [B,128,289]\n",
        "        x_in = torch.cat([x_speech, x_acc], dim=1)     # [B,256,289]\n",
        "\n",
        "        real_labels = torch.ones(batch_size, 1, device=device, requires_grad = False)\n",
        "        fake_labels = torch.zeros(batch_size, 1, device=device, requires_grad = False)\n",
        "\n",
        "        ############ START COPIED CODE ######################\n",
        "        acc_np = acc_voc[\"acc_no_pad\"].float().to(device)\n",
        "        voc_np = acc_voc[\"voc_no_pad\"].float().to(device)\n",
        "        speech_np = speech[\"no_pad\"].float().to(device)\n",
        "\n",
        "        # Compute transformations with generators\n",
        "        raw_fake_vocal = generator_vocal(x_in)[\"vocal\"]\n",
        "        fake_vocal = raw_fake_vocal.clone()\n",
        "        fake_vocal_crop = torch.narrow(fake_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        raw_fake_speech = generator_speech(x_voc)[\"speech\"]\n",
        "        fake_speech = raw_fake_speech.clone()\n",
        "        fake_speech_crop = torch.narrow(fake_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Generate reconstructed speech/vocal\n",
        "        fake_vocal_pad = transform_for_gen_2(fake_vocal, input_size_generators)  # you must define this\n",
        "        raw_rec_speech = generator_speech(fake_vocal_pad)[\"speech\"]\n",
        "        rec_speech = raw_rec_speech.clone()\n",
        "        rec_speech_crop = torch.narrow(rec_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        fake_speech_pad = transform_for_gen_2(fake_speech, input_size_generators)  # you must define this\n",
        "        fake_speech_with_acc = torch.cat([fake_speech_pad, x_acc], dim=1)\n",
        "        raw_rec_vocal = generator_vocal(fake_speech_with_acc)[\"vocal\"]\n",
        "        rec_vocal = raw_rec_vocal.clone()\n",
        "        rec_vocal_crop = torch.narrow(rec_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Identity generation\n",
        "        identity_vocal = generator_vocal(torch.cat([x_voc, x_acc], dim=1))[\"vocal\"]\n",
        "        identity_vocal_crop = torch.narrow(identity_vocal, 2, 0, clip_length).clone()\n",
        "\n",
        "        identity_speech = generator_speech(x_speech)[\"speech\"]\n",
        "        identity_speech_crop = torch.narrow(identity_speech, 2, 0, clip_length).clone()\n",
        "\n",
        "        # Compute losses\n",
        "        pred_real_vocal = discriminator_vocal(voc_np, acc_np)\n",
        "        pred_fake_vocal_D = discriminator_vocal(fake_vocal_crop.detach(), acc_np)\n",
        "        pred_real_speech = discriminator_speech(speech_np)\n",
        "        pred_fake_speech_D = discriminator_speech(fake_speech_crop.detach())\n",
        "\n",
        "        loss_DV_fake = bce_loss(pred_fake_vocal_D, fake_labels)\n",
        "        loss_DV_real = bce_loss(pred_real_vocal, real_labels)\n",
        "        loss_DS_fake = bce_loss(pred_fake_speech_D, fake_labels)\n",
        "        loss_DS_real = bce_loss(pred_real_speech, real_labels)\n",
        "\n",
        "        # Minimizing adv losses is teaching the gens to trick the discs (labels are swapped)\n",
        "        pred_fake_vocal = discriminator_vocal(fake_vocal_crop, acc_np)\n",
        "        pred_fake_speech = discriminator_speech(fake_speech_crop)\n",
        "        loss_adv_vocal = mse_loss(pred_fake_vocal, real_labels)\n",
        "        loss_adv_speech = mse_loss(pred_fake_speech, real_labels)\n",
        "\n",
        "        loss_cycle_vocal = l1_loss(rec_vocal_crop, voc_np)\n",
        "        loss_cycle_speech = l1_loss(rec_speech_crop, speech_np)\n",
        "\n",
        "        loss_identity_vocal = l1_loss(identity_vocal_crop, voc_np)\n",
        "        loss_identity_speech = l1_loss(identity_speech_crop, speech_np)\n",
        "\n",
        "        # NOTE: COULD INCLUDE IDENTITY LOSS\n",
        "\n",
        "        loss_DV = 0.5 * (loss_DV_real + loss_DV_fake)\n",
        "        loss_DS = 0.5 * (loss_DS_real + loss_DS_fake)\n",
        "        loss_GV = (loss_adv_vocal + lambda_cycle * loss_cycle_vocal + lambda_identity * loss_identity_vocal) / (1 + lambda_cycle + lambda_identity)\n",
        "        loss_GS = (loss_adv_speech + lambda_cycle * loss_cycle_speech + lambda_identity * loss_identity_speech) / (1 + lambda_cycle + lambda_identity)\n",
        "\n",
        "#\n",
        "        running_loss_DV = alpha * running_loss_DV + (1 - alpha) * loss_DV.item()\n",
        "        running_loss_DS = alpha * running_loss_DS + (1 - alpha) * loss_DS.item()\n",
        "\n",
        "\n",
        "        # Update generators\n",
        "        ((loss_GV + loss_GS) / virtual_batch_size).backward()\n",
        "\n",
        "\n",
        "        # Record gradients & take steps\n",
        "        if (num_batches + 1) % virtual_batch_size == 0:\n",
        "          # Record gradients\n",
        "          grad_norm = 0.0\n",
        "          count = 0\n",
        "          for p in generator_vocal.parameters():\n",
        "              if p.grad is not None:\n",
        "                  grad_norm += p.grad.norm().item()\n",
        "                  count += 1\n",
        "          if count > 0:\n",
        "              grad_norms_GV.append(grad_norm / count)\n",
        "\n",
        "          grad_norm = 0.0\n",
        "          count = 0\n",
        "          for p in generator_speech.parameters():\n",
        "              if p.grad is not None:\n",
        "                  grad_norm += p.grad.norm().item()\n",
        "                  count += 1\n",
        "          if count > 0:\n",
        "              grad_norms_GS.append(grad_norm / count)\n",
        "\n",
        "          # Take steps\n",
        "          optimizer_GV.step()\n",
        "          optimizer_GS.step()\n",
        "          optimizer_GV.zero_grad()\n",
        "          optimizer_GS.zero_grad()\n",
        "\n",
        "\n",
        "        # Update discriminators\n",
        "        if running_loss_DV > dv_threshold or smart_discriminator:\n",
        "          (loss_DV / virtual_batch_size).backward()\n",
        "          num_DV_backwards += 1\n",
        "          if (num_DV_backwards+1) % virtual_batch_size == 0:\n",
        "            grad_norm = 0.0\n",
        "            count = 0\n",
        "            for p in discriminator_vocal.parameters():\n",
        "                if p.grad is not None:\n",
        "                    grad_norm += p.grad.norm().item()\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                grad_norms_DV.append(grad_norm / count)\n",
        "\n",
        "            optimizer_DV.step()\n",
        "            optimizer_DV.zero_grad()\n",
        "            num_DV_backwards = 0\n",
        "\n",
        "        if running_loss_DS > ds_threshold or smart_discriminator:\n",
        "          (loss_DS / virtual_batch_size).backward()\n",
        "          num_DS_backwards += 1\n",
        "          if (num_DS_backwards+1) % virtual_batch_size == 0:\n",
        "            # record gradients\n",
        "            grad_norm = 0.0\n",
        "            count = 0\n",
        "            for p in discriminator_speech.parameters():\n",
        "                if p.grad is not None:\n",
        "                    grad_norm += p.grad.norm().item()\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                grad_norms_DS.append(grad_norm / count)\n",
        "\n",
        "            optimizer_DS.step()\n",
        "            optimizer_DS.zero_grad()\n",
        "            num_DS_backwards = 0\n",
        "\n",
        "        # Accumulate metrics\n",
        "        total_loss_DV     += loss_DV.item()\n",
        "        total_loss_DS     += loss_DS.item()\n",
        "        total_loss_adv_vocal  += loss_adv_vocal.item()\n",
        "        total_loss_adv_speech += loss_adv_speech.item()\n",
        "        total_loss_cycle_vocal += loss_cycle_vocal.item()\n",
        "        total_loss_cycle_speech += loss_cycle_speech.item()\n",
        "        total_loss_GV_identity += loss_identity_vocal.item()\n",
        "        total_loss_GS_identity += loss_identity_speech.item()\n",
        "        total_loss_GV      += loss_GV.item()\n",
        "        total_loss_GS   += loss_GS.item()\n",
        "        num_batches       += 1\n",
        "        # audio_files = []\n",
        "        # if save_output:\n",
        "        #     fake_singing_list = [fake_crop[i] for i in range(fake_crop.shape[0])]\n",
        "        #     audio_files = convert_to_audio(fake_singing_list)\n",
        "    return {\n",
        "        \"loss_DV\":      total_loss_DV / num_batches,\n",
        "        \"loss_DS\":      total_loss_DS / num_batches,\n",
        "        \"loss_GV\":      total_loss_GV / num_batches,\n",
        "        \"loss_GS\":      total_loss_GS / num_batches,\n",
        "        \"loss_adv_vocal\":  total_loss_adv_vocal / num_batches,\n",
        "        \"loss_adv_speech\":  total_loss_adv_speech / num_batches,\n",
        "        \"loss_cycle_vocal\":  total_loss_cycle_vocal / num_batches,\n",
        "        \"loss_cycle_speech\":  total_loss_cycle_speech / num_batches,\n",
        "        \"loss_identity_vocal\":  total_loss_GV_identity / num_batches,\n",
        "        \"loss_identity_speech\":  total_loss_GS_identity / num_batches,\n",
        "        \"avg_grad_norm_DV\": sum(grad_norms_DV) / len(grad_norms_DV) if grad_norms_DV else 0.0,\n",
        "        \"avg_grad_norm_DS\": sum(grad_norms_DS) / len(grad_norms_DS) if grad_norms_DS else 0.0,\n",
        "        \"avg_grad_norm_GV\": sum(grad_norms_GV) / len(grad_norms_GV) if grad_norms_GV else 0.0,\n",
        "        \"avg_grad_norm_GS\": sum(grad_norms_GS) / len(grad_norms_GS) if grad_norms_GS else 0.0,\n",
        "        \"num_DV_updates\" : len(grad_norms_DV),\n",
        "        \"num_DS_updates\" : len(grad_norms_DS)\n",
        "    }#, audio_files\n",
        "\n",
        "# ----- Multi-Epoch Training Function -----\n",
        "def cycle_train(\n",
        "    generator_vocal,\n",
        "    generator_speech,\n",
        "    discriminator_vocal,\n",
        "    discriminator_speech,\n",
        "    optimizer_DV,\n",
        "    optimizer_DS,\n",
        "    optimizer_GV,\n",
        "    optimizer_GS,\n",
        "    acc_voc_loader,\n",
        "    speech_loader,\n",
        "    l1_loss,\n",
        "    mse_loss,\n",
        "    lambda_l1,\n",
        "    lambda_cycle,\n",
        "    lambda_identity,\n",
        "    bce_loss,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    virtual_batch_size,\n",
        "    clip_length,\n",
        "    input_size_generators,\n",
        "    log_dir,\n",
        "    save_audio = True,\n",
        "    smart_discriminator = False,\n",
        "    batch_size = 32,\n",
        "):\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        save_audio = True if epoch == num_epochs-1 else False\n",
        "        print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
        "        epoch_metrics = cycle_train_epoch(\n",
        "            generator_vocal,\n",
        "            generator_speech,\n",
        "            discriminator_vocal,\n",
        "            discriminator_speech,\n",
        "            optimizer_DV,\n",
        "            optimizer_DS,\n",
        "            optimizer_GV,\n",
        "            optimizer_GS,\n",
        "            acc_voc_loader,\n",
        "            speech_loader,\n",
        "            l1_loss,\n",
        "            mse_loss,\n",
        "            lambda_l1,\n",
        "            lambda_cycle,\n",
        "            lambda_identity,\n",
        "            bce_loss,\n",
        "            device,\n",
        "            virtual_batch_size,\n",
        "            clip_length,\n",
        "            input_size_generators,\n",
        "            save_output = save_audio,\n",
        "            smart_discriminator = smart_discriminator,\n",
        "            batch_size = batch_size,\n",
        "        )\n",
        "        print(f\"Epoch {epoch+1} Metrics:\")\n",
        "        print(f\"  Loss_DV:         {epoch_metrics['loss_DV']:.4f}\")\n",
        "        print(f\"  Loss_DS:         {epoch_metrics['loss_DS']:.4f}\")\n",
        "        # print(f\"  Loss_GV_total:   {epoch_metrics['loss_GV']:.4f}\")\n",
        "        # print(f\"  Loss_GS_total:   {epoch_metrics['loss_GS']:.4f}\")\n",
        "        print(f\"  Loss_adv_vocal:     {epoch_metrics['loss_adv_vocal']:.4f}\")\n",
        "        print(f\"  Loss_adv_speech:     {epoch_metrics['loss_adv_speech']:.4f}\")\n",
        "        print(f\"  Loss_Cycle Vocal:     {epoch_metrics['loss_cycle_vocal']:.4f}\")\n",
        "        print(f\"  Loss_Cycle Speech:     {epoch_metrics['loss_cycle_speech']:.4f}\")\n",
        "        print(f\"  Loss_Identity Vocal:     {epoch_metrics['loss_identity_vocal']:.4f}\")\n",
        "        print(f\"  Loss_Identity Speech:     {epoch_metrics['loss_identity_speech']:.4f}\")\n",
        "        print(f\"  Grad Norm DV:    {epoch_metrics['avg_grad_norm_DV']:.4f}\")\n",
        "        print(f\"  Grad Norm DS:    {epoch_metrics['avg_grad_norm_DS']:.4f}\")\n",
        "        print(f\"  Grad Norm GV:    {epoch_metrics['avg_grad_norm_GV']:.4f}\")\n",
        "        print(f\"  Grad Norm GS:    {epoch_metrics['avg_grad_norm_GS']:.4f}\")\n",
        "        print(f\"  num_DV_updates:    {epoch_metrics['num_DV_updates']:.4f}\")\n",
        "        print(f\"  num_DS_updates:    {epoch_metrics['num_DS_updates']:.4f}\")\n",
        "\n",
        "        # Log metrics to TensorBoard.\n",
        "        writer.add_scalar(\"Loss/Discriminator\", epoch_metrics[\"loss_DV\"], epoch)\n",
        "        # writer.add_scalar(\"Loss/Generator_total\", epoch_metrics[\"loss_G_total\"], epoch)\n",
        "        writer.add_scalar(\"Loss/Generator_adversarial\", epoch_metrics[\"loss_adv_vocal\"], epoch)\n",
        "        # writer.add_scalar(\"Loss/Generator_L1\", epoch_metrics[\"loss_G_L1\"], epoch)\n",
        "        writer.add_scalar(\"Loss/Cycle\", epoch_metrics[\"loss_cycle_vocal\"], epoch)\n",
        "        writer.add_scalar(\"Gradients/Discriminator\", epoch_metrics[\"avg_grad_norm_DV\"], epoch)\n",
        "        writer.add_scalar(\"Gradients/Generator\", epoch_metrics[\"avg_grad_norm_GV\"], epoch)\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "    writer.close()\n",
        "    return #audio_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6YYjPW1qo_f"
      },
      "source": [
        "## Variable dataset\n",
        "By default we train shorter models on colab and longer models in a docker container on a local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "21sTx3lXqo_f"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "    path = \"/content/drive/My Drive/git_projects/spring_2025_dl_audio_project_data/\"\n",
        "else:\n",
        "    path = \"/workspace/hdd_project_data/\"\n",
        "\n",
        "# Dataset paths for short clips\n",
        "if colab:\n",
        "    librispeech_data = \"LibriSpeechDataset_withOverlap.pt\"\n",
        "    musdb_data = \"musdb_noOverlap_test.pt\"\n",
        "else:\n",
        "    # librispeech_data = \"librispeech_longClip_train_small.pt\"\n",
        "    # musdb_data = \"musdb_longClip_train.pt\"\n",
        "    librispeech_data = \"LibriSpeechDataset_withOverlap.pt\"\n",
        "    musdb_data = \"musdb_noOverlap_test.pt\"\n",
        "\n",
        "librispeechDataset_path = path + librispeech_data\n",
        "musdbDataset_path = path + musdb_data\n",
        "\n",
        "librispeech_dataset = torch.load(librispeechDataset_path, weights_only=False)\n",
        "musdb_dataset = torch.load(musdbDataset_path, weights_only=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PNUZyJubqo_f"
      },
      "outputs": [],
      "source": [
        "# Because of the way the librispeech dataset was constructed, it is slightly longer\n",
        "# than the musbd dataset. Crop the librispeech dataset with these lines\n",
        "librispeech_dataset.mel_specs = librispeech_dataset.mel_specs[0:len(musdb_dataset)]\n",
        "librispeech_dataset.sample_rates = librispeech_dataset.sample_rates[0:len(musdb_dataset)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68JIKFsnqo_f"
      },
      "source": [
        "### Record length of clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaN9YGVpqo_g",
        "outputId": "f4c32e17-ef48-4feb-bbd2-6cfedb048d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== MusDB Dataset Exploration ===\n",
            "Length: 4167\n",
            "mel_specs shape: torch.Size([4167, 2, 128, 256])\n",
            "sample_rates shape: torch.Size([4167])\n",
            "\n",
            "Sample 0 - Accompaniment shape: torch.Size([128, 256])\n",
            "Sample 0 - Vocal shape: torch.Size([128, 256])\n",
            "Sample 0 - Sample rate: tensor(44100)\n",
            "\n",
            "=== LibriSpeech Dataset Exploration ===\n",
            "Length: 4167\n",
            "mel_specs shape: torch.Size([4167, 128, 256])\n",
            "sample_rates shape: torch.Size([4167])\n",
            "\n",
            "Sample 0 - Speech shape: torch.Size([128, 256])\n",
            "Sample 0 - Sample rate: tensor(44100)\n",
            "\n",
            "=========================\n",
            "Training clip length: 256\n"
          ]
        }
      ],
      "source": [
        "# --- Explore the Datasets ---\n",
        "print(\"=== MusDB Dataset Exploration ===\")\n",
        "print(\"Length:\", len(musdb_dataset))\n",
        "print(\"mel_specs shape:\", musdb_dataset.mel_specs.shape)\n",
        "print(\"sample_rates shape:\", musdb_dataset.sample_rates.shape)\n",
        "print()\n",
        "accompaniment, vocal, sample_rate = musdb_dataset[0]\n",
        "print(\"Sample 0 - Accompaniment shape:\", accompaniment.size())\n",
        "print(\"Sample 0 - Vocal shape:\", vocal.size())\n",
        "print(\"Sample 0 - Sample rate:\", sample_rate)\n",
        "print()\n",
        "\n",
        "print(\"=== LibriSpeech Dataset Exploration ===\")\n",
        "print(\"Length:\", len(librispeech_dataset))\n",
        "print(\"mel_specs shape:\", librispeech_dataset.mel_specs.shape)\n",
        "print(\"sample_rates shape:\", librispeech_dataset.sample_rates.shape)\n",
        "print()\n",
        "speech, sample_rate = librispeech_dataset[0]\n",
        "print(\"Sample 0 - Speech shape:\", speech.size())\n",
        "print(\"Sample 0 - Sample rate:\", sample_rate)\n",
        "\n",
        "musdb_length = musdb_dataset.mel_specs.shape[-1]\n",
        "librispeech_length = librispeech_dataset.mel_specs.shape[-1]\n",
        "\n",
        "if musdb_length == librispeech_length:\n",
        "    clip_length = musdb_length\n",
        "else:\n",
        "    raise ValueError(\"The lengths of the datasets do not match. Please check the dataset lengths.\")\n",
        "print()\n",
        "print(\"=========================\")\n",
        "print(\"Training clip length:\", clip_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ6VJupIqo_h"
      },
      "source": [
        "## Initialize Generator Models\n",
        "We initilaze generator models so we can find the necessary padding for the loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7__Bvn7qo_h",
        "outputId": "c8c92d4a-9636-4dde-ca0d-11c020905f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using valid convolutions with 289 inputs and 257 outputs\n",
            "Using valid convolutions with 289 inputs and 257 outputs\n",
            "Input size for generators: 289\n",
            "Output size for generators: 257\n"
          ]
        }
      ],
      "source": [
        "# Model configurations for generator and generator_2.\n",
        "model_config_gen_vocal= {\n",
        "    \"num_inputs\": 256,  # Two spectrograms concatenated (2 * 128 mel bins)\n",
        "    \"num_outputs\": 128,\n",
        "    \"num_channels\": [512*2, 512*4, 512*8],\n",
        "    \"instruments\": [\"vocal\"],\n",
        "    \"kernel_size\": 3,\n",
        "    \"target_output_size\": clip_length,\n",
        "    \"conv_type\": \"normal\",\n",
        "    \"res\": \"fixed\",\n",
        "    \"separate\": False,\n",
        "    \"depth\": 1,\n",
        "    \"strides\": 2\n",
        "}\n",
        "\n",
        "model_config_gen_speech = {\n",
        "    \"num_inputs\": 128,  # One spectrogram input\n",
        "    \"num_outputs\": 128,\n",
        "    \"num_channels\": [256*2, 256*4, 256*8],\n",
        "    \"instruments\": [\"speech\"],\n",
        "    \"kernel_size\": 3,\n",
        "    \"target_output_size\": clip_length,\n",
        "    \"conv_type\": \"normal\",\n",
        "    \"res\": \"fixed\",\n",
        "    \"separate\": False,\n",
        "    \"depth\": 1,\n",
        "    \"strides\": 2\n",
        "}\n",
        "generator_vocal = Waveunet(**model_config_gen_vocal).to(device)\n",
        "generator_speech = Waveunet(**model_config_gen_speech).to(device)\n",
        "\n",
        "input_size_generators = generator_vocal.input_size\n",
        "output_size_generators = generator_vocal.output_size\n",
        "print(\"Input size for generators:\", input_size_generators)\n",
        "print(\"Output size for generators:\", output_size_generators)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQgk_uArqo_h"
      },
      "source": [
        "### Create dataloader\n",
        "We create the dataloaders for the training loop using the correct input_size for the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2ZkE_8bPqo_h"
      },
      "outputs": [],
      "source": [
        "# Define batch size, virtual batch size, and the number of workers for DataLoaders\n",
        "batch_size = 64  # Change as needed\n",
        "target_virtual_batch_size = 256\n",
        "num_workers = 1\n",
        "\n",
        "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = \"runs/\" + \"cycleGAN_experiment_\" + now\n",
        "\n",
        "if target_virtual_batch_size % batch_size != 0:\n",
        "    raise ValueError(\"virtual_batch_size must be a multiple of batch_size.\")\n",
        "else:\n",
        "    virtual_batch_size = target_virtual_batch_size // batch_size\n",
        "\n",
        "# ---------------- hyper‑parameters in ONE place ----------------\n",
        "train_parameters = {\n",
        "    # data loaders\n",
        "    \"batch_size\":     batch_size,\n",
        "    \"virtual_batch_size\": virtual_batch_size,\n",
        "    \"num_workers\":    num_workers,\n",
        "    \"clip_length\": clip_length,\n",
        "    \"input_size_generators\":    input_size_generators,\n",
        "    \"random_accomp\": True,\n",
        "\n",
        "    # optimisation\n",
        "    \"lr_G\":          1e-4,\n",
        "    \"lr_G2\":         1e-4,\n",
        "    \"lr_D\":          1e-4,\n",
        "    \"betas\":         (0.9, 0.999),\n",
        "\n",
        "    # loss weights\n",
        "    \"lambda_l1\":     1,\n",
        "    \"lambda_cycle\": .001,\n",
        "    \"lambda_identity\": 0.00001,\n",
        "\n",
        "    # schedule\n",
        "    \"num_epochs\":    50,\n",
        "\n",
        "    # bookkeeping\n",
        "    \"log_dir\":       f\"runs/cycleGAN_experiment_{now}\",\n",
        "    \"model_dir\":     \"models\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yeJf-5wcqo_h"
      },
      "outputs": [],
      "source": [
        "################ DO WE WANT TO SHUFFLE THE DATASETS? ################\n",
        "\n",
        "# Create data loaders\n",
        "acc_voc_loader = DataLoader(\n",
        "    AccompanimentVocalData(musdb_dataset, output_length=input_size_generators),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    # num_workers=num_workers,\n",
        "    # pin_memory=True,\n",
        "    # persistent_workers=True\n",
        ")\n",
        "\n",
        "speech_loader = DataLoader(\n",
        "    SpeechData(librispeech_dataset, output_length=input_size_generators),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    # num_workers=num_workers,\n",
        "    # pin_memory=True,\n",
        "    # persistent_workers=True\n",
        ")\n",
        "\n",
        "acc_loader = DataLoader(\n",
        "    AccompanimentData(musdb_dataset, output_length=input_size_generators),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    # num_workers=num_workers,\n",
        "    # pin_memory=True,\n",
        "    # persistent_workers=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBr9vgsBqo_h"
      },
      "source": [
        "### Initialize Discriminator Models\n",
        "We initialize the discriminator models and call ``fit_rocket``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phkEdf7rSckQ",
        "outputId": "0ea81190-15fe-450a-b9f2-1110db47918f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores: 24\n",
            "\n",
            "Fitting discriminator_vocal...\n",
            "MiniRocket fitted. Feature dimension: 9996\n",
            "\n",
            "Fitting discriminator_speech...\n",
            "MiniRocket fitted. Feature dimension: 9996\n"
          ]
        }
      ],
      "source": [
        "# check the number of cores\n",
        "import multiprocessing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "print(\"Number of CPU cores:\", num_cores)\n",
        "\n",
        "################ DO WE WANT BOTH DISCRIMINATORS TO USE ALL THE CORES ###############\n",
        "# The discriminators will not be running at the same time,\n",
        "# so it seems safe to give them both more than half the cores.\n",
        "minirocket_n_jobs = num_cores-4\n",
        "\n",
        "# Instantiate the discriminators.\n",
        "discriminator_vocal = TsaiMiniRocketDiscriminator(freq_bins = 128,\n",
        "                                                   hidden_dim = 512,).to(device)\n",
        "discriminator_speech = TsaiMiniRocketDiscriminator(freq_bins = 128,\n",
        "                                                   hidden_dim = 512,\n",
        "                                                   accompaniment = False).to(device)\n",
        "\n",
        "# Optionally, prepare the discriminator (e.g., pre-fitting on some speech data).\n",
        "acc_voc_batch = next(iter(acc_voc_loader))\n",
        "speech_batch = next(iter(speech_loader))[\"no_pad\"]\n",
        "\n",
        "print()\n",
        "print(\"Fitting discriminator_vocal...\")\n",
        "discriminator_vocal.fit_rocket(speech_batch)\n",
        "print()\n",
        "print(\"Fitting discriminator_speech...\")\n",
        "discriminator_speech.fit_rocket(speech_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K93BNsp5qo_i"
      },
      "outputs": [],
      "source": [
        "# Loss functions.\n",
        "bce_loss = nn.BCELoss().to(device)\n",
        "l1_loss = nn.L1Loss().to(device)\n",
        "mse_loss = nn.MSELoss().to(device)\n",
        "\n",
        "# Optimizers.\n",
        "optimizer_GV  = optim.Adam(generator_vocal.parameters(),  lr=train_parameters[\"lr_G\"],  betas=train_parameters[\"betas\"])\n",
        "optimizer_GS = optim.Adam(generator_speech.parameters(), lr=train_parameters[\"lr_G2\"], betas=train_parameters[\"betas\"])\n",
        "optimizer_DV  = optim.Adam(discriminator_vocal.parameters(), lr=train_parameters[\"lr_D\"], betas=train_parameters[\"betas\"])\n",
        "optimizer_DS  = optim.Adam(discriminator_speech.parameters(), lr=train_parameters[\"lr_D\"], betas=train_parameters[\"betas\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IrrtFAj8Tjlv"
      },
      "outputs": [],
      "source": [
        "# Clear the CUDA cache to free up memory. Sometimes PyTorch doesn't release memory immediately.\n",
        "# This can help prevent out-of-memory errors.\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IVbczkbqqo_i"
      },
      "outputs": [],
      "source": [
        "## Optionally load a model checkpoint #####\n",
        "# NEED TO ADD SECOND DISCRIMINATOR IF WE END UP LOADING A MODEL\n",
        "\n",
        "# state_time = \"20250424-233102\"\n",
        "# model_dir  = \"models\"\n",
        "\n",
        "# # ----  load the raw weight dictionaries ----\n",
        "# disc_speech_state = torch.load(f\"{model_dir}/discriminator_speech_state_dict_{state_time}.pt\", map_location=device)\n",
        "# disc_vocal_state = torch.load(f\"{model_dir}/discriminator_vocal_state_dict_{state_time}.pt\", map_location=device)\n",
        "# gen_speech_state  = torch.load(f\"{model_dir}/generator_state_speech_dict_{state_time}.pt\",         map_location=device)\n",
        "# gen_vocal_state = torch.load(f\"{model_dir}/generator_state_vocal_dict_{state_time}.pt\",       map_location=device)\n",
        "\n",
        "# # ----   rebuild the model objects ----\n",
        "# discriminator_vocal = TsaiMiniRocketDiscriminator().to(device)\n",
        "# discriminator_speech = TsaiMiniRocketDiscriminator(freq_bins = 128,\n",
        "#                                                    hidden_dim = 512,\n",
        "#                                                    accompaniment = False).to(device)\n",
        "\n",
        "\n",
        "# generator_vocal     = Waveunet(**model_config_gen_vocal).to(device)\n",
        "# generator_speech   = Waveunet(**model_config_gen_speech).to(device)\n",
        "\n",
        "# # ---- load the weights into those models ----\n",
        "# discriminator_speech.load_state_dict(disc_speech_state)\n",
        "# discriminator_vocal.load_state_dict(disc_vocal_state)\n",
        "# generator_speech.load_state_dict(gen_speech_state)\n",
        "# generator_vocal.load_state_dict(gen_vocal_state)\n",
        "\n",
        "# print(now)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqBLylPoqo_i"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "collapsed": true,
        "id": "PWajAnHDMunt",
        "outputId": "053d4572-d948-4d2a-db9e-d63bf72463c4"
      },
      "outputs": [],
      "source": [
        "# cycle_train_epoch_rand_accomp = torch.compile(cycle_train_epoch_rand_accomp, mode=\"default\")\n",
        "\n",
        "# # # Start training.\n",
        "# # audio_files = cycle_train(\n",
        "# #     generator_vocal,\n",
        "# #     generator_speech,\n",
        "# #     discriminator_vocal,\n",
        "# #     discriminator_speech,\n",
        "# #     optimizer_DV,\n",
        "# #     optimizer_DS,\n",
        "# #     optimizer_GV,\n",
        "# #     optimizer_GS,\n",
        "# #     accompaniment_loader,\n",
        "# #     vocal_loader,\n",
        "# #     speech_loader,\n",
        "# #     l1_loss,\n",
        "# #     train_parameters[\"lambda_l1\"],\n",
        "# #     train_parameters[\"lambda_cycle\"],\n",
        "# #     adversarial_loss,\n",
        "# #     device,\n",
        "# #     num_epochs          = train_parameters[\"num_epochs\"],\n",
        "# #     virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "# #     log_dir             = train_parameters[\"log_dir\"],\n",
        "# #     clip_length = train_parameters[\"clip_length\"],\n",
        "# #     input_size_generators = train_parameters[\"input_size_generators\"],\n",
        "# # )\n",
        "\n",
        "# audio_files = cycle_train_rand_accomp(\n",
        "#     generator_vocal,\n",
        "#     generator_speech,\n",
        "#     discriminator_vocal,\n",
        "#     discriminator_speech,\n",
        "#     optimizer_DV,\n",
        "#     optimizer_DS,\n",
        "#     optimizer_GV,\n",
        "#     optimizer_GS,\n",
        "#     acc_voc_loader,\n",
        "#     speech_loader,\n",
        "#     acc_loader,\n",
        "#     l1_loss,\n",
        "#     mse_loss,\n",
        "#     train_parameters[\"lambda_l1\"],\n",
        "#     train_parameters[\"lambda_cycle\"],\n",
        "#     train_parameters[\"lambda_identity\"],\n",
        "#     bce_loss,\n",
        "#     device,\n",
        "#     num_epochs          = train_parameters[\"num_epochs\"],\n",
        "#     virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "#     log_dir             = train_parameters[\"log_dir\"],\n",
        "#     clip_length = train_parameters[\"clip_length\"],\n",
        "#     input_size_generators = train_parameters[\"input_size_generators\"],\n",
        "#     batch_size = train_parameters[\"batch_size\"]\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # assert False\n",
        "# path = \"models/\"\n",
        "# torch.save(generator_vocal.state_dict(), path + \"generator_state_vocal_dict_\" + now + \".pt\")\n",
        "# torch.save(generator_speech.state_dict(), path + \"generator_state_speech_dict_\" + now + \".pt\")\n",
        "# torch.save(discriminator_speech.state_dict(), path + \"discriminator_speech_state_dict_\" + now + \".pt\")\n",
        "# torch.save(discriminator_vocal.state_dict(), path + \"discriminator_vocal_state_dict_\" + now + \".pt\")\n",
        "\n",
        "# # ------------- package everything to save -------------\n",
        "# export_dict = {\n",
        "#     \"train_parameters\": train_parameters,\n",
        "#     \"model_config_gen_speech\": model_config_gen_speech,      # Wave‑U‑Net (speech+accomp → vocal)\n",
        "#     \"model_config_gen_vocal\": model_config_gen_vocal,    # Wave‑U‑Net (vocal → speech)\n",
        "# }\n",
        "# import json\n",
        "\n",
        "# # (optional) ensure JSON‑serialisable: convert tuples → lists\n",
        "# def _convert(obj):\n",
        "#     if isinstance(obj, tuple):\n",
        "#         return list(obj)\n",
        "#     if isinstance(obj, dict):\n",
        "#         return {k: _convert(v) for k, v in obj.items()}\n",
        "#     if isinstance(obj, list):\n",
        "#         return [_convert(x) for x in obj]\n",
        "#     return obj\n",
        "\n",
        "# export_dict = _convert(export_dict)\n",
        "\n",
        "# with open(f\"{path}/training_record_{now}.json\", \"w\") as fp:\n",
        "#     json.dump(export_dict, fp, indent=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "MuLveiJ9rStq",
        "outputId": "b046852d-9077-48bc-d1d1-8b7e8df574f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:16,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.7512\n",
            "  Loss_DS:         0.7336\n",
            "  Loss_adv_vocal:     0.1735\n",
            "  Loss_adv_speech:     0.1649\n",
            "  Loss_Cycle Vocal:     23.5501\n",
            "  Loss_Cycle Speech:     26.3075\n",
            "  Loss_Identity Vocal:     30.0653\n",
            "  Loss_Identity Speech:     29.2166\n",
            "  Grad Norm DV:    0.7523\n",
            "  Grad Norm DS:    0.9174\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0046\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    14.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:15,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.7515\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1154\n",
            "  Loss_adv_speech:     0.1992\n",
            "  Loss_Cycle Vocal:     9.1575\n",
            "  Loss_Cycle Speech:     10.5017\n",
            "  Loss_Identity Vocal:     15.4101\n",
            "  Loss_Identity Speech:     14.6025\n",
            "  Grad Norm DV:    0.3659\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0060\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:14,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.7417\n",
            "  Loss_DS:         0.6545\n",
            "  Loss_adv_vocal:     0.1087\n",
            "  Loss_adv_speech:     0.1538\n",
            "  Loss_Cycle Vocal:     7.3917\n",
            "  Loss_Cycle Speech:     8.8523\n",
            "  Loss_Identity Vocal:     10.1300\n",
            "  Loss_Identity Speech:     11.9215\n",
            "  Grad Norm DV:    0.1464\n",
            "  Grad Norm DS:    1.3821\n",
            "  Grad Norm GV:    0.0035\n",
            "  Grad Norm GS:    0.0041\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    7.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:14,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.7379\n",
            "  Loss_DS:         0.7572\n",
            "  Loss_adv_vocal:     0.1093\n",
            "  Loss_adv_speech:     0.0862\n",
            "  Loss_Cycle Vocal:     6.5361\n",
            "  Loss_Cycle Speech:     8.5947\n",
            "  Loss_Identity Vocal:     7.6687\n",
            "  Loss_Identity Speech:     10.6504\n",
            "  Grad Norm DV:    0.1896\n",
            "  Grad Norm DS:    0.2796\n",
            "  Grad Norm GV:    0.0022\n",
            "  Grad Norm GS:    0.0019\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    18.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:15,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.7327\n",
            "  Loss_DS:         0.6357\n",
            "  Loss_adv_vocal:     0.1095\n",
            "  Loss_adv_speech:     0.1449\n",
            "  Loss_Cycle Vocal:     6.0047\n",
            "  Loss_Cycle Speech:     8.3001\n",
            "  Loss_Identity Vocal:     7.1417\n",
            "  Loss_Identity Speech:     9.9419\n",
            "  Grad Norm DV:    0.1899\n",
            "  Grad Norm DS:    0.3473\n",
            "  Grad Norm GV:    0.0032\n",
            "  Grad Norm GS:    0.0041\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    11.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:14,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.7217\n",
            "  Loss_DS:         0.6723\n",
            "  Loss_adv_vocal:     0.1125\n",
            "  Loss_adv_speech:     0.1073\n",
            "  Loss_Cycle Vocal:     5.7884\n",
            "  Loss_Cycle Speech:     7.5534\n",
            "  Loss_Identity Vocal:     7.2712\n",
            "  Loss_Identity Speech:     9.2429\n",
            "  Grad Norm DV:    0.2038\n",
            "  Grad Norm DS:    0.2866\n",
            "  Grad Norm GV:    0.0052\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    14.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:15,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.7063\n",
            "  Loss_DS:         0.6351\n",
            "  Loss_adv_vocal:     0.1167\n",
            "  Loss_adv_speech:     0.1257\n",
            "  Loss_Cycle Vocal:     5.7994\n",
            "  Loss_Cycle Speech:     6.8482\n",
            "  Loss_Identity Vocal:     6.9715\n",
            "  Loss_Identity Speech:     8.8479\n",
            "  Grad Norm DV:    0.2694\n",
            "  Grad Norm DS:    0.2836\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0087\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:15,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.6947\n",
            "  Loss_DS:         0.6407\n",
            "  Loss_adv_vocal:     0.1191\n",
            "  Loss_adv_speech:     0.1210\n",
            "  Loss_Cycle Vocal:     5.5142\n",
            "  Loss_Cycle Speech:     6.2866\n",
            "  Loss_Identity Vocal:     6.6864\n",
            "  Loss_Identity Speech:     8.7532\n",
            "  Grad Norm DV:    0.3108\n",
            "  Grad Norm DS:    0.3640\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0081\n",
            "  num_DV_updates:    14.0000\n",
            "  num_DS_updates:    11.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:15,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.6808\n",
            "  Loss_DS:         0.6410\n",
            "  Loss_adv_vocal:     0.1192\n",
            "  Loss_adv_speech:     0.1177\n",
            "  Loss_Cycle Vocal:     5.2513\n",
            "  Loss_Cycle Speech:     5.9302\n",
            "  Loss_Identity Vocal:     6.3784\n",
            "  Loss_Identity Speech:     8.4457\n",
            "  Grad Norm DV:    0.2678\n",
            "  Grad Norm DS:    0.3024\n",
            "  Grad Norm GV:    0.0055\n",
            "  Grad Norm GS:    0.0058\n",
            "  num_DV_updates:    14.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:13,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.6723\n",
            "  Loss_DS:         0.6280\n",
            "  Loss_adv_vocal:     0.1192\n",
            "  Loss_adv_speech:     0.1238\n",
            "  Loss_Cycle Vocal:     5.1791\n",
            "  Loss_Cycle Speech:     5.8616\n",
            "  Loss_Identity Vocal:     6.0588\n",
            "  Loss_Identity Speech:     8.1331\n",
            "  Grad Norm DV:    0.3421\n",
            "  Grad Norm DS:    0.3845\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    10.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:13,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.6641\n",
            "  Loss_DS:         0.6426\n",
            "  Loss_adv_vocal:     0.1203\n",
            "  Loss_adv_speech:     0.1145\n",
            "  Loss_Cycle Vocal:     5.0166\n",
            "  Loss_Cycle Speech:     5.7453\n",
            "  Loss_Identity Vocal:     5.8718\n",
            "  Loss_Identity Speech:     7.9120\n",
            "  Grad Norm DV:    0.4034\n",
            "  Grad Norm DS:    0.2859\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    12.0000\n",
            "  num_DS_updates:    13.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:13,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.6534\n",
            "  Loss_DS:         0.6006\n",
            "  Loss_adv_vocal:     0.1162\n",
            "  Loss_adv_speech:     0.1385\n",
            "  Loss_Cycle Vocal:     5.0436\n",
            "  Loss_Cycle Speech:     5.7548\n",
            "  Loss_Identity Vocal:     5.8405\n",
            "  Loss_Identity Speech:     7.7479\n",
            "  Grad Norm DV:    0.3104\n",
            "  Grad Norm DS:    4.1593\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    1.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.6482\n",
            "  Loss_DS:         0.7093\n",
            "  Loss_adv_vocal:     0.1245\n",
            "  Loss_adv_speech:     0.0902\n",
            "  Loss_Cycle Vocal:     5.4164\n",
            "  Loss_Cycle Speech:     6.0570\n",
            "  Loss_Identity Vocal:     6.0879\n",
            "  Loss_Identity Speech:     7.8785\n",
            "  Grad Norm DV:    0.9646\n",
            "  Grad Norm DS:    0.5202\n",
            "  Grad Norm GV:    0.0093\n",
            "  Grad Norm GS:    0.0108\n",
            "  num_DV_updates:    6.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.6967\n",
            "  Loss_DS:         0.6683\n",
            "  Loss_adv_vocal:     0.1083\n",
            "  Loss_adv_speech:     0.1064\n",
            "  Loss_Cycle Vocal:     5.4836\n",
            "  Loss_Cycle Speech:     6.1153\n",
            "  Loss_Identity Vocal:     6.0658\n",
            "  Loss_Identity Speech:     7.9725\n",
            "  Grad Norm DV:    0.1818\n",
            "  Grad Norm DS:    0.1633\n",
            "  Grad Norm GV:    0.0093\n",
            "  Grad Norm GS:    0.0109\n",
            "  num_DV_updates:    17.0000\n",
            "  num_DS_updates:    16.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5931\n",
            "  Loss_DS:         0.5895\n",
            "  Loss_adv_vocal:     0.1634\n",
            "  Loss_adv_speech:     0.1498\n",
            "  Loss_Cycle Vocal:     5.1077\n",
            "  Loss_Cycle Speech:     5.7809\n",
            "  Loss_Identity Vocal:     6.0090\n",
            "  Loss_Identity Speech:     7.9552\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0088\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5907\n",
            "  Loss_adv_vocal:     0.1631\n",
            "  Loss_adv_speech:     0.1494\n",
            "  Loss_Cycle Vocal:     4.9106\n",
            "  Loss_Cycle Speech:     5.5884\n",
            "  Loss_Identity Vocal:     5.8390\n",
            "  Loss_Identity Speech:     7.7701\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5932\n",
            "  Loss_adv_vocal:     0.1625\n",
            "  Loss_adv_speech:     0.1483\n",
            "  Loss_Cycle Vocal:     4.7238\n",
            "  Loss_Cycle Speech:     5.3706\n",
            "  Loss_Identity Vocal:     5.6878\n",
            "  Loss_Identity Speech:     7.5154\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0053\n",
            "  Grad Norm GS:    0.0052\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5979\n",
            "  Loss_DS:         0.5947\n",
            "  Loss_adv_vocal:     0.1610\n",
            "  Loss_adv_speech:     0.1473\n",
            "  Loss_Cycle Vocal:     4.6655\n",
            "  Loss_Cycle Speech:     5.1656\n",
            "  Loss_Identity Vocal:     5.6840\n",
            "  Loss_Identity Speech:     7.3027\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0055\n",
            "  Grad Norm GS:    0.0055\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.6431\n",
            "  Loss_DS:         0.5950\n",
            "  Loss_adv_vocal:     0.1371\n",
            "  Loss_adv_speech:     0.1471\n",
            "  Loss_Cycle Vocal:     4.6381\n",
            "  Loss_Cycle Speech:     4.9369\n",
            "  Loss_Identity Vocal:     5.7372\n",
            "  Loss_Identity Speech:     7.1645\n",
            "  Grad Norm DV:    0.9341\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    6.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.7274\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1013\n",
            "  Loss_adv_speech:     0.1468\n",
            "  Loss_Cycle Vocal:     4.5904\n",
            "  Loss_Cycle Speech:     4.7888\n",
            "  Loss_Identity Vocal:     5.7234\n",
            "  Loss_Identity Speech:     7.1214\n",
            "  Grad Norm DV:    0.2194\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    18.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.6000\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1728\n",
            "  Loss_adv_speech:     0.1467\n",
            "  Loss_Cycle Vocal:     4.5439\n",
            "  Loss_Cycle Speech:     4.7195\n",
            "  Loss_Identity Vocal:     5.6680\n",
            "  Loss_Identity Speech:     7.0690\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.6011\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1726\n",
            "  Loss_adv_speech:     0.1464\n",
            "  Loss_Cycle Vocal:     4.5615\n",
            "  Loss_Cycle Speech:     4.6963\n",
            "  Loss_Identity Vocal:     5.6500\n",
            "  Loss_Identity Speech:     7.0080\n",
            "  Grad Norm DV:    4.2103\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    1.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.7763\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.0856\n",
            "  Loss_adv_speech:     0.1464\n",
            "  Loss_Cycle Vocal:     4.5463\n",
            "  Loss_Cycle Speech:     4.6714\n",
            "  Loss_Identity Vocal:     5.6196\n",
            "  Loss_Identity Speech:     6.9830\n",
            "  Grad Norm DV:    0.6798\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0062\n",
            "  num_DV_updates:    12.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.7133\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.1083\n",
            "  Loss_adv_speech:     0.1465\n",
            "  Loss_Cycle Vocal:     4.4959\n",
            "  Loss_Cycle Speech:     4.6228\n",
            "  Loss_Identity Vocal:     5.6075\n",
            "  Loss_Identity Speech:     6.9712\n",
            "  Grad Norm DV:    0.1281\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    17.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.6585\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1366\n",
            "  Loss_adv_speech:     0.1467\n",
            "  Loss_Cycle Vocal:     4.4279\n",
            "  Loss_Cycle Speech:     4.5746\n",
            "  Loss_Identity Vocal:     5.6037\n",
            "  Loss_Identity Speech:     6.9311\n",
            "  Grad Norm DV:    0.2513\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0055\n",
            "  Grad Norm GS:    0.0053\n",
            "  num_DV_updates:    12.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.6901\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.0974\n",
            "  Loss_adv_speech:     0.1463\n",
            "  Loss_Cycle Vocal:     4.3648\n",
            "  Loss_Cycle Speech:     4.5436\n",
            "  Loss_Identity Vocal:     5.5013\n",
            "  Loss_Identity Speech:     6.8768\n",
            "  Grad Norm DV:    0.1887\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0062\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.6477\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1176\n",
            "  Loss_adv_speech:     0.1463\n",
            "  Loss_Cycle Vocal:     4.3664\n",
            "  Loss_Cycle Speech:     4.5320\n",
            "  Loss_Identity Vocal:     5.5292\n",
            "  Loss_Identity Speech:     6.8378\n",
            "  Grad Norm DV:    0.2356\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    12.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.6527\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1074\n",
            "  Loss_adv_speech:     0.1466\n",
            "  Loss_Cycle Vocal:     4.3524\n",
            "  Loss_Cycle Speech:     4.4896\n",
            "  Loss_Identity Vocal:     5.4963\n",
            "  Loss_Identity Speech:     6.7906\n",
            "  Grad Norm DV:    0.2514\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.6309\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1206\n",
            "  Loss_adv_speech:     0.1463\n",
            "  Loss_Cycle Vocal:     4.3084\n",
            "  Loss_Cycle Speech:     4.4245\n",
            "  Loss_Identity Vocal:     5.4988\n",
            "  Loss_Identity Speech:     6.7346\n",
            "  Grad Norm DV:    0.4785\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0057\n",
            "  Grad Norm GS:    0.0056\n",
            "  num_DV_updates:    8.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.6606\n",
            "  Loss_DS:         0.5977\n",
            "  Loss_adv_vocal:     0.1009\n",
            "  Loss_adv_speech:     0.1462\n",
            "  Loss_Cycle Vocal:     4.3064\n",
            "  Loss_Cycle Speech:     4.4053\n",
            "  Loss_Identity Vocal:     5.4783\n",
            "  Loss_Identity Speech:     6.6794\n",
            "  Grad Norm DV:    0.2039\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0059\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5787\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1537\n",
            "  Loss_adv_speech:     0.1466\n",
            "  Loss_Cycle Vocal:     4.3526\n",
            "  Loss_Cycle Speech:     4.4033\n",
            "  Loss_Identity Vocal:     5.5312\n",
            "  Loss_Identity Speech:     6.6620\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5798\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1536\n",
            "  Loss_adv_speech:     0.1461\n",
            "  Loss_Cycle Vocal:     4.2948\n",
            "  Loss_Cycle Speech:     4.3369\n",
            "  Loss_Identity Vocal:     5.5393\n",
            "  Loss_Identity Speech:     6.6376\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5804\n",
            "  Loss_DS:         0.5982\n",
            "  Loss_adv_vocal:     0.1530\n",
            "  Loss_adv_speech:     0.1460\n",
            "  Loss_Cycle Vocal:     4.2933\n",
            "  Loss_Cycle Speech:     4.3182\n",
            "  Loss_Identity Vocal:     5.5154\n",
            "  Loss_Identity Speech:     6.6212\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0062\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5815\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.1527\n",
            "  Loss_adv_speech:     0.1461\n",
            "  Loss_Cycle Vocal:     4.2259\n",
            "  Loss_Cycle Speech:     4.2646\n",
            "  Loss_Identity Vocal:     5.5319\n",
            "  Loss_Identity Speech:     6.5849\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0059\n",
            "  Grad Norm GS:    0.0055\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5822\n",
            "  Loss_DS:         0.5986\n",
            "  Loss_adv_vocal:     0.1522\n",
            "  Loss_adv_speech:     0.1458\n",
            "  Loss_Cycle Vocal:     4.2457\n",
            "  Loss_Cycle Speech:     4.2360\n",
            "  Loss_Identity Vocal:     5.5584\n",
            "  Loss_Identity Speech:     6.5621\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5830\n",
            "  Loss_DS:         0.5982\n",
            "  Loss_adv_vocal:     0.1517\n",
            "  Loss_adv_speech:     0.1459\n",
            "  Loss_Cycle Vocal:     4.1779\n",
            "  Loss_Cycle Speech:     4.1517\n",
            "  Loss_Identity Vocal:     5.5494\n",
            "  Loss_Identity Speech:     6.5496\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0058\n",
            "  Grad Norm GS:    0.0053\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5841\n",
            "  Loss_DS:         0.6086\n",
            "  Loss_adv_vocal:     0.1508\n",
            "  Loss_adv_speech:     0.1387\n",
            "  Loss_Cycle Vocal:     4.0994\n",
            "  Loss_Cycle Speech:     4.0954\n",
            "  Loss_Identity Vocal:     5.5157\n",
            "  Loss_Identity Speech:     6.5535\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.5715\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    6.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5855\n",
            "  Loss_DS:         0.6770\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.0991\n",
            "  Loss_Cycle Vocal:     4.1145\n",
            "  Loss_Cycle Speech:     4.0593\n",
            "  Loss_Identity Vocal:     5.5714\n",
            "  Loss_Identity Speech:     6.5959\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2514\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    15.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5852\n",
            "  Loss_DS:         0.6122\n",
            "  Loss_adv_vocal:     0.1498\n",
            "  Loss_adv_speech:     0.1327\n",
            "  Loss_Cycle Vocal:     4.1224\n",
            "  Loss_Cycle Speech:     4.0133\n",
            "  Loss_Identity Vocal:     5.5748\n",
            "  Loss_Identity Speech:     6.6267\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.4417\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    7.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5872\n",
            "  Loss_DS:         0.6562\n",
            "  Loss_adv_vocal:     0.1497\n",
            "  Loss_adv_speech:     0.1034\n",
            "  Loss_Cycle Vocal:     4.0950\n",
            "  Loss_Cycle Speech:     3.9592\n",
            "  Loss_Identity Vocal:     5.5871\n",
            "  Loss_Identity Speech:     6.6516\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2728\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    13.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5868\n",
            "  Loss_DS:         0.6291\n",
            "  Loss_adv_vocal:     0.1491\n",
            "  Loss_adv_speech:     0.1142\n",
            "  Loss_Cycle Vocal:     4.0596\n",
            "  Loss_Cycle Speech:     3.9069\n",
            "  Loss_Identity Vocal:     5.6132\n",
            "  Loss_Identity Speech:     6.6678\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2399\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5880\n",
            "  Loss_DS:         0.6161\n",
            "  Loss_adv_vocal:     0.1488\n",
            "  Loss_adv_speech:     0.1210\n",
            "  Loss_Cycle Vocal:     3.9810\n",
            "  Loss_Cycle Speech:     3.8459\n",
            "  Loss_Identity Vocal:     5.5635\n",
            "  Loss_Identity Speech:     6.6515\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.4615\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    7.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5888\n",
            "  Loss_DS:         0.6453\n",
            "  Loss_adv_vocal:     0.1490\n",
            "  Loss_adv_speech:     0.1044\n",
            "  Loss_Cycle Vocal:     3.9422\n",
            "  Loss_Cycle Speech:     3.8205\n",
            "  Loss_Identity Vocal:     5.5506\n",
            "  Loss_Identity Speech:     6.6554\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2405\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0059\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    14.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5874\n",
            "  Loss_DS:         0.5917\n",
            "  Loss_adv_vocal:     0.1483\n",
            "  Loss_adv_speech:     0.1346\n",
            "  Loss_Cycle Vocal:     3.9595\n",
            "  Loss_Cycle Speech:     3.7990\n",
            "  Loss_Identity Vocal:     5.5482\n",
            "  Loss_Identity Speech:     6.6546\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5880\n",
            "  Loss_DS:         0.5911\n",
            "  Loss_adv_vocal:     0.1483\n",
            "  Loss_adv_speech:     0.1347\n",
            "  Loss_Cycle Vocal:     3.9736\n",
            "  Loss_Cycle Speech:     3.7914\n",
            "  Loss_Identity Vocal:     5.5688\n",
            "  Loss_Identity Speech:     6.6484\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5891\n",
            "  Loss_DS:         0.5918\n",
            "  Loss_adv_vocal:     0.1476\n",
            "  Loss_adv_speech:     0.1345\n",
            "  Loss_Cycle Vocal:     4.0198\n",
            "  Loss_Cycle Speech:     3.8394\n",
            "  Loss_Identity Vocal:     5.5531\n",
            "  Loss_Identity Speech:     6.6423\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5890\n",
            "  Loss_DS:         0.5915\n",
            "  Loss_adv_vocal:     0.1480\n",
            "  Loss_adv_speech:     0.1343\n",
            "  Loss_Cycle Vocal:     3.8850\n",
            "  Loss_Cycle Speech:     3.7521\n",
            "  Loss_Identity Vocal:     5.4650\n",
            "  Loss_Identity Speech:     6.6056\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5891\n",
            "  Loss_DS:         0.5927\n",
            "  Loss_adv_vocal:     0.1478\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.8037\n",
            "  Loss_Cycle Speech:     3.6801\n",
            "  Loss_Identity Vocal:     5.4778\n",
            "  Loss_Identity Speech:     6.5853\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5896\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1477\n",
            "  Loss_adv_speech:     0.1342\n",
            "  Loss_Cycle Vocal:     3.8065\n",
            "  Loss_Cycle Speech:     3.6914\n",
            "  Loss_Identity Vocal:     5.4698\n",
            "  Loss_Identity Speech:     6.6176\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5892\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1481\n",
            "  Loss_adv_speech:     0.1341\n",
            "  Loss_Cycle Vocal:     3.7373\n",
            "  Loss_Cycle Speech:     3.6456\n",
            "  Loss_Identity Vocal:     5.4543\n",
            "  Loss_Identity Speech:     6.6275\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5890\n",
            "  Loss_DS:         0.5934\n",
            "  Loss_adv_vocal:     0.1476\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.7535\n",
            "  Loss_Cycle Speech:     3.6534\n",
            "  Loss_Identity Vocal:     5.4829\n",
            "  Loss_Identity Speech:     6.6525\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5889\n",
            "  Loss_DS:         0.5926\n",
            "  Loss_adv_vocal:     0.1477\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.7448\n",
            "  Loss_Cycle Speech:     3.6182\n",
            "  Loss_Identity Vocal:     5.4945\n",
            "  Loss_Identity Speech:     6.6166\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5929\n",
            "  Loss_adv_vocal:     0.1471\n",
            "  Loss_adv_speech:     0.1337\n",
            "  Loss_Cycle Vocal:     3.7025\n",
            "  Loss_Cycle Speech:     3.5971\n",
            "  Loss_Identity Vocal:     5.5157\n",
            "  Loss_Identity Speech:     6.6207\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5903\n",
            "  Loss_DS:         0.5929\n",
            "  Loss_adv_vocal:     0.1472\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.6295\n",
            "  Loss_Cycle Speech:     3.5524\n",
            "  Loss_Identity Vocal:     5.4940\n",
            "  Loss_Identity Speech:     6.6233\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0058\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5904\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1473\n",
            "  Loss_adv_speech:     0.1335\n",
            "  Loss_Cycle Vocal:     3.5754\n",
            "  Loss_Cycle Speech:     3.5219\n",
            "  Loss_Identity Vocal:     5.4671\n",
            "  Loss_Identity Speech:     6.6303\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5930\n",
            "  Loss_adv_vocal:     0.1471\n",
            "  Loss_adv_speech:     0.1334\n",
            "  Loss_Cycle Vocal:     3.5814\n",
            "  Loss_Cycle Speech:     3.5424\n",
            "  Loss_Identity Vocal:     5.4855\n",
            "  Loss_Identity Speech:     6.6278\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1467\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.5607\n",
            "  Loss_Cycle Speech:     3.5154\n",
            "  Loss_Identity Vocal:     5.4959\n",
            "  Loss_Identity Speech:     6.5825\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5925\n",
            "  Loss_adv_vocal:     0.1468\n",
            "  Loss_adv_speech:     0.1339\n",
            "  Loss_Cycle Vocal:     3.5594\n",
            "  Loss_Cycle Speech:     3.5204\n",
            "  Loss_Identity Vocal:     5.4865\n",
            "  Loss_Identity Speech:     6.5738\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5908\n",
            "  Loss_DS:         0.5936\n",
            "  Loss_adv_vocal:     0.1466\n",
            "  Loss_adv_speech:     0.1338\n",
            "  Loss_Cycle Vocal:     3.5550\n",
            "  Loss_Cycle Speech:     3.5160\n",
            "  Loss_Identity Vocal:     5.5100\n",
            "  Loss_Identity Speech:     6.5752\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5933\n",
            "  Loss_adv_vocal:     0.1464\n",
            "  Loss_adv_speech:     0.1337\n",
            "  Loss_Cycle Vocal:     3.5430\n",
            "  Loss_Cycle Speech:     3.5128\n",
            "  Loss_Identity Vocal:     5.5152\n",
            "  Loss_Identity Speech:     6.5454\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5922\n",
            "  Loss_DS:         0.5931\n",
            "  Loss_adv_vocal:     0.1464\n",
            "  Loss_adv_speech:     0.1338\n",
            "  Loss_Cycle Vocal:     3.4790\n",
            "  Loss_Cycle Speech:     3.4916\n",
            "  Loss_Identity Vocal:     5.5072\n",
            "  Loss_Identity Speech:     6.5566\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5931\n",
            "  Loss_DS:         0.5940\n",
            "  Loss_adv_vocal:     0.1460\n",
            "  Loss_adv_speech:     0.1340\n",
            "  Loss_Cycle Vocal:     3.4078\n",
            "  Loss_Cycle Speech:     3.4462\n",
            "  Loss_Identity Vocal:     5.4696\n",
            "  Loss_Identity Speech:     6.5189\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0058\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5931\n",
            "  Loss_adv_vocal:     0.1455\n",
            "  Loss_adv_speech:     0.1333\n",
            "  Loss_Cycle Vocal:     3.3805\n",
            "  Loss_Cycle Speech:     3.4386\n",
            "  Loss_Identity Vocal:     5.4704\n",
            "  Loss_Identity Speech:     6.5165\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5938\n",
            "  Loss_adv_vocal:     0.1457\n",
            "  Loss_adv_speech:     0.1335\n",
            "  Loss_Cycle Vocal:     3.3449\n",
            "  Loss_Cycle Speech:     3.4198\n",
            "  Loss_Identity Vocal:     5.4747\n",
            "  Loss_Identity Speech:     6.5189\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5939\n",
            "  Loss_adv_vocal:     0.1454\n",
            "  Loss_adv_speech:     0.1333\n",
            "  Loss_Cycle Vocal:     3.3590\n",
            "  Loss_Cycle Speech:     3.4246\n",
            "  Loss_Identity Vocal:     5.4773\n",
            "  Loss_Identity Speech:     6.5131\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0082\n",
            "  Grad Norm GS:    0.0084\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5944\n",
            "  Loss_adv_vocal:     0.1454\n",
            "  Loss_adv_speech:     0.1333\n",
            "  Loss_Cycle Vocal:     3.3093\n",
            "  Loss_Cycle Speech:     3.4077\n",
            "  Loss_Identity Vocal:     5.4897\n",
            "  Loss_Identity Speech:     6.5221\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5941\n",
            "  Loss_adv_vocal:     0.1452\n",
            "  Loss_adv_speech:     0.1332\n",
            "  Loss_Cycle Vocal:     3.2562\n",
            "  Loss_Cycle Speech:     3.3748\n",
            "  Loss_Identity Vocal:     5.4608\n",
            "  Loss_Identity Speech:     6.5103\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1449\n",
            "  Loss_adv_speech:     0.1330\n",
            "  Loss_Cycle Vocal:     3.2353\n",
            "  Loss_Cycle Speech:     3.3672\n",
            "  Loss_Identity Vocal:     5.4691\n",
            "  Loss_Identity Speech:     6.4954\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5958\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1447\n",
            "  Loss_adv_speech:     0.1332\n",
            "  Loss_Cycle Vocal:     3.3300\n",
            "  Loss_Cycle Speech:     3.4397\n",
            "  Loss_Identity Vocal:     5.5233\n",
            "  Loss_Identity Speech:     6.4990\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5945\n",
            "  Loss_adv_vocal:     0.1452\n",
            "  Loss_adv_speech:     0.1334\n",
            "  Loss_Cycle Vocal:     3.5134\n",
            "  Loss_Cycle Speech:     3.5787\n",
            "  Loss_Identity Vocal:     5.5090\n",
            "  Loss_Identity Speech:     6.5134\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0081\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5946\n",
            "  Loss_adv_vocal:     0.1454\n",
            "  Loss_adv_speech:     0.1331\n",
            "  Loss_Cycle Vocal:     3.2838\n",
            "  Loss_Cycle Speech:     3.3816\n",
            "  Loss_Identity Vocal:     5.4570\n",
            "  Loss_Identity Speech:     6.5029\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1440\n",
            "  Loss_adv_speech:     0.1330\n",
            "  Loss_Cycle Vocal:     3.2456\n",
            "  Loss_Cycle Speech:     3.3779\n",
            "  Loss_Identity Vocal:     5.4818\n",
            "  Loss_Identity Speech:     6.5155\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5946\n",
            "  Loss_adv_vocal:     0.1439\n",
            "  Loss_adv_speech:     0.1330\n",
            "  Loss_Cycle Vocal:     3.1659\n",
            "  Loss_Cycle Speech:     3.3153\n",
            "  Loss_Identity Vocal:     5.4756\n",
            "  Loss_Identity Speech:     6.4865\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0060\n",
            "  Grad Norm GS:    0.0058\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5947\n",
            "  Loss_adv_vocal:     0.1434\n",
            "  Loss_adv_speech:     0.1327\n",
            "  Loss_Cycle Vocal:     3.1604\n",
            "  Loss_Cycle Speech:     3.2917\n",
            "  Loss_Identity Vocal:     5.4903\n",
            "  Loss_Identity Speech:     6.4555\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5978\n",
            "  Loss_DS:         0.5954\n",
            "  Loss_adv_vocal:     0.1433\n",
            "  Loss_adv_speech:     0.1327\n",
            "  Loss_Cycle Vocal:     3.1557\n",
            "  Loss_Cycle Speech:     3.2854\n",
            "  Loss_Identity Vocal:     5.4977\n",
            "  Loss_Identity Speech:     6.4431\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0059\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5974\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1427\n",
            "  Loss_adv_speech:     0.1326\n",
            "  Loss_Cycle Vocal:     3.1446\n",
            "  Loss_Cycle Speech:     3.2851\n",
            "  Loss_Identity Vocal:     5.4967\n",
            "  Loss_Identity Speech:     6.4224\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5980\n",
            "  Loss_DS:         0.5950\n",
            "  Loss_adv_vocal:     0.1426\n",
            "  Loss_adv_speech:     0.1328\n",
            "  Loss_Cycle Vocal:     3.1097\n",
            "  Loss_Cycle Speech:     3.2763\n",
            "  Loss_Identity Vocal:     5.4756\n",
            "  Loss_Identity Speech:     6.3985\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5986\n",
            "  Loss_DS:         0.5957\n",
            "  Loss_adv_vocal:     0.1421\n",
            "  Loss_adv_speech:     0.1327\n",
            "  Loss_Cycle Vocal:     3.1069\n",
            "  Loss_Cycle Speech:     3.2583\n",
            "  Loss_Identity Vocal:     5.4818\n",
            "  Loss_Identity Speech:     6.3868\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5992\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1420\n",
            "  Loss_adv_speech:     0.1320\n",
            "  Loss_Cycle Vocal:     3.0833\n",
            "  Loss_Cycle Speech:     3.2363\n",
            "  Loss_Identity Vocal:     5.4864\n",
            "  Loss_Identity Speech:     6.3664\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5996\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1416\n",
            "  Loss_adv_speech:     0.1325\n",
            "  Loss_Cycle Vocal:     2.9882\n",
            "  Loss_Cycle Speech:     3.1831\n",
            "  Loss_Identity Vocal:     5.4445\n",
            "  Loss_Identity Speech:     6.3315\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0059\n",
            "  Grad Norm GS:    0.0054\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.6007\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1414\n",
            "  Loss_adv_speech:     0.1325\n",
            "  Loss_Cycle Vocal:     3.0131\n",
            "  Loss_Cycle Speech:     3.2050\n",
            "  Loss_Identity Vocal:     5.4527\n",
            "  Loss_Identity Speech:     6.3394\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.6059\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1375\n",
            "  Loss_adv_speech:     0.1322\n",
            "  Loss_Cycle Vocal:     3.0405\n",
            "  Loss_Cycle Speech:     3.2060\n",
            "  Loss_Identity Vocal:     5.4457\n",
            "  Loss_Identity Speech:     6.3334\n",
            "  Grad Norm DV:    1.2807\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    3.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.7416\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.0774\n",
            "  Loss_adv_speech:     0.1319\n",
            "  Loss_Cycle Vocal:     2.9493\n",
            "  Loss_Cycle Speech:     3.1449\n",
            "  Loss_Identity Vocal:     5.4272\n",
            "  Loss_Identity Speech:     6.3153\n",
            "  Grad Norm DV:    0.3231\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.6256\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1406\n",
            "  Loss_adv_speech:     0.1318\n",
            "  Loss_Cycle Vocal:     2.9900\n",
            "  Loss_Cycle Speech:     3.1584\n",
            "  Loss_Identity Vocal:     5.4682\n",
            "  Loss_Identity Speech:     6.3016\n",
            "  Grad Norm DV:    0.2915\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    10.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.6700\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.0996\n",
            "  Loss_adv_speech:     0.1320\n",
            "  Loss_Cycle Vocal:     2.9986\n",
            "  Loss_Cycle Speech:     3.1490\n",
            "  Loss_Identity Vocal:     5.4806\n",
            "  Loss_Identity Speech:     6.2847\n",
            "  Grad Norm DV:    0.2843\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.6348\n",
            "  Loss_DS:         0.5982\n",
            "  Loss_adv_vocal:     0.1102\n",
            "  Loss_adv_speech:     0.1317\n",
            "  Loss_Cycle Vocal:     2.9878\n",
            "  Loss_Cycle Speech:     3.1345\n",
            "  Loss_Identity Vocal:     5.4924\n",
            "  Loss_Identity Speech:     6.2924\n",
            "  Grad Norm DV:    0.2622\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    12.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1323\n",
            "  Loss_Cycle Vocal:     2.9725\n",
            "  Loss_Cycle Speech:     3.1018\n",
            "  Loss_Identity Vocal:     5.5121\n",
            "  Loss_Identity Speech:     6.2837\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5986\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1320\n",
            "  Loss_Cycle Vocal:     2.9642\n",
            "  Loss_Cycle Speech:     3.0804\n",
            "  Loss_Identity Vocal:     5.5256\n",
            "  Loss_Identity Speech:     6.2754\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.6014\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1322\n",
            "  Loss_Cycle Vocal:     2.8623\n",
            "  Loss_Cycle Speech:     3.0188\n",
            "  Loss_Identity Vocal:     5.4818\n",
            "  Loss_Identity Speech:     6.2524\n",
            "  Grad Norm DV:    1.7915\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0057\n",
            "  num_DV_updates:    2.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.7385\n",
            "  Loss_DS:         0.5985\n",
            "  Loss_adv_vocal:     0.0742\n",
            "  Loss_adv_speech:     0.1315\n",
            "  Loss_Cycle Vocal:     2.8647\n",
            "  Loss_Cycle Speech:     3.0416\n",
            "  Loss_Identity Vocal:     5.4658\n",
            "  Loss_Identity Speech:     6.2546\n",
            "  Grad Norm DV:    0.3722\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.6249\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.1332\n",
            "  Loss_adv_speech:     0.1316\n",
            "  Loss_Cycle Vocal:     2.8570\n",
            "  Loss_Cycle Speech:     3.0205\n",
            "  Loss_Identity Vocal:     5.4853\n",
            "  Loss_Identity Speech:     6.2389\n",
            "  Grad Norm DV:    0.2786\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    10.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.6570\n",
            "  Loss_DS:         0.5982\n",
            "  Loss_adv_vocal:     0.1044\n",
            "  Loss_adv_speech:     0.1316\n",
            "  Loss_Cycle Vocal:     2.9166\n",
            "  Loss_Cycle Speech:     3.0331\n",
            "  Loss_Identity Vocal:     5.5038\n",
            "  Loss_Identity Speech:     6.2510\n",
            "  Grad Norm DV:    0.2619\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.6362\n",
            "  Loss_DS:         0.5982\n",
            "  Loss_adv_vocal:     0.1070\n",
            "  Loss_adv_speech:     0.1315\n",
            "  Loss_Cycle Vocal:     2.8805\n",
            "  Loss_Cycle Speech:     3.0251\n",
            "  Loss_Identity Vocal:     5.4924\n",
            "  Loss_Identity Speech:     6.2135\n",
            "  Grad Norm DV:    0.2314\n",
            "  Grad Norm DS:    3.2936\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    1.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5859\n",
            "  Loss_DS:         0.6734\n",
            "  Loss_adv_vocal:     0.1353\n",
            "  Loss_adv_speech:     0.0967\n",
            "  Loss_Cycle Vocal:     2.8655\n",
            "  Loss_Cycle Speech:     2.9959\n",
            "  Loss_Identity Vocal:     5.4953\n",
            "  Loss_Identity Speech:     6.2253\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.4992\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    10.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5866\n",
            "  Loss_DS:         0.6792\n",
            "  Loss_adv_vocal:     0.1349\n",
            "  Loss_adv_speech:     0.0954\n",
            "  Loss_Cycle Vocal:     2.8604\n",
            "  Loss_Cycle Speech:     2.9753\n",
            "  Loss_Identity Vocal:     5.5201\n",
            "  Loss_Identity Speech:     6.2251\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.1844\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    16.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5863\n",
            "  Loss_DS:         0.5899\n",
            "  Loss_adv_vocal:     0.1346\n",
            "  Loss_adv_speech:     0.1384\n",
            "  Loss_Cycle Vocal:     2.8352\n",
            "  Loss_Cycle Speech:     2.9366\n",
            "  Loss_Identity Vocal:     5.5312\n",
            "  Loss_Identity Speech:     6.2352\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0055\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5871\n",
            "  Loss_DS:         0.5901\n",
            "  Loss_adv_vocal:     0.1347\n",
            "  Loss_adv_speech:     0.1384\n",
            "  Loss_Cycle Vocal:     2.8175\n",
            "  Loss_Cycle Speech:     2.9440\n",
            "  Loss_Identity Vocal:     5.5303\n",
            "  Loss_Identity Speech:     6.2225\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5876\n",
            "  Loss_DS:         0.5905\n",
            "  Loss_adv_vocal:     0.1343\n",
            "  Loss_adv_speech:     0.1383\n",
            "  Loss_Cycle Vocal:     2.7690\n",
            "  Loss_Cycle Speech:     2.9249\n",
            "  Loss_Identity Vocal:     5.5112\n",
            "  Loss_Identity Speech:     6.2156\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5871\n",
            "  Loss_DS:         0.5911\n",
            "  Loss_adv_vocal:     0.1340\n",
            "  Loss_adv_speech:     0.1378\n",
            "  Loss_Cycle Vocal:     2.7227\n",
            "  Loss_Cycle Speech:     2.9009\n",
            "  Loss_Identity Vocal:     5.4917\n",
            "  Loss_Identity Speech:     6.2066\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5876\n",
            "  Loss_DS:         0.5917\n",
            "  Loss_adv_vocal:     0.1342\n",
            "  Loss_adv_speech:     0.1377\n",
            "  Loss_Cycle Vocal:     2.7255\n",
            "  Loss_Cycle Speech:     2.8968\n",
            "  Loss_Identity Vocal:     5.4902\n",
            "  Loss_Identity Speech:     6.2023\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0084\n",
            "  Grad Norm GS:    0.0084\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5875\n",
            "  Loss_DS:         0.5910\n",
            "  Loss_adv_vocal:     0.1340\n",
            "  Loss_adv_speech:     0.1379\n",
            "  Loss_Cycle Vocal:     2.6996\n",
            "  Loss_Cycle Speech:     2.8748\n",
            "  Loss_Identity Vocal:     5.4815\n",
            "  Loss_Identity Speech:     6.1884\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5914\n",
            "  Loss_adv_vocal:     0.1338\n",
            "  Loss_adv_speech:     0.1381\n",
            "  Loss_Cycle Vocal:     2.6919\n",
            "  Loss_Cycle Speech:     2.8801\n",
            "  Loss_Identity Vocal:     5.4938\n",
            "  Loss_Identity Speech:     6.2027\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5914\n",
            "  Loss_adv_vocal:     0.1346\n",
            "  Loss_adv_speech:     0.1381\n",
            "  Loss_Cycle Vocal:     2.7035\n",
            "  Loss_Cycle Speech:     2.8720\n",
            "  Loss_Identity Vocal:     5.4952\n",
            "  Loss_Identity Speech:     6.2012\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5872\n",
            "  Loss_DS:         0.5912\n",
            "  Loss_adv_vocal:     0.1340\n",
            "  Loss_adv_speech:     0.1373\n",
            "  Loss_Cycle Vocal:     2.6981\n",
            "  Loss_Cycle Speech:     2.8633\n",
            "  Loss_Identity Vocal:     5.4977\n",
            "  Loss_Identity Speech:     6.1972\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5886\n",
            "  Loss_DS:         0.5916\n",
            "  Loss_adv_vocal:     0.1334\n",
            "  Loss_adv_speech:     0.1378\n",
            "  Loss_Cycle Vocal:     2.6376\n",
            "  Loss_Cycle Speech:     2.8294\n",
            "  Loss_Identity Vocal:     5.4579\n",
            "  Loss_Identity Speech:     6.1720\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5894\n",
            "  Loss_DS:         0.5916\n",
            "  Loss_adv_vocal:     0.1335\n",
            "  Loss_adv_speech:     0.1376\n",
            "  Loss_Cycle Vocal:     2.6207\n",
            "  Loss_Cycle Speech:     2.7931\n",
            "  Loss_Identity Vocal:     5.4600\n",
            "  Loss_Identity Speech:     6.1874\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5897\n",
            "  Loss_DS:         0.5927\n",
            "  Loss_adv_vocal:     0.1335\n",
            "  Loss_adv_speech:     0.1377\n",
            "  Loss_Cycle Vocal:     2.6732\n",
            "  Loss_Cycle Speech:     2.8201\n",
            "  Loss_Identity Vocal:     5.5146\n",
            "  Loss_Identity Speech:     6.1814\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5890\n",
            "  Loss_DS:         0.5923\n",
            "  Loss_adv_vocal:     0.1334\n",
            "  Loss_adv_speech:     0.1376\n",
            "  Loss_Cycle Vocal:     2.6151\n",
            "  Loss_Cycle Speech:     2.8149\n",
            "  Loss_Identity Vocal:     5.4951\n",
            "  Loss_Identity Speech:     6.1818\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5896\n",
            "  Loss_DS:         0.5920\n",
            "  Loss_adv_vocal:     0.1335\n",
            "  Loss_adv_speech:     0.1374\n",
            "  Loss_Cycle Vocal:     2.6206\n",
            "  Loss_Cycle Speech:     2.8066\n",
            "  Loss_Identity Vocal:     5.5019\n",
            "  Loss_Identity Speech:     6.1624\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5901\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1325\n",
            "  Loss_adv_speech:     0.1376\n",
            "  Loss_Cycle Vocal:     2.6363\n",
            "  Loss_Cycle Speech:     2.7966\n",
            "  Loss_Identity Vocal:     5.5152\n",
            "  Loss_Identity Speech:     6.1398\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5906\n",
            "  Loss_DS:         0.5922\n",
            "  Loss_adv_vocal:     0.1327\n",
            "  Loss_adv_speech:     0.1374\n",
            "  Loss_Cycle Vocal:     2.5957\n",
            "  Loss_Cycle Speech:     2.7899\n",
            "  Loss_Identity Vocal:     5.5085\n",
            "  Loss_Identity Speech:     6.1403\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5902\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1325\n",
            "  Loss_adv_speech:     0.1370\n",
            "  Loss_Cycle Vocal:     2.6237\n",
            "  Loss_Cycle Speech:     2.7817\n",
            "  Loss_Identity Vocal:     5.5166\n",
            "  Loss_Identity Speech:     6.1232\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5915\n",
            "  Loss_DS:         0.5927\n",
            "  Loss_adv_vocal:     0.1321\n",
            "  Loss_adv_speech:     0.1372\n",
            "  Loss_Cycle Vocal:     2.5717\n",
            "  Loss_Cycle Speech:     2.7425\n",
            "  Loss_Identity Vocal:     5.5025\n",
            "  Loss_Identity Speech:     6.1057\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5914\n",
            "  Loss_DS:         0.5924\n",
            "  Loss_adv_vocal:     0.1321\n",
            "  Loss_adv_speech:     0.1372\n",
            "  Loss_Cycle Vocal:     2.5292\n",
            "  Loss_Cycle Speech:     2.7146\n",
            "  Loss_Identity Vocal:     5.4778\n",
            "  Loss_Identity Speech:     6.1015\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5912\n",
            "  Loss_DS:         0.5922\n",
            "  Loss_adv_vocal:     0.1324\n",
            "  Loss_adv_speech:     0.1372\n",
            "  Loss_Cycle Vocal:     2.5430\n",
            "  Loss_Cycle Speech:     2.7157\n",
            "  Loss_Identity Vocal:     5.4796\n",
            "  Loss_Identity Speech:     6.0799\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5911\n",
            "  Loss_DS:         0.5931\n",
            "  Loss_adv_vocal:     0.1320\n",
            "  Loss_adv_speech:     0.1376\n",
            "  Loss_Cycle Vocal:     2.5788\n",
            "  Loss_Cycle Speech:     2.7163\n",
            "  Loss_Identity Vocal:     5.5164\n",
            "  Loss_Identity Speech:     6.0820\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5925\n",
            "  Loss_DS:         0.5937\n",
            "  Loss_adv_vocal:     0.1320\n",
            "  Loss_adv_speech:     0.1373\n",
            "  Loss_Cycle Vocal:     2.5693\n",
            "  Loss_Cycle Speech:     2.7224\n",
            "  Loss_Identity Vocal:     5.5206\n",
            "  Loss_Identity Speech:     6.0579\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5929\n",
            "  Loss_DS:         0.5927\n",
            "  Loss_adv_vocal:     0.1313\n",
            "  Loss_adv_speech:     0.1372\n",
            "  Loss_Cycle Vocal:     2.5122\n",
            "  Loss_Cycle Speech:     2.6774\n",
            "  Loss_Identity Vocal:     5.4982\n",
            "  Loss_Identity Speech:     6.0156\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1318\n",
            "  Loss_adv_speech:     0.1371\n",
            "  Loss_Cycle Vocal:     2.5421\n",
            "  Loss_Cycle Speech:     2.6981\n",
            "  Loss_Identity Vocal:     5.5042\n",
            "  Loss_Identity Speech:     5.9936\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5925\n",
            "  Loss_DS:         0.5942\n",
            "  Loss_adv_vocal:     0.1312\n",
            "  Loss_adv_speech:     0.1370\n",
            "  Loss_Cycle Vocal:     2.4919\n",
            "  Loss_Cycle Speech:     2.6630\n",
            "  Loss_Identity Vocal:     5.4739\n",
            "  Loss_Identity Speech:     5.9736\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5923\n",
            "  Loss_adv_vocal:     0.1312\n",
            "  Loss_adv_speech:     0.1370\n",
            "  Loss_Cycle Vocal:     2.4290\n",
            "  Loss_Cycle Speech:     2.6152\n",
            "  Loss_Identity Vocal:     5.4576\n",
            "  Loss_Identity Speech:     5.9333\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5921\n",
            "  Loss_DS:         0.5943\n",
            "  Loss_adv_vocal:     0.1313\n",
            "  Loss_adv_speech:     0.1367\n",
            "  Loss_Cycle Vocal:     2.4668\n",
            "  Loss_Cycle Speech:     2.6471\n",
            "  Loss_Identity Vocal:     5.4778\n",
            "  Loss_Identity Speech:     5.9081\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5930\n",
            "  Loss_adv_vocal:     0.1316\n",
            "  Loss_adv_speech:     0.1369\n",
            "  Loss_Cycle Vocal:     2.4811\n",
            "  Loss_Cycle Speech:     2.6719\n",
            "  Loss_Identity Vocal:     5.4908\n",
            "  Loss_Identity Speech:     5.8910\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5938\n",
            "  Loss_adv_vocal:     0.1310\n",
            "  Loss_adv_speech:     0.1370\n",
            "  Loss_Cycle Vocal:     2.4860\n",
            "  Loss_Cycle Speech:     2.6794\n",
            "  Loss_Identity Vocal:     5.4711\n",
            "  Loss_Identity Speech:     5.8110\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5928\n",
            "  Loss_adv_vocal:     0.1307\n",
            "  Loss_adv_speech:     0.1369\n",
            "  Loss_Cycle Vocal:     2.4783\n",
            "  Loss_Cycle Speech:     2.6278\n",
            "  Loss_Identity Vocal:     5.4981\n",
            "  Loss_Identity Speech:     5.7577\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5932\n",
            "  Loss_adv_vocal:     0.1306\n",
            "  Loss_adv_speech:     0.1367\n",
            "  Loss_Cycle Vocal:     2.4621\n",
            "  Loss_Cycle Speech:     2.6203\n",
            "  Loss_Identity Vocal:     5.4934\n",
            "  Loss_Identity Speech:     5.6950\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.5937\n",
            "  Loss_adv_vocal:     0.1308\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.4343\n",
            "  Loss_Cycle Speech:     2.6141\n",
            "  Loss_Identity Vocal:     5.4806\n",
            "  Loss_Identity Speech:     5.6305\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5941\n",
            "  Loss_adv_vocal:     0.1305\n",
            "  Loss_adv_speech:     0.1367\n",
            "  Loss_Cycle Vocal:     2.4216\n",
            "  Loss_Cycle Speech:     2.6205\n",
            "  Loss_Identity Vocal:     5.4652\n",
            "  Loss_Identity Speech:     5.5952\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5936\n",
            "  Loss_adv_vocal:     0.1304\n",
            "  Loss_adv_speech:     0.1369\n",
            "  Loss_Cycle Vocal:     2.4099\n",
            "  Loss_Cycle Speech:     2.5864\n",
            "  Loss_Identity Vocal:     5.4814\n",
            "  Loss_Identity Speech:     5.5556\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5947\n",
            "  Loss_adv_vocal:     0.1305\n",
            "  Loss_adv_speech:     0.1365\n",
            "  Loss_Cycle Vocal:     2.4221\n",
            "  Loss_Cycle Speech:     2.5767\n",
            "  Loss_Identity Vocal:     5.4928\n",
            "  Loss_Identity Speech:     5.5214\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5955\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1366\n",
            "  Loss_Cycle Vocal:     2.4214\n",
            "  Loss_Cycle Speech:     2.5706\n",
            "  Loss_Identity Vocal:     5.4871\n",
            "  Loss_Identity Speech:     5.4967\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5940\n",
            "  Loss_adv_vocal:     0.1304\n",
            "  Loss_adv_speech:     0.1368\n",
            "  Loss_Cycle Vocal:     2.4167\n",
            "  Loss_Cycle Speech:     2.5661\n",
            "  Loss_Identity Vocal:     5.4756\n",
            "  Loss_Identity Speech:     5.4636\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5933\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1367\n",
            "  Loss_Cycle Vocal:     2.4041\n",
            "  Loss_Cycle Speech:     2.5538\n",
            "  Loss_Identity Vocal:     5.4800\n",
            "  Loss_Identity Speech:     5.4408\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5942\n",
            "  Loss_adv_vocal:     0.1302\n",
            "  Loss_adv_speech:     0.1366\n",
            "  Loss_Cycle Vocal:     2.3795\n",
            "  Loss_Cycle Speech:     2.5812\n",
            "  Loss_Identity Vocal:     5.4468\n",
            "  Loss_Identity Speech:     5.4234\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5937\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1363\n",
            "  Loss_Cycle Vocal:     2.3588\n",
            "  Loss_Cycle Speech:     2.5518\n",
            "  Loss_Identity Vocal:     5.4342\n",
            "  Loss_Identity Speech:     5.4097\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5951\n",
            "  Loss_DS:         0.5943\n",
            "  Loss_adv_vocal:     0.1302\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.2855\n",
            "  Loss_Cycle Speech:     2.4740\n",
            "  Loss_Identity Vocal:     5.4138\n",
            "  Loss_Identity Speech:     5.3858\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5942\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1365\n",
            "  Loss_Cycle Vocal:     2.2791\n",
            "  Loss_Cycle Speech:     2.4854\n",
            "  Loss_Identity Vocal:     5.4235\n",
            "  Loss_Identity Speech:     5.3808\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5958\n",
            "  Loss_DS:         0.5946\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1367\n",
            "  Loss_Cycle Vocal:     2.2867\n",
            "  Loss_Cycle Speech:     2.4776\n",
            "  Loss_Identity Vocal:     5.4268\n",
            "  Loss_Identity Speech:     5.3520\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5935\n",
            "  Loss_adv_vocal:     0.1298\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.2276\n",
            "  Loss_Cycle Speech:     2.4455\n",
            "  Loss_Identity Vocal:     5.4087\n",
            "  Loss_Identity Speech:     5.3383\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0057\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1299\n",
            "  Loss_adv_speech:     0.1366\n",
            "  Loss_Cycle Vocal:     2.2365\n",
            "  Loss_Cycle Speech:     2.4431\n",
            "  Loss_Identity Vocal:     5.3969\n",
            "  Loss_Identity Speech:     5.3384\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5940\n",
            "  Loss_adv_vocal:     0.1299\n",
            "  Loss_adv_speech:     0.1366\n",
            "  Loss_Cycle Vocal:     2.2535\n",
            "  Loss_Cycle Speech:     2.4455\n",
            "  Loss_Identity Vocal:     5.4007\n",
            "  Loss_Identity Speech:     5.3173\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5959\n",
            "  Loss_DS:         0.5937\n",
            "  Loss_adv_vocal:     0.1301\n",
            "  Loss_adv_speech:     0.1363\n",
            "  Loss_Cycle Vocal:     2.2799\n",
            "  Loss_Cycle Speech:     2.4572\n",
            "  Loss_Identity Vocal:     5.4068\n",
            "  Loss_Identity Speech:     5.3163\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5966\n",
            "  Loss_DS:         0.5943\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.2716\n",
            "  Loss_Cycle Speech:     2.4478\n",
            "  Loss_Identity Vocal:     5.3957\n",
            "  Loss_Identity Speech:     5.2968\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1298\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.2651\n",
            "  Loss_Cycle Speech:     2.4412\n",
            "  Loss_Identity Vocal:     5.3920\n",
            "  Loss_Identity Speech:     5.2735\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0084\n",
            "  Grad Norm GS:    0.0083\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5952\n",
            "  Loss_adv_vocal:     0.1301\n",
            "  Loss_adv_speech:     0.1362\n",
            "  Loss_Cycle Vocal:     2.3613\n",
            "  Loss_Cycle Speech:     2.5457\n",
            "  Loss_Identity Vocal:     5.4270\n",
            "  Loss_Identity Speech:     5.2769\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0083\n",
            "  Grad Norm GS:    0.0081\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5944\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1368\n",
            "  Loss_Cycle Vocal:     2.4365\n",
            "  Loss_Cycle Speech:     2.6542\n",
            "  Loss_Identity Vocal:     5.4195\n",
            "  Loss_Identity Speech:     5.3667\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5942\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.2911\n",
            "  Loss_Cycle Speech:     2.4524\n",
            "  Loss_Identity Vocal:     5.3798\n",
            "  Loss_Identity Speech:     5.3282\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5959\n",
            "  Loss_DS:         0.5940\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1365\n",
            "  Loss_Cycle Vocal:     2.2265\n",
            "  Loss_Cycle Speech:     2.3946\n",
            "  Loss_Identity Vocal:     5.3546\n",
            "  Loss_Identity Speech:     5.2741\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5945\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1365\n",
            "  Loss_Cycle Vocal:     2.2419\n",
            "  Loss_Cycle Speech:     2.4137\n",
            "  Loss_Identity Vocal:     5.3624\n",
            "  Loss_Identity Speech:     5.2434\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1299\n",
            "  Loss_adv_speech:     0.1363\n",
            "  Loss_Cycle Vocal:     2.2117\n",
            "  Loss_Cycle Speech:     2.3880\n",
            "  Loss_Identity Vocal:     5.3483\n",
            "  Loss_Identity Speech:     5.2465\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1363\n",
            "  Loss_Cycle Vocal:     2.2697\n",
            "  Loss_Cycle Speech:     2.4291\n",
            "  Loss_Identity Vocal:     5.3594\n",
            "  Loss_Identity Speech:     5.2242\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5961\n",
            "  Loss_DS:         0.5941\n",
            "  Loss_adv_vocal:     0.1299\n",
            "  Loss_adv_speech:     0.1362\n",
            "  Loss_Cycle Vocal:     2.1922\n",
            "  Loss_Cycle Speech:     2.3737\n",
            "  Loss_Identity Vocal:     5.3150\n",
            "  Loss_Identity Speech:     5.1991\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5966\n",
            "  Loss_DS:         0.5947\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1363\n",
            "  Loss_Cycle Vocal:     2.2080\n",
            "  Loss_Cycle Speech:     2.3626\n",
            "  Loss_Identity Vocal:     5.3102\n",
            "  Loss_Identity Speech:     5.1883\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0084\n",
            "  Grad Norm GS:    0.0084\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5973\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1292\n",
            "  Loss_adv_speech:     0.1364\n",
            "  Loss_Cycle Vocal:     2.1684\n",
            "  Loss_Cycle Speech:     2.3445\n",
            "  Loss_Identity Vocal:     5.2827\n",
            "  Loss_Identity Speech:     5.1635\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5964\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1509\n",
            "  Loss_Cycle Speech:     2.3336\n",
            "  Loss_Identity Vocal:     5.2734\n",
            "  Loss_Identity Speech:     5.1539\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5968\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1730\n",
            "  Loss_Cycle Speech:     2.3424\n",
            "  Loss_Identity Vocal:     5.2626\n",
            "  Loss_Identity Speech:     5.1381\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0079\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5975\n",
            "  Loss_DS:         0.5951\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1362\n",
            "  Loss_Cycle Vocal:     2.1957\n",
            "  Loss_Cycle Speech:     2.3431\n",
            "  Loss_Identity Vocal:     5.2591\n",
            "  Loss_Identity Speech:     5.1295\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5945\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.2232\n",
            "  Loss_Cycle Speech:     2.3734\n",
            "  Loss_Identity Vocal:     5.2408\n",
            "  Loss_Identity Speech:     5.1182\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5975\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1660\n",
            "  Loss_Cycle Speech:     2.3194\n",
            "  Loss_Identity Vocal:     5.1923\n",
            "  Loss_Identity Speech:     5.0982\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1359\n",
            "  Loss_Cycle Vocal:     2.1674\n",
            "  Loss_Cycle Speech:     2.3231\n",
            "  Loss_Identity Vocal:     5.2118\n",
            "  Loss_Identity Speech:     5.0826\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5980\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1365\n",
            "  Loss_Cycle Vocal:     2.1293\n",
            "  Loss_Cycle Speech:     2.3007\n",
            "  Loss_Identity Vocal:     5.1505\n",
            "  Loss_Identity Speech:     5.0779\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5981\n",
            "  Loss_DS:         0.5952\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     2.1456\n",
            "  Loss_Cycle Speech:     2.3135\n",
            "  Loss_Identity Vocal:     5.1215\n",
            "  Loss_Identity Speech:     5.0596\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5977\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1286\n",
            "  Loss_adv_speech:     0.1359\n",
            "  Loss_Cycle Vocal:     2.1428\n",
            "  Loss_Cycle Speech:     2.3039\n",
            "  Loss_Identity Vocal:     5.0993\n",
            "  Loss_Identity Speech:     5.0484\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5991\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1331\n",
            "  Loss_Cycle Speech:     2.2893\n",
            "  Loss_Identity Vocal:     5.0711\n",
            "  Loss_Identity Speech:     5.0381\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5983\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1798\n",
            "  Loss_Cycle Speech:     2.3189\n",
            "  Loss_Identity Vocal:     5.0669\n",
            "  Loss_Identity Speech:     5.0340\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5948\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1360\n",
            "  Loss_Cycle Vocal:     2.1748\n",
            "  Loss_Cycle Speech:     2.3318\n",
            "  Loss_Identity Vocal:     5.0376\n",
            "  Loss_Identity Speech:     5.0222\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5974\n",
            "  Loss_DS:         0.5946\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.1812\n",
            "  Loss_Cycle Speech:     2.3457\n",
            "  Loss_Identity Vocal:     5.0140\n",
            "  Loss_Identity Speech:     5.0166\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5977\n",
            "  Loss_DS:         0.5951\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1357\n",
            "  Loss_Cycle Vocal:     2.1648\n",
            "  Loss_Cycle Speech:     2.3101\n",
            "  Loss_Identity Vocal:     4.9902\n",
            "  Loss_Identity Speech:     4.9948\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5983\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1357\n",
            "  Loss_Cycle Vocal:     2.1560\n",
            "  Loss_Cycle Speech:     2.3212\n",
            "  Loss_Identity Vocal:     4.9597\n",
            "  Loss_Identity Speech:     4.9680\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5982\n",
            "  Loss_DS:         0.5962\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1359\n",
            "  Loss_Cycle Vocal:     2.1580\n",
            "  Loss_Cycle Speech:     2.3061\n",
            "  Loss_Identity Vocal:     4.9203\n",
            "  Loss_Identity Speech:     4.9726\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5987\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1281\n",
            "  Loss_adv_speech:     0.1360\n",
            "  Loss_Cycle Vocal:     2.1654\n",
            "  Loss_Cycle Speech:     2.3054\n",
            "  Loss_Identity Vocal:     4.8860\n",
            "  Loss_Identity Speech:     4.9695\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.6002\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.1152\n",
            "  Loss_Cycle Speech:     2.2550\n",
            "  Loss_Identity Vocal:     4.8346\n",
            "  Loss_Identity Speech:     4.9371\n",
            "  Grad Norm DV:    3.4884\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    1.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.7608\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.0691\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.1129\n",
            "  Loss_Cycle Speech:     2.2467\n",
            "  Loss_Identity Vocal:     4.7875\n",
            "  Loss_Identity Speech:     4.8959\n",
            "  Grad Norm DV:    0.5436\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.6385\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1182\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     2.2237\n",
            "  Loss_Cycle Speech:     2.3507\n",
            "  Loss_Identity Vocal:     4.7798\n",
            "  Loss_Identity Speech:     4.8927\n",
            "  Grad Norm DV:    0.1584\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0083\n",
            "  Grad Norm GS:    0.0081\n",
            "  num_DV_updates:    14.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.6094\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.1434\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     2.2299\n",
            "  Loss_Cycle Speech:     2.3560\n",
            "  Loss_Identity Vocal:     4.7582\n",
            "  Loss_Identity Speech:     4.9168\n",
            "  Grad Norm DV:    0.6798\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0079\n",
            "  num_DV_updates:    5.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.7052\n",
            "  Loss_DS:         0.5946\n",
            "  Loss_adv_vocal:     0.0801\n",
            "  Loss_adv_speech:     0.1359\n",
            "  Loss_Cycle Vocal:     2.1311\n",
            "  Loss_Cycle Speech:     2.2727\n",
            "  Loss_Identity Vocal:     4.6893\n",
            "  Loss_Identity Speech:     4.8746\n",
            "  Grad Norm DV:    0.3054\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.6311\n",
            "  Loss_DS:         0.5957\n",
            "  Loss_adv_vocal:     0.1129\n",
            "  Loss_adv_speech:     0.1361\n",
            "  Loss_Cycle Vocal:     2.0647\n",
            "  Loss_Cycle Speech:     2.2290\n",
            "  Loss_Identity Vocal:     4.6129\n",
            "  Loss_Identity Speech:     4.8517\n",
            "  Grad Norm DV:    0.1984\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5974\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.0320\n",
            "  Loss_Cycle Speech:     2.1910\n",
            "  Loss_Identity Vocal:     4.5579\n",
            "  Loss_Identity Speech:     4.8260\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5978\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1359\n",
            "  Loss_Cycle Vocal:     2.0254\n",
            "  Loss_Cycle Speech:     2.2006\n",
            "  Loss_Identity Vocal:     4.5043\n",
            "  Loss_Identity Speech:     4.8129\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.0663\n",
            "  Loss_Cycle Speech:     2.2136\n",
            "  Loss_Identity Vocal:     4.4809\n",
            "  Loss_Identity Speech:     4.8084\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5980\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1282\n",
            "  Loss_adv_speech:     0.1355\n",
            "  Loss_Cycle Vocal:     2.0704\n",
            "  Loss_Cycle Speech:     2.2194\n",
            "  Loss_Identity Vocal:     4.4532\n",
            "  Loss_Identity Speech:     4.8053\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5981\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1355\n",
            "  Loss_Cycle Vocal:     2.0718\n",
            "  Loss_Cycle Speech:     2.2277\n",
            "  Loss_Identity Vocal:     4.4531\n",
            "  Loss_Identity Speech:     4.7827\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5990\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1282\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     2.0823\n",
            "  Loss_Cycle Speech:     2.2306\n",
            "  Loss_Identity Vocal:     4.3908\n",
            "  Loss_Identity Speech:     4.7964\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5982\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1357\n",
            "  Loss_Cycle Vocal:     2.0881\n",
            "  Loss_Cycle Speech:     2.2159\n",
            "  Loss_Identity Vocal:     4.3479\n",
            "  Loss_Identity Speech:     4.7781\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5985\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.0475\n",
            "  Loss_Cycle Speech:     2.1786\n",
            "  Loss_Identity Vocal:     4.2854\n",
            "  Loss_Identity Speech:     4.7347\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5985\n",
            "  Loss_DS:         0.5952\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     2.0904\n",
            "  Loss_Cycle Speech:     2.2046\n",
            "  Loss_Identity Vocal:     4.2780\n",
            "  Loss_Identity Speech:     4.7435\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5991\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     2.0656\n",
            "  Loss_Cycle Speech:     2.1769\n",
            "  Loss_Identity Vocal:     4.2174\n",
            "  Loss_Identity Speech:     4.7183\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5986\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1355\n",
            "  Loss_Cycle Vocal:     2.0830\n",
            "  Loss_Cycle Speech:     2.1916\n",
            "  Loss_Identity Vocal:     4.1925\n",
            "  Loss_Identity Speech:     4.6925\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5985\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.1358\n",
            "  Loss_Cycle Vocal:     2.0749\n",
            "  Loss_Cycle Speech:     2.2069\n",
            "  Loss_Identity Vocal:     4.1636\n",
            "  Loss_Identity Speech:     4.6830\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5991\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     2.0599\n",
            "  Loss_Cycle Speech:     2.1840\n",
            "  Loss_Identity Vocal:     4.1531\n",
            "  Loss_Identity Speech:     4.7108\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5991\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1352\n",
            "  Loss_Cycle Vocal:     2.0419\n",
            "  Loss_Cycle Speech:     2.1691\n",
            "  Loss_Identity Vocal:     4.1197\n",
            "  Loss_Identity Speech:     4.6481\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5993\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     2.0343\n",
            "  Loss_Cycle Speech:     2.1549\n",
            "  Loss_Identity Vocal:     4.0503\n",
            "  Loss_Identity Speech:     4.6251\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5995\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1281\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     2.0221\n",
            "  Loss_Cycle Speech:     2.1484\n",
            "  Loss_Identity Vocal:     4.0214\n",
            "  Loss_Identity Speech:     4.6088\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5992\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     2.0203\n",
            "  Loss_Cycle Speech:     2.1441\n",
            "  Loss_Identity Vocal:     3.9891\n",
            "  Loss_Identity Speech:     4.5943\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5995\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1276\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     2.0284\n",
            "  Loss_Cycle Speech:     2.1525\n",
            "  Loss_Identity Vocal:     4.0223\n",
            "  Loss_Identity Speech:     4.5740\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5992\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1356\n",
            "  Loss_Cycle Vocal:     1.9810\n",
            "  Loss_Cycle Speech:     2.1215\n",
            "  Loss_Identity Vocal:     3.9693\n",
            "  Loss_Identity Speech:     4.5562\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5994\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1281\n",
            "  Loss_adv_speech:     0.1360\n",
            "  Loss_Cycle Vocal:     2.0003\n",
            "  Loss_Cycle Speech:     2.1365\n",
            "  Loss_Identity Vocal:     3.9374\n",
            "  Loss_Identity Speech:     4.5301\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5992\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     1.9679\n",
            "  Loss_Cycle Speech:     2.1105\n",
            "  Loss_Identity Vocal:     3.9122\n",
            "  Loss_Identity Speech:     4.5285\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5987\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     1.9728\n",
            "  Loss_Cycle Speech:     2.1195\n",
            "  Loss_Identity Vocal:     3.8752\n",
            "  Loss_Identity Speech:     4.5198\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5992\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1352\n",
            "  Loss_Cycle Vocal:     1.9655\n",
            "  Loss_Cycle Speech:     2.1015\n",
            "  Loss_Identity Vocal:     3.8361\n",
            "  Loss_Identity Speech:     4.4909\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5999\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     1.9599\n",
            "  Loss_Cycle Speech:     2.1198\n",
            "  Loss_Identity Vocal:     3.8452\n",
            "  Loss_Identity Speech:     4.4762\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5998\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1275\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9600\n",
            "  Loss_Cycle Speech:     2.1029\n",
            "  Loss_Identity Vocal:     3.8193\n",
            "  Loss_Identity Speech:     4.4597\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5998\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1275\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     1.9155\n",
            "  Loss_Cycle Speech:     2.0741\n",
            "  Loss_Identity Vocal:     3.7653\n",
            "  Loss_Identity Speech:     4.4405\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.6004\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1276\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9201\n",
            "  Loss_Cycle Speech:     2.0830\n",
            "  Loss_Identity Vocal:     3.7360\n",
            "  Loss_Identity Speech:     4.4139\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5996\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     2.0113\n",
            "  Loss_Cycle Speech:     2.1290\n",
            "  Loss_Identity Vocal:     3.7633\n",
            "  Loss_Identity Speech:     4.4258\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0081\n",
            "  Grad Norm GS:    0.0079\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.6038\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1251\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9315\n",
            "  Loss_Cycle Speech:     2.0786\n",
            "  Loss_Identity Vocal:     3.7294\n",
            "  Loss_Identity Speech:     4.4555\n",
            "  Grad Norm DV:    1.1133\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    3.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.7172\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.0771\n",
            "  Loss_adv_speech:     0.1354\n",
            "  Loss_Cycle Vocal:     1.9226\n",
            "  Loss_Cycle Speech:     2.0663\n",
            "  Loss_Identity Vocal:     3.6996\n",
            "  Loss_Identity Speech:     4.3775\n",
            "  Grad Norm DV:    0.3229\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    15.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.6093\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1328\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9621\n",
            "  Loss_Cycle Speech:     2.0977\n",
            "  Loss_Identity Vocal:     3.7149\n",
            "  Loss_Identity Speech:     4.3708\n",
            "  Grad Norm DV:    0.5101\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    6.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.6629\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.0957\n",
            "  Loss_adv_speech:     0.1352\n",
            "  Loss_Cycle Vocal:     1.9295\n",
            "  Loss_Cycle Speech:     2.0808\n",
            "  Loss_Identity Vocal:     3.6738\n",
            "  Loss_Identity Speech:     4.3472\n",
            "  Grad Norm DV:    0.2863\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.6394\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1023\n",
            "  Loss_adv_speech:     0.1353\n",
            "  Loss_Cycle Vocal:     1.9240\n",
            "  Loss_Cycle Speech:     2.0666\n",
            "  Loss_Identity Vocal:     3.6738\n",
            "  Loss_Identity Speech:     4.3260\n",
            "  Grad Norm DV:    0.2168\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    13.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     2.0089\n",
            "  Loss_Cycle Speech:     2.1293\n",
            "  Loss_Identity Vocal:     3.6857\n",
            "  Loss_Identity Speech:     4.3110\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.1305\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9611\n",
            "  Loss_Cycle Speech:     2.1095\n",
            "  Loss_Identity Vocal:     3.6809\n",
            "  Loss_Identity Speech:     4.3377\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5886\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1301\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9638\n",
            "  Loss_Cycle Speech:     2.1092\n",
            "  Loss_Identity Vocal:     3.6618\n",
            "  Loss_Identity Speech:     4.3429\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5879\n",
            "  Loss_DS:         0.5980\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1350\n",
            "  Loss_Cycle Vocal:     1.9438\n",
            "  Loss_Cycle Speech:     2.0856\n",
            "  Loss_Identity Vocal:     3.6547\n",
            "  Loss_Identity Speech:     4.3023\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1303\n",
            "  Loss_adv_speech:     0.1355\n",
            "  Loss_Cycle Vocal:     1.9614\n",
            "  Loss_Cycle Speech:     2.0873\n",
            "  Loss_Identity Vocal:     3.6706\n",
            "  Loss_Identity Speech:     4.2988\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5877\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1304\n",
            "  Loss_adv_speech:     0.1351\n",
            "  Loss_Cycle Vocal:     1.9196\n",
            "  Loss_Cycle Speech:     2.0618\n",
            "  Loss_Identity Vocal:     3.6303\n",
            "  Loss_Identity Speech:     4.2833\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5886\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.1302\n",
            "  Loss_adv_speech:     0.1348\n",
            "  Loss_Cycle Vocal:     1.8843\n",
            "  Loss_Cycle Speech:     2.0389\n",
            "  Loss_Identity Vocal:     3.5693\n",
            "  Loss_Identity Speech:     4.2484\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5889\n",
            "  Loss_DS:         0.5990\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1337\n",
            "  Loss_Cycle Vocal:     1.8938\n",
            "  Loss_Cycle Speech:     2.0383\n",
            "  Loss_Identity Vocal:     3.6251\n",
            "  Loss_Identity Speech:     4.1948\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    1.0741\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    3.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5888\n",
            "  Loss_DS:         0.6784\n",
            "  Loss_adv_vocal:     0.1304\n",
            "  Loss_adv_speech:     0.0926\n",
            "  Loss_Cycle Vocal:     1.9436\n",
            "  Loss_Cycle Speech:     2.0709\n",
            "  Loss_Identity Vocal:     3.6091\n",
            "  Loss_Identity Speech:     4.1965\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.3489\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    13.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5888\n",
            "  Loss_DS:         0.6287\n",
            "  Loss_adv_vocal:     0.1299\n",
            "  Loss_adv_speech:     0.1141\n",
            "  Loss_Cycle Vocal:     1.9410\n",
            "  Loss_Cycle Speech:     2.0751\n",
            "  Loss_Identity Vocal:     3.6213\n",
            "  Loss_Identity Speech:     4.2056\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2175\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5889\n",
            "  Loss_DS:         0.6190\n",
            "  Loss_adv_vocal:     0.1301\n",
            "  Loss_adv_speech:     0.1172\n",
            "  Loss_Cycle Vocal:     1.9393\n",
            "  Loss_Cycle Speech:     2.0719\n",
            "  Loss_Identity Vocal:     3.5880\n",
            "  Loss_Identity Speech:     4.2015\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.5229\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    6.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5885\n",
            "  Loss_DS:         0.6591\n",
            "  Loss_adv_vocal:     0.1302\n",
            "  Loss_adv_speech:     0.0972\n",
            "  Loss_Cycle Vocal:     1.9046\n",
            "  Loss_Cycle Speech:     2.0322\n",
            "  Loss_Identity Vocal:     3.5887\n",
            "  Loss_Identity Speech:     4.1563\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2463\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    14.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5892\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1311\n",
            "  Loss_Cycle Vocal:     1.9267\n",
            "  Loss_Cycle Speech:     2.0430\n",
            "  Loss_Identity Vocal:     3.6220\n",
            "  Loss_Identity Speech:     4.2415\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5896\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1298\n",
            "  Loss_adv_speech:     0.1310\n",
            "  Loss_Cycle Vocal:     1.9324\n",
            "  Loss_Cycle Speech:     2.0686\n",
            "  Loss_Identity Vocal:     3.5661\n",
            "  Loss_Identity Speech:     4.2722\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5889\n",
            "  Loss_DS:         0.5954\n",
            "  Loss_adv_vocal:     0.1301\n",
            "  Loss_adv_speech:     0.1311\n",
            "  Loss_Cycle Vocal:     1.9176\n",
            "  Loss_Cycle Speech:     2.0456\n",
            "  Loss_Identity Vocal:     3.5458\n",
            "  Loss_Identity Speech:     4.1909\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5893\n",
            "  Loss_DS:         0.5957\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.9107\n",
            "  Loss_Cycle Speech:     2.0217\n",
            "  Loss_Identity Vocal:     3.5093\n",
            "  Loss_Identity Speech:     4.0957\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5893\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1298\n",
            "  Loss_adv_speech:     0.1311\n",
            "  Loss_Cycle Vocal:     1.9151\n",
            "  Loss_Cycle Speech:     2.0207\n",
            "  Loss_Identity Vocal:     3.5080\n",
            "  Loss_Identity Speech:     4.0844\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5884\n",
            "  Loss_DS:         0.5954\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.9082\n",
            "  Loss_Cycle Speech:     2.0348\n",
            "  Loss_Identity Vocal:     3.5204\n",
            "  Loss_Identity Speech:     4.1036\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5895\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1310\n",
            "  Loss_Cycle Vocal:     1.9081\n",
            "  Loss_Cycle Speech:     2.0302\n",
            "  Loss_Identity Vocal:     3.5427\n",
            "  Loss_Identity Speech:     4.1536\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5887\n",
            "  Loss_DS:         0.5957\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1313\n",
            "  Loss_Cycle Vocal:     1.8993\n",
            "  Loss_Cycle Speech:     2.0189\n",
            "  Loss_Identity Vocal:     3.4785\n",
            "  Loss_Identity Speech:     4.2226\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5889\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1307\n",
            "  Loss_Cycle Vocal:     1.9037\n",
            "  Loss_Cycle Speech:     2.0254\n",
            "  Loss_Identity Vocal:     3.4456\n",
            "  Loss_Identity Speech:     4.0966\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5892\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1307\n",
            "  Loss_Cycle Vocal:     1.8978\n",
            "  Loss_Cycle Speech:     2.0042\n",
            "  Loss_Identity Vocal:     3.4553\n",
            "  Loss_Identity Speech:     4.0452\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5887\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.9096\n",
            "  Loss_Cycle Speech:     2.0351\n",
            "  Loss_Identity Vocal:     3.4210\n",
            "  Loss_Identity Speech:     4.0251\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5897\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1308\n",
            "  Loss_Cycle Vocal:     1.9091\n",
            "  Loss_Cycle Speech:     2.0629\n",
            "  Loss_Identity Vocal:     3.4291\n",
            "  Loss_Identity Speech:     4.0365\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5899\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.8597\n",
            "  Loss_Cycle Speech:     1.9825\n",
            "  Loss_Identity Vocal:     3.3810\n",
            "  Loss_Identity Speech:     4.0108\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5897\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1300\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.8307\n",
            "  Loss_Cycle Speech:     1.9600\n",
            "  Loss_Identity Vocal:     3.3511\n",
            "  Loss_Identity Speech:     3.9926\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5892\n",
            "  Loss_DS:         0.5957\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1308\n",
            "  Loss_Cycle Vocal:     1.8383\n",
            "  Loss_Cycle Speech:     1.9560\n",
            "  Loss_Identity Vocal:     3.3400\n",
            "  Loss_Identity Speech:     3.9753\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5890\n",
            "  Loss_DS:         0.5952\n",
            "  Loss_adv_vocal:     0.1297\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.8875\n",
            "  Loss_Cycle Speech:     1.9983\n",
            "  Loss_Identity Vocal:     3.3829\n",
            "  Loss_Identity Speech:     3.9906\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5903\n",
            "  Loss_DS:         0.5953\n",
            "  Loss_adv_vocal:     0.1298\n",
            "  Loss_adv_speech:     0.1309\n",
            "  Loss_Cycle Vocal:     1.8941\n",
            "  Loss_Cycle Speech:     2.0075\n",
            "  Loss_Identity Vocal:     3.3854\n",
            "  Loss_Identity Speech:     4.0498\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5899\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1310\n",
            "  Loss_Cycle Vocal:     1.8836\n",
            "  Loss_Cycle Speech:     2.0048\n",
            "  Loss_Identity Vocal:     3.3715\n",
            "  Loss_Identity Speech:     4.0376\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5902\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.8705\n",
            "  Loss_Cycle Speech:     1.9956\n",
            "  Loss_Identity Vocal:     3.3581\n",
            "  Loss_Identity Speech:     3.9896\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5899\n",
            "  Loss_DS:         0.5962\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.8885\n",
            "  Loss_Cycle Speech:     2.0012\n",
            "  Loss_Identity Vocal:     3.3981\n",
            "  Loss_Identity Speech:     3.9785\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5894\n",
            "  Loss_DS:         0.5949\n",
            "  Loss_adv_vocal:     0.1292\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.8017\n",
            "  Loss_Cycle Speech:     1.9435\n",
            "  Loss_Identity Vocal:     3.2968\n",
            "  Loss_Identity Speech:     4.0930\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5898\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1308\n",
            "  Loss_Cycle Vocal:     1.8093\n",
            "  Loss_Cycle Speech:     1.9533\n",
            "  Loss_Identity Vocal:     3.2487\n",
            "  Loss_Identity Speech:     3.9425\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0083\n",
            "  Grad Norm GS:    0.0081\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5901\n",
            "  Loss_DS:         0.5958\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1309\n",
            "  Loss_Cycle Vocal:     1.8081\n",
            "  Loss_Cycle Speech:     1.9340\n",
            "  Loss_Identity Vocal:     3.2205\n",
            "  Loss_Identity Speech:     3.9052\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0088\n",
            "  Grad Norm GS:    0.0087\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5899\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1291\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7942\n",
            "  Loss_Cycle Speech:     1.9300\n",
            "  Loss_Identity Vocal:     3.2045\n",
            "  Loss_Identity Speech:     3.8753\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7880\n",
            "  Loss_Cycle Speech:     1.9332\n",
            "  Loss_Identity Vocal:     3.2077\n",
            "  Loss_Identity Speech:     3.8916\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5904\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.7789\n",
            "  Loss_Cycle Speech:     1.9420\n",
            "  Loss_Identity Vocal:     3.1899\n",
            "  Loss_Identity Speech:     3.8732\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5903\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.8236\n",
            "  Loss_Cycle Speech:     1.9619\n",
            "  Loss_Identity Vocal:     3.2044\n",
            "  Loss_Identity Speech:     3.8750\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0081\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5892\n",
            "  Loss_DS:         0.5951\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.8707\n",
            "  Loss_Cycle Speech:     2.0195\n",
            "  Loss_Identity Vocal:     3.2784\n",
            "  Loss_Identity Speech:     3.9296\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0079\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5905\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.8340\n",
            "  Loss_Cycle Speech:     1.9506\n",
            "  Loss_Identity Vocal:     3.2367\n",
            "  Loss_Identity Speech:     3.9025\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5904\n",
            "  Loss_DS:         0.5960\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.8346\n",
            "  Loss_Cycle Speech:     1.9502\n",
            "  Loss_Identity Vocal:     3.3071\n",
            "  Loss_Identity Speech:     3.8779\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5902\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1294\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.8206\n",
            "  Loss_Cycle Speech:     1.9302\n",
            "  Loss_Identity Vocal:     3.3117\n",
            "  Loss_Identity Speech:     3.8513\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5903\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.8388\n",
            "  Loss_Cycle Speech:     1.9487\n",
            "  Loss_Identity Vocal:     3.2515\n",
            "  Loss_Identity Speech:     3.8551\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5906\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1296\n",
            "  Loss_adv_speech:     0.1307\n",
            "  Loss_Cycle Vocal:     1.8249\n",
            "  Loss_Cycle Speech:     1.9349\n",
            "  Loss_Identity Vocal:     3.2240\n",
            "  Loss_Identity Speech:     3.8303\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5904\n",
            "  Loss_DS:         0.5955\n",
            "  Loss_adv_vocal:     0.1295\n",
            "  Loss_adv_speech:     0.1307\n",
            "  Loss_Cycle Vocal:     1.8241\n",
            "  Loss_Cycle Speech:     1.9445\n",
            "  Loss_Identity Vocal:     3.2628\n",
            "  Loss_Identity Speech:     3.8224\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5897\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1291\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.8161\n",
            "  Loss_Cycle Speech:     1.9340\n",
            "  Loss_Identity Vocal:     3.1917\n",
            "  Loss_Identity Speech:     3.8383\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5906\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7995\n",
            "  Loss_Cycle Speech:     1.9247\n",
            "  Loss_Identity Vocal:     3.2273\n",
            "  Loss_Identity Speech:     3.8281\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5901\n",
            "  Loss_DS:         0.5969\n",
            "  Loss_adv_vocal:     0.1292\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.8048\n",
            "  Loss_Cycle Speech:     1.9453\n",
            "  Loss_Identity Vocal:     3.2597\n",
            "  Loss_Identity Speech:     3.8349\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5903\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7963\n",
            "  Loss_Cycle Speech:     1.9384\n",
            "  Loss_Identity Vocal:     3.2166\n",
            "  Loss_Identity Speech:     3.8390\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.7756\n",
            "  Loss_Cycle Speech:     1.9115\n",
            "  Loss_Identity Vocal:     3.1560\n",
            "  Loss_Identity Speech:     3.8100\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5911\n",
            "  Loss_DS:         0.5965\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7333\n",
            "  Loss_Cycle Speech:     1.8941\n",
            "  Loss_Identity Vocal:     3.1073\n",
            "  Loss_Identity Speech:     3.8099\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5911\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1291\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.7510\n",
            "  Loss_Cycle Speech:     1.8823\n",
            "  Loss_Identity Vocal:     3.1053\n",
            "  Loss_Identity Speech:     3.7928\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5906\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.7807\n",
            "  Loss_Cycle Speech:     1.8961\n",
            "  Loss_Identity Vocal:     3.1407\n",
            "  Loss_Identity Speech:     3.7639\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5910\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7953\n",
            "  Loss_Cycle Speech:     1.9427\n",
            "  Loss_Identity Vocal:     3.1618\n",
            "  Loss_Identity Speech:     3.7837\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5959\n",
            "  Loss_adv_vocal:     0.1293\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.7346\n",
            "  Loss_Cycle Speech:     1.8817\n",
            "  Loss_Identity Vocal:     3.1124\n",
            "  Loss_Identity Speech:     3.8187\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5956\n",
            "  Loss_adv_vocal:     0.1292\n",
            "  Loss_adv_speech:     0.1307\n",
            "  Loss_Cycle Vocal:     1.7194\n",
            "  Loss_Cycle Speech:     1.8698\n",
            "  Loss_Identity Vocal:     3.0537\n",
            "  Loss_Identity Speech:     3.7490\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1291\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.7423\n",
            "  Loss_Cycle Speech:     1.9111\n",
            "  Loss_Identity Vocal:     3.0712\n",
            "  Loss_Identity Speech:     3.7609\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5912\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7450\n",
            "  Loss_Cycle Speech:     1.8789\n",
            "  Loss_Identity Vocal:     3.0943\n",
            "  Loss_Identity Speech:     3.7663\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7442\n",
            "  Loss_Cycle Speech:     1.8944\n",
            "  Loss_Identity Vocal:     3.0926\n",
            "  Loss_Identity Speech:     3.7339\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5917\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7669\n",
            "  Loss_Cycle Speech:     1.9051\n",
            "  Loss_Identity Vocal:     3.0796\n",
            "  Loss_Identity Speech:     3.7309\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5911\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1292\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7368\n",
            "  Loss_Cycle Speech:     1.8831\n",
            "  Loss_Identity Vocal:     3.1128\n",
            "  Loss_Identity Speech:     3.7539\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0062\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5913\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1286\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7014\n",
            "  Loss_Cycle Speech:     1.8405\n",
            "  Loss_Identity Vocal:     3.0555\n",
            "  Loss_Identity Speech:     3.6998\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5912\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.7380\n",
            "  Loss_Cycle Speech:     1.8675\n",
            "  Loss_Identity Vocal:     3.0606\n",
            "  Loss_Identity Speech:     3.7083\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5911\n",
            "  Loss_DS:         0.5962\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.7220\n",
            "  Loss_Cycle Speech:     1.8808\n",
            "  Loss_Identity Vocal:     3.0094\n",
            "  Loss_Identity Speech:     3.6929\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5907\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1290\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7782\n",
            "  Loss_Cycle Speech:     1.9046\n",
            "  Loss_Identity Vocal:     3.0597\n",
            "  Loss_Identity Speech:     3.7413\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5914\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1284\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.7644\n",
            "  Loss_Cycle Speech:     1.9033\n",
            "  Loss_Identity Vocal:     3.0721\n",
            "  Loss_Identity Speech:     3.7581\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.7604\n",
            "  Loss_Cycle Speech:     1.9083\n",
            "  Loss_Identity Vocal:     3.0382\n",
            "  Loss_Identity Speech:     3.6924\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5914\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.8328\n",
            "  Loss_Cycle Speech:     1.9613\n",
            "  Loss_Identity Vocal:     3.0904\n",
            "  Loss_Identity Speech:     3.7222\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0081\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5915\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1288\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7721\n",
            "  Loss_Cycle Speech:     1.9064\n",
            "  Loss_Identity Vocal:     3.0599\n",
            "  Loss_Identity Speech:     3.7111\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1289\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7193\n",
            "  Loss_Cycle Speech:     1.8610\n",
            "  Loss_Identity Vocal:     3.0232\n",
            "  Loss_Identity Speech:     3.6937\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5912\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7202\n",
            "  Loss_Cycle Speech:     1.8570\n",
            "  Loss_Identity Vocal:     3.0263\n",
            "  Loss_Identity Speech:     3.6596\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5925\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1284\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7240\n",
            "  Loss_Cycle Speech:     1.8587\n",
            "  Loss_Identity Vocal:     3.0331\n",
            "  Loss_Identity Speech:     3.6630\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5912\n",
            "  Loss_DS:         0.5970\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1297\n",
            "  Loss_Cycle Vocal:     1.8236\n",
            "  Loss_Cycle Speech:     1.9661\n",
            "  Loss_Identity Vocal:     3.1483\n",
            "  Loss_Identity Speech:     3.7047\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5914\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1284\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.7416\n",
            "  Loss_Cycle Speech:     1.8690\n",
            "  Loss_Identity Vocal:     3.0633\n",
            "  Loss_Identity Speech:     3.6666\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5916\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7020\n",
            "  Loss_Cycle Speech:     1.8409\n",
            "  Loss_Identity Vocal:     2.9748\n",
            "  Loss_Identity Speech:     3.6364\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5915\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7262\n",
            "  Loss_Cycle Speech:     1.8614\n",
            "  Loss_Identity Vocal:     2.9755\n",
            "  Loss_Identity Speech:     3.6252\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5909\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1284\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7379\n",
            "  Loss_Cycle Speech:     1.8837\n",
            "  Loss_Identity Vocal:     2.9839\n",
            "  Loss_Identity Speech:     3.6547\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5917\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7227\n",
            "  Loss_Cycle Speech:     1.8524\n",
            "  Loss_Identity Vocal:     2.9810\n",
            "  Loss_Identity Speech:     3.6311\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5917\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1291\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7267\n",
            "  Loss_Cycle Speech:     1.8616\n",
            "  Loss_Identity Vocal:     2.9995\n",
            "  Loss_Identity Speech:     3.6462\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5922\n",
            "  Loss_DS:         0.5980\n",
            "  Loss_adv_vocal:     0.1286\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7326\n",
            "  Loss_Cycle Speech:     1.8590\n",
            "  Loss_Identity Vocal:     2.9801\n",
            "  Loss_Identity Speech:     3.6283\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1303\n",
            "  Loss_Cycle Vocal:     1.7388\n",
            "  Loss_Cycle Speech:     1.8538\n",
            "  Loss_Identity Vocal:     2.9766\n",
            "  Loss_Identity Speech:     3.6164\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5921\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1285\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.7474\n",
            "  Loss_Cycle Speech:     1.8820\n",
            "  Loss_Identity Vocal:     2.9807\n",
            "  Loss_Identity Speech:     3.6367\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5916\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7345\n",
            "  Loss_Cycle Speech:     1.8684\n",
            "  Loss_Identity Vocal:     2.9788\n",
            "  Loss_Identity Speech:     3.6152\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5925\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.7404\n",
            "  Loss_Cycle Speech:     1.8576\n",
            "  Loss_Identity Vocal:     2.9526\n",
            "  Loss_Identity Speech:     3.5894\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5927\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1287\n",
            "  Loss_adv_speech:     0.1305\n",
            "  Loss_Cycle Vocal:     1.7354\n",
            "  Loss_Cycle Speech:     1.8587\n",
            "  Loss_Identity Vocal:     2.9397\n",
            "  Loss_Identity Speech:     3.5909\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5930\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1283\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.6472\n",
            "  Loss_Cycle Speech:     1.8048\n",
            "  Loss_Identity Vocal:     2.8815\n",
            "  Loss_Identity Speech:     3.5625\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0059\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5918\n",
            "  Loss_DS:         0.5979\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1306\n",
            "  Loss_Cycle Vocal:     1.7001\n",
            "  Loss_Cycle Speech:     1.8464\n",
            "  Loss_Identity Vocal:     2.9028\n",
            "  Loss_Identity Speech:     3.5649\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5923\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.7174\n",
            "  Loss_Cycle Speech:     1.8587\n",
            "  Loss_Identity Vocal:     2.9538\n",
            "  Loss_Identity Speech:     3.6418\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5929\n",
            "  Loss_DS:         0.5973\n",
            "  Loss_adv_vocal:     0.1282\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.6622\n",
            "  Loss_Cycle Speech:     1.8055\n",
            "  Loss_Identity Vocal:     2.9263\n",
            "  Loss_Identity Speech:     3.6142\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5924\n",
            "  Loss_DS:         0.5976\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.6551\n",
            "  Loss_Cycle Speech:     1.7957\n",
            "  Loss_Identity Vocal:     2.8748\n",
            "  Loss_Identity Speech:     3.5564\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5926\n",
            "  Loss_DS:         0.5962\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.6895\n",
            "  Loss_Cycle Speech:     1.8198\n",
            "  Loss_Identity Vocal:     2.8908\n",
            "  Loss_Identity Speech:     3.5510\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5918\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.7043\n",
            "  Loss_Cycle Speech:     1.8446\n",
            "  Loss_Identity Vocal:     2.9742\n",
            "  Loss_Identity Speech:     3.5405\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5928\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.6927\n",
            "  Loss_Cycle Speech:     1.8271\n",
            "  Loss_Identity Vocal:     2.9248\n",
            "  Loss_Identity Speech:     3.5563\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5929\n",
            "  Loss_DS:         0.5972\n",
            "  Loss_adv_vocal:     0.1281\n",
            "  Loss_adv_speech:     0.1296\n",
            "  Loss_Cycle Vocal:     1.6959\n",
            "  Loss_Cycle Speech:     1.8289\n",
            "  Loss_Identity Vocal:     2.9070\n",
            "  Loss_Identity Speech:     3.5280\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5922\n",
            "  Loss_DS:         0.5980\n",
            "  Loss_adv_vocal:     0.1282\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7036\n",
            "  Loss_Cycle Speech:     1.8310\n",
            "  Loss_Identity Vocal:     2.9412\n",
            "  Loss_Identity Speech:     3.6213\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.7071\n",
            "  Loss_Cycle Speech:     1.8289\n",
            "  Loss_Identity Vocal:     2.9390\n",
            "  Loss_Identity Speech:     3.6011\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5924\n",
            "  Loss_DS:         0.5975\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7068\n",
            "  Loss_Cycle Speech:     1.8166\n",
            "  Loss_Identity Vocal:     2.9460\n",
            "  Loss_Identity Speech:     3.5574\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5924\n",
            "  Loss_DS:         0.5983\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1299\n",
            "  Loss_Cycle Vocal:     1.7020\n",
            "  Loss_Cycle Speech:     1.8213\n",
            "  Loss_Identity Vocal:     2.9380\n",
            "  Loss_Identity Speech:     3.5252\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5927\n",
            "  Loss_DS:         0.5971\n",
            "  Loss_adv_vocal:     0.1277\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.7062\n",
            "  Loss_Cycle Speech:     1.8512\n",
            "  Loss_Identity Vocal:     2.8866\n",
            "  Loss_Identity Speech:     3.5376\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1300\n",
            "  Loss_Cycle Vocal:     1.6766\n",
            "  Loss_Cycle Speech:     1.8104\n",
            "  Loss_Identity Vocal:     2.8503\n",
            "  Loss_Identity Speech:     3.5696\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5927\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.1304\n",
            "  Loss_Cycle Vocal:     1.6880\n",
            "  Loss_Cycle Speech:     1.8234\n",
            "  Loss_Identity Vocal:     2.8701\n",
            "  Loss_Identity Speech:     3.5858\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5983\n",
            "  Loss_adv_vocal:     0.1279\n",
            "  Loss_adv_speech:     0.1302\n",
            "  Loss_Cycle Vocal:     1.6603\n",
            "  Loss_Cycle Speech:     1.8131\n",
            "  Loss_Identity Vocal:     2.8326\n",
            "  Loss_Identity Speech:     3.5517\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5930\n",
            "  Loss_DS:         0.5977\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1295\n",
            "  Loss_Cycle Vocal:     1.6656\n",
            "  Loss_Cycle Speech:     1.8123\n",
            "  Loss_Identity Vocal:     2.9090\n",
            "  Loss_Identity Speech:     3.5039\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5928\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1280\n",
            "  Loss_adv_speech:     0.1301\n",
            "  Loss_Cycle Vocal:     1.6927\n",
            "  Loss_Cycle Speech:     1.8149\n",
            "  Loss_Identity Vocal:     2.8924\n",
            "  Loss_Identity Speech:     3.5321\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5978\n",
            "  Loss_adv_vocal:     0.1276\n",
            "  Loss_adv_speech:     0.1297\n",
            "  Loss_Cycle Vocal:     1.6963\n",
            "  Loss_Cycle Speech:     1.8212\n",
            "  Loss_Identity Vocal:     2.8911\n",
            "  Loss_Identity Speech:     3.5537\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5989\n",
            "  Loss_adv_vocal:     0.1276\n",
            "  Loss_adv_speech:     0.1295\n",
            "  Loss_Cycle Vocal:     1.6873\n",
            "  Loss_Cycle Speech:     1.8097\n",
            "  Loss_Identity Vocal:     2.9067\n",
            "  Loss_Identity Speech:     3.5104\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    3.1151\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0062\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    1.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.6464\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1054\n",
            "  Loss_Cycle Vocal:     1.6582\n",
            "  Loss_Cycle Speech:     1.7960\n",
            "  Loss_Identity Vocal:     2.8386\n",
            "  Loss_Identity Speech:     3.5404\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.5157\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    8.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.6995\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.0845\n",
            "  Loss_Cycle Vocal:     1.6741\n",
            "  Loss_Cycle Speech:     1.8027\n",
            "  Loss_Identity Vocal:     2.8246\n",
            "  Loss_Identity Speech:     3.5217\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2121\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    17.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.6041\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.6490\n",
            "  Loss_Cycle Speech:     1.7867\n",
            "  Loss_Identity Vocal:     2.8453\n",
            "  Loss_Identity Speech:     3.4827\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    1.0054\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    3.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5938\n",
            "  Loss_DS:         0.6614\n",
            "  Loss_adv_vocal:     0.1275\n",
            "  Loss_adv_speech:     0.0943\n",
            "  Loss_Cycle Vocal:     1.6578\n",
            "  Loss_Cycle Speech:     1.7955\n",
            "  Loss_Identity Vocal:     2.8341\n",
            "  Loss_Identity Speech:     3.4705\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.3507\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    12.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.6331\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1057\n",
            "  Loss_Cycle Vocal:     1.6908\n",
            "  Loss_Cycle Speech:     1.8080\n",
            "  Loss_Identity Vocal:     2.8986\n",
            "  Loss_Identity Speech:     3.4607\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2034\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    13.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5964\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1259\n",
            "  Loss_Cycle Vocal:     1.6906\n",
            "  Loss_Cycle Speech:     1.7980\n",
            "  Loss_Identity Vocal:     2.9003\n",
            "  Loss_Identity Speech:     3.4803\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.5961\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1257\n",
            "  Loss_Cycle Vocal:     1.6642\n",
            "  Loss_Cycle Speech:     1.7869\n",
            "  Loss_Identity Vocal:     2.8579\n",
            "  Loss_Identity Speech:     3.4694\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5974\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1254\n",
            "  Loss_Cycle Vocal:     1.6244\n",
            "  Loss_Cycle Speech:     1.7610\n",
            "  Loss_Identity Vocal:     2.7931\n",
            "  Loss_Identity Speech:     3.4573\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5963\n",
            "  Loss_adv_vocal:     0.1276\n",
            "  Loss_adv_speech:     0.1256\n",
            "  Loss_Cycle Vocal:     1.6225\n",
            "  Loss_Cycle Speech:     1.7543\n",
            "  Loss_Identity Vocal:     2.7488\n",
            "  Loss_Identity Speech:     3.4345\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5967\n",
            "  Loss_adv_vocal:     0.1273\n",
            "  Loss_adv_speech:     0.1255\n",
            "  Loss_Cycle Vocal:     1.6466\n",
            "  Loss_Cycle Speech:     1.7907\n",
            "  Loss_Identity Vocal:     2.7699\n",
            "  Loss_Identity Speech:     3.4355\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5968\n",
            "  Loss_adv_vocal:     0.1278\n",
            "  Loss_adv_speech:     0.1257\n",
            "  Loss_Cycle Vocal:     1.6702\n",
            "  Loss_Cycle Speech:     1.8085\n",
            "  Loss_Identity Vocal:     2.7794\n",
            "  Loss_Identity Speech:     3.4739\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5966\n",
            "  Loss_adv_vocal:     0.1274\n",
            "  Loss_adv_speech:     0.1255\n",
            "  Loss_Cycle Vocal:     1.6324\n",
            "  Loss_Cycle Speech:     1.7951\n",
            "  Loss_Identity Vocal:     2.7937\n",
            "  Loss_Identity Speech:     3.4666\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    2.9351\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    1.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.6505\n",
            "  Loss_adv_vocal:     0.1273\n",
            "  Loss_adv_speech:     0.1005\n",
            "  Loss_Cycle Vocal:     1.6644\n",
            "  Loss_Cycle Speech:     1.7862\n",
            "  Loss_Identity Vocal:     2.9244\n",
            "  Loss_Identity Speech:     3.4599\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.5121\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    8.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.6914\n",
            "  Loss_adv_vocal:     0.1272\n",
            "  Loss_adv_speech:     0.0860\n",
            "  Loss_Cycle Vocal:     1.6842\n",
            "  Loss_Cycle Speech:     1.8003\n",
            "  Loss_Identity Vocal:     2.9192\n",
            "  Loss_Identity Speech:     3.4372\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2083\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    16.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5938\n",
            "  Loss_DS:         0.6056\n",
            "  Loss_adv_vocal:     0.1273\n",
            "  Loss_adv_speech:     0.1257\n",
            "  Loss_Cycle Vocal:     1.6173\n",
            "  Loss_Cycle Speech:     1.7731\n",
            "  Loss_Identity Vocal:     2.7846\n",
            "  Loss_Identity Speech:     3.4220\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.7210\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    4.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.6491\n",
            "  Loss_adv_vocal:     0.1271\n",
            "  Loss_adv_speech:     0.0959\n",
            "  Loss_Cycle Vocal:     1.6004\n",
            "  Loss_Cycle Speech:     1.7451\n",
            "  Loss_Identity Vocal:     2.7242\n",
            "  Loss_Identity Speech:     3.4001\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.3490\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    11.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.6362\n",
            "  Loss_adv_vocal:     0.1275\n",
            "  Loss_adv_speech:     0.1008\n",
            "  Loss_Cycle Vocal:     1.6420\n",
            "  Loss_Cycle Speech:     1.7902\n",
            "  Loss_Identity Vocal:     2.7634\n",
            "  Loss_Identity Speech:     3.4241\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.2010\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    14.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5854\n",
            "  Loss_adv_vocal:     0.1275\n",
            "  Loss_adv_speech:     0.1284\n",
            "  Loss_Cycle Vocal:     1.6246\n",
            "  Loss_Cycle Speech:     1.7554\n",
            "  Loss_Identity Vocal:     2.7529\n",
            "  Loss_Identity Speech:     3.4867\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5936\n",
            "  Loss_DS:         0.5847\n",
            "  Loss_adv_vocal:     0.1272\n",
            "  Loss_adv_speech:     0.1283\n",
            "  Loss_Cycle Vocal:     1.6081\n",
            "  Loss_Cycle Speech:     1.7607\n",
            "  Loss_Identity Vocal:     2.7537\n",
            "  Loss_Identity Speech:     3.4127\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5852\n",
            "  Loss_adv_vocal:     0.1272\n",
            "  Loss_adv_speech:     0.1281\n",
            "  Loss_Cycle Vocal:     1.6489\n",
            "  Loss_Cycle Speech:     1.7828\n",
            "  Loss_Identity Vocal:     2.7635\n",
            "  Loss_Identity Speech:     3.3884\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5853\n",
            "  Loss_adv_vocal:     0.1273\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.6480\n",
            "  Loss_Cycle Speech:     1.7730\n",
            "  Loss_Identity Vocal:     2.7650\n",
            "  Loss_Identity Speech:     3.3917\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5852\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.6417\n",
            "  Loss_Cycle Speech:     1.7700\n",
            "  Loss_Identity Vocal:     2.7618\n",
            "  Loss_Identity Speech:     3.4187\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1272\n",
            "  Loss_adv_speech:     0.1282\n",
            "  Loss_Cycle Vocal:     1.6407\n",
            "  Loss_Cycle Speech:     1.7787\n",
            "  Loss_Identity Vocal:     2.7725\n",
            "  Loss_Identity Speech:     3.4339\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.6721\n",
            "  Loss_Cycle Speech:     1.8042\n",
            "  Loss_Identity Vocal:     2.7744\n",
            "  Loss_Identity Speech:     3.4140\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5851\n",
            "  Loss_adv_vocal:     0.1271\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.6351\n",
            "  Loss_Cycle Speech:     1.7737\n",
            "  Loss_Identity Vocal:     2.7559\n",
            "  Loss_Identity Speech:     3.4028\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5851\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1283\n",
            "  Loss_Cycle Vocal:     1.6293\n",
            "  Loss_Cycle Speech:     1.7731\n",
            "  Loss_Identity Vocal:     2.7299\n",
            "  Loss_Identity Speech:     3.4087\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5852\n",
            "  Loss_adv_vocal:     0.1265\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.6406\n",
            "  Loss_Cycle Speech:     1.7716\n",
            "  Loss_Identity Vocal:     2.7709\n",
            "  Loss_Identity Speech:     3.4364\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5854\n",
            "  Loss_adv_vocal:     0.1267\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.6042\n",
            "  Loss_Cycle Speech:     1.7424\n",
            "  Loss_Identity Vocal:     2.7640\n",
            "  Loss_Identity Speech:     3.4128\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5851\n",
            "  Loss_adv_vocal:     0.1271\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5970\n",
            "  Loss_Cycle Speech:     1.7416\n",
            "  Loss_Identity Vocal:     2.6931\n",
            "  Loss_Identity Speech:     3.3975\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5851\n",
            "  Loss_adv_vocal:     0.1272\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5799\n",
            "  Loss_Cycle Speech:     1.7393\n",
            "  Loss_Identity Vocal:     2.6683\n",
            "  Loss_Identity Speech:     3.3488\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1271\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5685\n",
            "  Loss_Cycle Speech:     1.7308\n",
            "  Loss_Identity Vocal:     2.6577\n",
            "  Loss_Identity Speech:     3.3555\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5849\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5860\n",
            "  Loss_Cycle Speech:     1.7241\n",
            "  Loss_Identity Vocal:     2.6649\n",
            "  Loss_Identity Speech:     3.3116\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5853\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1282\n",
            "  Loss_Cycle Vocal:     1.6121\n",
            "  Loss_Cycle Speech:     1.7416\n",
            "  Loss_Identity Vocal:     2.6788\n",
            "  Loss_Identity Speech:     3.3285\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5951\n",
            "  Loss_DS:         0.5857\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5816\n",
            "  Loss_Cycle Speech:     1.7288\n",
            "  Loss_Identity Vocal:     2.6756\n",
            "  Loss_Identity Speech:     3.3269\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5857\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1281\n",
            "  Loss_Cycle Vocal:     1.5759\n",
            "  Loss_Cycle Speech:     1.7201\n",
            "  Loss_Identity Vocal:     2.6540\n",
            "  Loss_Identity Speech:     3.3222\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5780\n",
            "  Loss_Cycle Speech:     1.7145\n",
            "  Loss_Identity Vocal:     2.6783\n",
            "  Loss_Identity Speech:     3.3398\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5861\n",
            "  Loss_adv_vocal:     0.1273\n",
            "  Loss_adv_speech:     0.1282\n",
            "  Loss_Cycle Vocal:     1.5645\n",
            "  Loss_Cycle Speech:     1.7130\n",
            "  Loss_Identity Vocal:     2.7000\n",
            "  Loss_Identity Speech:     3.3427\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5858\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5490\n",
            "  Loss_Cycle Speech:     1.6985\n",
            "  Loss_Identity Vocal:     2.6678\n",
            "  Loss_Identity Speech:     3.3209\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0061\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5850\n",
            "  Loss_adv_vocal:     0.1271\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5984\n",
            "  Loss_Cycle Speech:     1.7296\n",
            "  Loss_Identity Vocal:     2.6654\n",
            "  Loss_Identity Speech:     3.3182\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5861\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5866\n",
            "  Loss_Cycle Speech:     1.7206\n",
            "  Loss_Identity Vocal:     2.6690\n",
            "  Loss_Identity Speech:     3.3392\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1270\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5688\n",
            "  Loss_Cycle Speech:     1.7170\n",
            "  Loss_Identity Vocal:     2.6409\n",
            "  Loss_Identity Speech:     3.3129\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5857\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.5858\n",
            "  Loss_Cycle Speech:     1.7313\n",
            "  Loss_Identity Vocal:     2.6528\n",
            "  Loss_Identity Speech:     3.3167\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1284\n",
            "  Loss_Cycle Vocal:     1.5702\n",
            "  Loss_Cycle Speech:     1.7098\n",
            "  Loss_Identity Vocal:     2.6750\n",
            "  Loss_Identity Speech:     3.3451\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.6078\n",
            "  Loss_Cycle Speech:     1.7522\n",
            "  Loss_Identity Vocal:     2.6706\n",
            "  Loss_Identity Speech:     3.4063\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5858\n",
            "  Loss_adv_vocal:     0.1267\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5938\n",
            "  Loss_Cycle Speech:     1.7376\n",
            "  Loss_Identity Vocal:     2.6824\n",
            "  Loss_Identity Speech:     3.4346\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5849\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5914\n",
            "  Loss_Cycle Speech:     1.7244\n",
            "  Loss_Identity Vocal:     2.6667\n",
            "  Loss_Identity Speech:     3.3697\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5853\n",
            "  Loss_adv_vocal:     0.1267\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5732\n",
            "  Loss_Cycle Speech:     1.7105\n",
            "  Loss_Identity Vocal:     2.6489\n",
            "  Loss_Identity Speech:     3.3173\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1265\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.5595\n",
            "  Loss_Cycle Speech:     1.7002\n",
            "  Loss_Identity Vocal:     2.6261\n",
            "  Loss_Identity Speech:     3.3609\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5854\n",
            "  Loss_adv_vocal:     0.1267\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5888\n",
            "  Loss_Cycle Speech:     1.7401\n",
            "  Loss_Identity Vocal:     2.6588\n",
            "  Loss_Identity Speech:     3.3327\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5857\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5732\n",
            "  Loss_Cycle Speech:     1.7157\n",
            "  Loss_Identity Vocal:     2.6348\n",
            "  Loss_Identity Speech:     3.3028\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5708\n",
            "  Loss_Cycle Speech:     1.7064\n",
            "  Loss_Identity Vocal:     2.6303\n",
            "  Loss_Identity Speech:     3.2879\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5832\n",
            "  Loss_Cycle Speech:     1.7163\n",
            "  Loss_Identity Vocal:     2.6257\n",
            "  Loss_Identity Speech:     3.3426\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5832\n",
            "  Loss_Cycle Speech:     1.7292\n",
            "  Loss_Identity Vocal:     2.6216\n",
            "  Loss_Identity Speech:     3.3272\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5857\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5775\n",
            "  Loss_Cycle Speech:     1.7162\n",
            "  Loss_Identity Vocal:     2.6138\n",
            "  Loss_Identity Speech:     3.2804\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.6948\n",
            "  Loss_Cycle Speech:     1.9211\n",
            "  Loss_Identity Vocal:     2.8606\n",
            "  Loss_Identity Speech:     3.3454\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5951\n",
            "  Loss_DS:         0.5856\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5948\n",
            "  Loss_Cycle Speech:     1.7108\n",
            "  Loss_Identity Vocal:     2.7515\n",
            "  Loss_Identity Speech:     3.2943\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1269\n",
            "  Loss_adv_speech:     0.1281\n",
            "  Loss_Cycle Vocal:     1.5757\n",
            "  Loss_Cycle Speech:     1.7121\n",
            "  Loss_Identity Vocal:     2.6536\n",
            "  Loss_Identity Speech:     3.2852\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5853\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5392\n",
            "  Loss_Cycle Speech:     1.6855\n",
            "  Loss_Identity Vocal:     2.6243\n",
            "  Loss_Identity Speech:     3.2492\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5854\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5678\n",
            "  Loss_Cycle Speech:     1.7064\n",
            "  Loss_Identity Vocal:     2.6062\n",
            "  Loss_Identity Speech:     3.2519\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5885\n",
            "  Loss_Cycle Speech:     1.7265\n",
            "  Loss_Identity Vocal:     2.6116\n",
            "  Loss_Identity Speech:     3.4685\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5863\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.6409\n",
            "  Loss_Cycle Speech:     1.7569\n",
            "  Loss_Identity Vocal:     2.6424\n",
            "  Loss_Identity Speech:     3.4362\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.8040\n",
            "  Loss_Cycle Speech:     1.8828\n",
            "  Loss_Identity Vocal:     2.7528\n",
            "  Loss_Identity Speech:     3.3371\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0094\n",
            "  Grad Norm GS:    0.0091\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.6676\n",
            "  Loss_Cycle Speech:     1.7993\n",
            "  Loss_Identity Vocal:     2.7079\n",
            "  Loss_Identity Speech:     3.3288\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5850\n",
            "  Loss_adv_vocal:     0.1265\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5950\n",
            "  Loss_Cycle Speech:     1.7455\n",
            "  Loss_Identity Vocal:     2.6563\n",
            "  Loss_Identity Speech:     3.3003\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1267\n",
            "  Loss_adv_speech:     0.1281\n",
            "  Loss_Cycle Vocal:     1.5163\n",
            "  Loss_Cycle Speech:     1.6701\n",
            "  Loss_Identity Vocal:     2.5713\n",
            "  Loss_Identity Speech:     3.2407\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5114\n",
            "  Loss_Cycle Speech:     1.6722\n",
            "  Loss_Identity Vocal:     2.5415\n",
            "  Loss_Identity Speech:     3.2557\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5868\n",
            "  Loss_adv_vocal:     0.1265\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5258\n",
            "  Loss_Cycle Speech:     1.6754\n",
            "  Loss_Identity Vocal:     2.5471\n",
            "  Loss_Identity Speech:     3.2347\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5961\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1261\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5503\n",
            "  Loss_Cycle Speech:     1.6806\n",
            "  Loss_Identity Vocal:     2.5672\n",
            "  Loss_Identity Speech:     3.2482\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5514\n",
            "  Loss_Cycle Speech:     1.6779\n",
            "  Loss_Identity Vocal:     2.5871\n",
            "  Loss_Identity Speech:     3.2758\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5967\n",
            "  Loss_DS:         0.5854\n",
            "  Loss_adv_vocal:     0.1264\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.5051\n",
            "  Loss_Cycle Speech:     1.6496\n",
            "  Loss_Identity Vocal:     2.6620\n",
            "  Loss_Identity Speech:     3.2836\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5307\n",
            "  Loss_Cycle Speech:     1.6798\n",
            "  Loss_Identity Vocal:     2.5841\n",
            "  Loss_Identity Speech:     3.2299\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5967\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1268\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5454\n",
            "  Loss_Cycle Speech:     1.7039\n",
            "  Loss_Identity Vocal:     2.5649\n",
            "  Loss_Identity Speech:     3.2260\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5855\n",
            "  Loss_adv_vocal:     0.1266\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5526\n",
            "  Loss_Cycle Speech:     1.7147\n",
            "  Loss_Identity Vocal:     2.5790\n",
            "  Loss_Identity Speech:     3.2398\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5955\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.6390\n",
            "  Loss_Cycle Speech:     1.7631\n",
            "  Loss_Identity Vocal:     2.7716\n",
            "  Loss_Identity Speech:     3.2800\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.5270\n",
            "  Loss_Cycle Speech:     1.6519\n",
            "  Loss_Identity Vocal:     2.9191\n",
            "  Loss_Identity Speech:     3.3164\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0060\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5861\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.5030\n",
            "  Loss_Cycle Speech:     1.6487\n",
            "  Loss_Identity Vocal:     2.6076\n",
            "  Loss_Identity Speech:     3.2422\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5965\n",
            "  Loss_DS:         0.5856\n",
            "  Loss_adv_vocal:     0.1264\n",
            "  Loss_adv_speech:     0.1280\n",
            "  Loss_Cycle Vocal:     1.5560\n",
            "  Loss_Cycle Speech:     1.6860\n",
            "  Loss_Identity Vocal:     2.5720\n",
            "  Loss_Identity Speech:     3.2097\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1265\n",
            "  Loss_adv_speech:     0.1281\n",
            "  Loss_Cycle Vocal:     1.5821\n",
            "  Loss_Cycle Speech:     1.7056\n",
            "  Loss_Identity Vocal:     2.5857\n",
            "  Loss_Identity Speech:     3.2166\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5954\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1264\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.6368\n",
            "  Loss_Cycle Speech:     1.7860\n",
            "  Loss_Identity Vocal:     2.6862\n",
            "  Loss_Identity Speech:     3.2477\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0086\n",
            "  Grad Norm GS:    0.0084\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5961\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1279\n",
            "  Loss_Cycle Vocal:     1.5351\n",
            "  Loss_Cycle Speech:     1.6847\n",
            "  Loss_Identity Vocal:     2.5743\n",
            "  Loss_Identity Speech:     3.2139\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5961\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.5021\n",
            "  Loss_Cycle Speech:     1.6482\n",
            "  Loss_Identity Vocal:     2.5454\n",
            "  Loss_Identity Speech:     3.2079\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5261\n",
            "  Loss_Cycle Speech:     1.6586\n",
            "  Loss_Identity Vocal:     2.5405\n",
            "  Loss_Identity Speech:     3.1896\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.4958\n",
            "  Loss_Cycle Speech:     1.6469\n",
            "  Loss_Identity Vocal:     2.5261\n",
            "  Loss_Identity Speech:     3.1730\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5957\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1277\n",
            "  Loss_Cycle Vocal:     1.4927\n",
            "  Loss_Cycle Speech:     1.6443\n",
            "  Loss_Identity Vocal:     2.5133\n",
            "  Loss_Identity Speech:     3.1870\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5958\n",
            "  Loss_DS:         0.5870\n",
            "  Loss_adv_vocal:     0.1261\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.5339\n",
            "  Loss_Cycle Speech:     1.6684\n",
            "  Loss_Identity Vocal:     2.5455\n",
            "  Loss_Identity Speech:     3.1861\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5968\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5208\n",
            "  Loss_Cycle Speech:     1.6703\n",
            "  Loss_Identity Vocal:     2.5153\n",
            "  Loss_Identity Speech:     3.1896\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5965\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.4613\n",
            "  Loss_Cycle Speech:     1.6245\n",
            "  Loss_Identity Vocal:     2.4740\n",
            "  Loss_Identity Speech:     3.1691\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5968\n",
            "  Loss_DS:         0.5863\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4722\n",
            "  Loss_Cycle Speech:     1.6210\n",
            "  Loss_Identity Vocal:     2.4699\n",
            "  Loss_Identity Speech:     3.1955\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1259\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4929\n",
            "  Loss_Cycle Speech:     1.6257\n",
            "  Loss_Identity Vocal:     2.4814\n",
            "  Loss_Identity Speech:     3.1997\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5969\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5821\n",
            "  Loss_Cycle Speech:     1.8019\n",
            "  Loss_Identity Vocal:     2.6832\n",
            "  Loss_Identity Speech:     3.2405\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5959\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5272\n",
            "  Loss_Cycle Speech:     1.7140\n",
            "  Loss_Identity Vocal:     2.9783\n",
            "  Loss_Identity Speech:     3.2439\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0062\n",
            "  Grad Norm GS:    0.0059\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5958\n",
            "  Loss_DS:         0.5863\n",
            "  Loss_adv_vocal:     0.1263\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5167\n",
            "  Loss_Cycle Speech:     1.6426\n",
            "  Loss_Identity Vocal:     2.6810\n",
            "  Loss_Identity Speech:     3.1963\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5523\n",
            "  Loss_Cycle Speech:     1.6838\n",
            "  Loss_Identity Vocal:     2.6240\n",
            "  Loss_Identity Speech:     3.1903\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.6046\n",
            "  Loss_Cycle Speech:     1.7183\n",
            "  Loss_Identity Vocal:     2.6459\n",
            "  Loss_Identity Speech:     3.1877\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0084\n",
            "  Grad Norm GS:    0.0082\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5964\n",
            "  Loss_DS:         0.5863\n",
            "  Loss_adv_vocal:     0.1261\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.5156\n",
            "  Loss_Cycle Speech:     1.6434\n",
            "  Loss_Identity Vocal:     2.5866\n",
            "  Loss_Identity Speech:     3.2041\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5966\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4624\n",
            "  Loss_Cycle Speech:     1.6121\n",
            "  Loss_Identity Vocal:     2.5269\n",
            "  Loss_Identity Speech:     3.1628\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5859\n",
            "  Loss_adv_vocal:     0.1261\n",
            "  Loss_adv_speech:     0.1278\n",
            "  Loss_Cycle Vocal:     1.5351\n",
            "  Loss_Cycle Speech:     1.6751\n",
            "  Loss_Identity Vocal:     2.5365\n",
            "  Loss_Identity Speech:     3.1547\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5963\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.6032\n",
            "  Loss_Cycle Speech:     1.7348\n",
            "  Loss_Identity Vocal:     2.5696\n",
            "  Loss_Identity Speech:     3.2040\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0083\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5966\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5416\n",
            "  Loss_Cycle Speech:     1.6875\n",
            "  Loss_Identity Vocal:     2.5404\n",
            "  Loss_Identity Speech:     3.2164\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5972\n",
            "  Loss_DS:         0.5864\n",
            "  Loss_adv_vocal:     0.1262\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4986\n",
            "  Loss_Cycle Speech:     1.6506\n",
            "  Loss_Identity Vocal:     2.5475\n",
            "  Loss_Identity Speech:     3.2177\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4971\n",
            "  Loss_Cycle Speech:     1.6446\n",
            "  Loss_Identity Vocal:     2.5384\n",
            "  Loss_Identity Speech:     3.1772\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5860\n",
            "  Loss_adv_vocal:     0.1258\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4707\n",
            "  Loss_Cycle Speech:     1.6192\n",
            "  Loss_Identity Vocal:     2.4835\n",
            "  Loss_Identity Speech:     3.1559\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5870\n",
            "  Loss_adv_vocal:     0.1258\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4938\n",
            "  Loss_Cycle Speech:     1.6341\n",
            "  Loss_Identity Vocal:     2.4785\n",
            "  Loss_Identity Speech:     3.1396\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5971\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1259\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4502\n",
            "  Loss_Cycle Speech:     1.6093\n",
            "  Loss_Identity Vocal:     2.4799\n",
            "  Loss_Identity Speech:     3.1333\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5969\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4780\n",
            "  Loss_Cycle Speech:     1.6180\n",
            "  Loss_Identity Vocal:     2.4965\n",
            "  Loss_Identity Speech:     3.1320\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1261\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5079\n",
            "  Loss_Cycle Speech:     1.6469\n",
            "  Loss_Identity Vocal:     2.5202\n",
            "  Loss_Identity Speech:     3.1953\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5960\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5396\n",
            "  Loss_Cycle Speech:     1.6660\n",
            "  Loss_Identity Vocal:     2.5098\n",
            "  Loss_Identity Speech:     3.1790\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5968\n",
            "  Loss_DS:         0.5870\n",
            "  Loss_adv_vocal:     0.1255\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.5101\n",
            "  Loss_Cycle Speech:     1.6451\n",
            "  Loss_Identity Vocal:     2.4894\n",
            "  Loss_Identity Speech:     3.1572\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5974\n",
            "  Loss_DS:         0.5863\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4876\n",
            "  Loss_Cycle Speech:     1.6184\n",
            "  Loss_Identity Vocal:     2.4948\n",
            "  Loss_Identity Speech:     3.1386\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5967\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1259\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4620\n",
            "  Loss_Cycle Speech:     1.6142\n",
            "  Loss_Identity Vocal:     2.4569\n",
            "  Loss_Identity Speech:     3.1250\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0065\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5871\n",
            "  Loss_adv_vocal:     0.1258\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5206\n",
            "  Loss_Cycle Speech:     1.6518\n",
            "  Loss_Identity Vocal:     2.4663\n",
            "  Loss_Identity Speech:     3.1244\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5968\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4423\n",
            "  Loss_Cycle Speech:     1.5858\n",
            "  Loss_Identity Vocal:     2.4368\n",
            "  Loss_Identity Speech:     3.1162\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5967\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1256\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.4401\n",
            "  Loss_Cycle Speech:     1.5790\n",
            "  Loss_Identity Vocal:     2.4413\n",
            "  Loss_Identity Speech:     3.1087\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5970\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4485\n",
            "  Loss_Cycle Speech:     1.6038\n",
            "  Loss_Identity Vocal:     2.4301\n",
            "  Loss_Identity Speech:     3.1105\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5972\n",
            "  Loss_DS:         0.5871\n",
            "  Loss_adv_vocal:     0.1260\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4428\n",
            "  Loss_Cycle Speech:     1.6033\n",
            "  Loss_Identity Vocal:     2.4318\n",
            "  Loss_Identity Speech:     3.1588\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5971\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1259\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4738\n",
            "  Loss_Cycle Speech:     1.6432\n",
            "  Loss_Identity Vocal:     2.4436\n",
            "  Loss_Identity Speech:     3.1437\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5975\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4531\n",
            "  Loss_Cycle Speech:     1.6058\n",
            "  Loss_Identity Vocal:     2.4336\n",
            "  Loss_Identity Speech:     3.1247\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5976\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4733\n",
            "  Loss_Cycle Speech:     1.6246\n",
            "  Loss_Identity Vocal:     2.4310\n",
            "  Loss_Identity Speech:     3.1146\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5966\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4757\n",
            "  Loss_Cycle Speech:     1.6226\n",
            "  Loss_Identity Vocal:     2.4517\n",
            "  Loss_Identity Speech:     3.1206\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5971\n",
            "  Loss_DS:         0.5865\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.4633\n",
            "  Loss_Cycle Speech:     1.6019\n",
            "  Loss_Identity Vocal:     2.4318\n",
            "  Loss_Identity Speech:     3.1008\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5974\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1256\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.4738\n",
            "  Loss_Cycle Speech:     1.6141\n",
            "  Loss_Identity Vocal:     2.4388\n",
            "  Loss_Identity Speech:     3.1060\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5979\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1249\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4812\n",
            "  Loss_Cycle Speech:     1.6319\n",
            "  Loss_Identity Vocal:     2.4725\n",
            "  Loss_Identity Speech:     3.1524\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5982\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.4633\n",
            "  Loss_Cycle Speech:     1.6099\n",
            "  Loss_Identity Vocal:     2.4749\n",
            "  Loss_Identity Speech:     3.1658\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5977\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1257\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4509\n",
            "  Loss_Cycle Speech:     1.5883\n",
            "  Loss_Identity Vocal:     2.4473\n",
            "  Loss_Identity Speech:     3.1116\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5977\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1252\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4619\n",
            "  Loss_Cycle Speech:     1.6085\n",
            "  Loss_Identity Vocal:     2.4247\n",
            "  Loss_Identity Speech:     3.1101\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5975\n",
            "  Loss_DS:         0.5877\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4719\n",
            "  Loss_Cycle Speech:     1.6065\n",
            "  Loss_Identity Vocal:     2.4363\n",
            "  Loss_Identity Speech:     3.1201\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5981\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1255\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4773\n",
            "  Loss_Cycle Speech:     1.6211\n",
            "  Loss_Identity Vocal:     2.4179\n",
            "  Loss_Identity Speech:     3.1278\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5975\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1253\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4204\n",
            "  Loss_Cycle Speech:     1.5854\n",
            "  Loss_Identity Vocal:     2.4070\n",
            "  Loss_Identity Speech:     3.1089\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5985\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1252\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4508\n",
            "  Loss_Cycle Speech:     1.5996\n",
            "  Loss_Identity Vocal:     2.3911\n",
            "  Loss_Identity Speech:     3.0911\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5981\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1251\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3979\n",
            "  Loss_Cycle Speech:     1.5605\n",
            "  Loss_Identity Vocal:     2.3685\n",
            "  Loss_Identity Speech:     3.0685\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5983\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1255\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4220\n",
            "  Loss_Cycle Speech:     1.5755\n",
            "  Loss_Identity Vocal:     2.3790\n",
            "  Loss_Identity Speech:     3.0550\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5983\n",
            "  Loss_DS:         0.5868\n",
            "  Loss_adv_vocal:     0.1255\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.4425\n",
            "  Loss_Cycle Speech:     1.5733\n",
            "  Loss_Identity Vocal:     2.3946\n",
            "  Loss_Identity Speech:     3.0680\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5980\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1275\n",
            "  Loss_Cycle Vocal:     1.4214\n",
            "  Loss_Cycle Speech:     1.5781\n",
            "  Loss_Identity Vocal:     2.3897\n",
            "  Loss_Identity Speech:     3.0829\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5983\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4927\n",
            "  Loss_Cycle Speech:     1.6167\n",
            "  Loss_Identity Vocal:     2.4104\n",
            "  Loss_Identity Speech:     3.0627\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0082\n",
            "  Grad Norm GS:    0.0080\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5868\n",
            "  Loss_adv_vocal:     0.1254\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4351\n",
            "  Loss_Cycle Speech:     1.5902\n",
            "  Loss_Identity Vocal:     2.3891\n",
            "  Loss_Identity Speech:     3.0787\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5979\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1250\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4507\n",
            "  Loss_Cycle Speech:     1.5904\n",
            "  Loss_Identity Vocal:     2.3902\n",
            "  Loss_Identity Speech:     3.0845\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5973\n",
            "  Loss_DS:         0.5867\n",
            "  Loss_adv_vocal:     0.1250\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4208\n",
            "  Loss_Cycle Speech:     1.5706\n",
            "  Loss_Identity Vocal:     2.3837\n",
            "  Loss_Identity Speech:     3.0792\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5871\n",
            "  Loss_adv_vocal:     0.1249\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4069\n",
            "  Loss_Cycle Speech:     1.5583\n",
            "  Loss_Identity Vocal:     2.3757\n",
            "  Loss_Identity Speech:     3.0698\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5982\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1252\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4440\n",
            "  Loss_Cycle Speech:     1.6049\n",
            "  Loss_Identity Vocal:     2.4034\n",
            "  Loss_Identity Speech:     3.0794\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5977\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1250\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4561\n",
            "  Loss_Cycle Speech:     1.6159\n",
            "  Loss_Identity Vocal:     2.4165\n",
            "  Loss_Identity Speech:     3.0712\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5979\n",
            "  Loss_DS:         0.5866\n",
            "  Loss_adv_vocal:     0.1253\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4376\n",
            "  Loss_Cycle Speech:     1.5795\n",
            "  Loss_Identity Vocal:     2.4022\n",
            "  Loss_Identity Speech:     3.0504\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5980\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1252\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.4598\n",
            "  Loss_Cycle Speech:     1.6125\n",
            "  Loss_Identity Vocal:     2.3953\n",
            "  Loss_Identity Speech:     3.0769\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5979\n",
            "  Loss_DS:         0.5870\n",
            "  Loss_adv_vocal:     0.1251\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4609\n",
            "  Loss_Cycle Speech:     1.6167\n",
            "  Loss_Identity Vocal:     2.4458\n",
            "  Loss_Identity Speech:     3.0826\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5984\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1248\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4545\n",
            "  Loss_Cycle Speech:     1.5986\n",
            "  Loss_Identity Vocal:     2.4503\n",
            "  Loss_Identity Speech:     3.0957\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5986\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1249\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4363\n",
            "  Loss_Cycle Speech:     1.5747\n",
            "  Loss_Identity Vocal:     2.4354\n",
            "  Loss_Identity Speech:     3.0926\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5988\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1248\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4629\n",
            "  Loss_Cycle Speech:     1.6102\n",
            "  Loss_Identity Vocal:     2.4357\n",
            "  Loss_Identity Speech:     3.1032\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5993\n",
            "  Loss_DS:         0.5871\n",
            "  Loss_adv_vocal:     0.1248\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4307\n",
            "  Loss_Cycle Speech:     1.5633\n",
            "  Loss_Identity Vocal:     2.4113\n",
            "  Loss_Identity Speech:     3.0489\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5981\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1249\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4098\n",
            "  Loss_Cycle Speech:     1.5610\n",
            "  Loss_Identity Vocal:     2.3565\n",
            "  Loss_Identity Speech:     3.0711\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.6002\n",
            "  Loss_DS:         0.5881\n",
            "  Loss_adv_vocal:     0.1245\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.4078\n",
            "  Loss_Cycle Speech:     1.5522\n",
            "  Loss_Identity Vocal:     2.3536\n",
            "  Loss_Identity Speech:     3.0400\n",
            "  Grad Norm DV:    3.1515\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    1.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.7159\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.0796\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4114\n",
            "  Loss_Cycle Speech:     1.5713\n",
            "  Loss_Identity Vocal:     2.3512\n",
            "  Loss_Identity Speech:     3.0651\n",
            "  Grad Norm DV:    0.5493\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    11.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.6582\n",
            "  Loss_DS:         0.5869\n",
            "  Loss_adv_vocal:     0.1049\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.4651\n",
            "  Loss_Cycle Speech:     1.5945\n",
            "  Loss_Identity Vocal:     2.3823\n",
            "  Loss_Identity Speech:     3.0375\n",
            "  Grad Norm DV:    0.1440\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0079\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    16.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5938\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1511\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.5756\n",
            "  Loss_Cycle Speech:     1.6876\n",
            "  Loss_Identity Vocal:     2.4510\n",
            "  Loss_Identity Speech:     3.0809\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0086\n",
            "  Grad Norm GS:    0.0083\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.5056\n",
            "  Loss_Cycle Speech:     1.6269\n",
            "  Loss_Identity Vocal:     2.4666\n",
            "  Loss_Identity Speech:     3.0830\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4118\n",
            "  Loss_Cycle Speech:     1.5676\n",
            "  Loss_Identity Vocal:     2.3789\n",
            "  Loss_Identity Speech:     3.0795\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1510\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.3910\n",
            "  Loss_Cycle Speech:     1.5548\n",
            "  Loss_Identity Vocal:     2.3367\n",
            "  Loss_Identity Speech:     3.0766\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.3732\n",
            "  Loss_Cycle Speech:     1.5304\n",
            "  Loss_Identity Vocal:     2.3208\n",
            "  Loss_Identity Speech:     3.0198\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.3861\n",
            "  Loss_Cycle Speech:     1.5362\n",
            "  Loss_Identity Vocal:     2.3182\n",
            "  Loss_Identity Speech:     3.0102\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5931\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1510\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.3646\n",
            "  Loss_Cycle Speech:     1.5224\n",
            "  Loss_Identity Vocal:     2.3160\n",
            "  Loss_Identity Speech:     3.0057\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0065\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1508\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3964\n",
            "  Loss_Cycle Speech:     1.5445\n",
            "  Loss_Identity Vocal:     2.3319\n",
            "  Loss_Identity Speech:     3.0113\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.4536\n",
            "  Loss_Cycle Speech:     1.5861\n",
            "  Loss_Identity Vocal:     2.3862\n",
            "  Loss_Identity Speech:     3.0519\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5932\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1510\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3744\n",
            "  Loss_Cycle Speech:     1.5502\n",
            "  Loss_Identity Vocal:     2.3349\n",
            "  Loss_Identity Speech:     3.0347\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1511\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3730\n",
            "  Loss_Cycle Speech:     1.5434\n",
            "  Loss_Identity Vocal:     2.3140\n",
            "  Loss_Identity Speech:     3.0433\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5881\n",
            "  Loss_adv_vocal:     0.1512\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4050\n",
            "  Loss_Cycle Speech:     1.5540\n",
            "  Loss_Identity Vocal:     2.3442\n",
            "  Loss_Identity Speech:     3.0545\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5882\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3936\n",
            "  Loss_Cycle Speech:     1.5509\n",
            "  Loss_Identity Vocal:     2.3441\n",
            "  Loss_Identity Speech:     3.0855\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.4210\n",
            "  Loss_Cycle Speech:     1.5694\n",
            "  Loss_Identity Vocal:     2.3529\n",
            "  Loss_Identity Speech:     3.0328\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5938\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1508\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.4931\n",
            "  Loss_Cycle Speech:     1.6239\n",
            "  Loss_Identity Vocal:     2.3745\n",
            "  Loss_Identity Speech:     3.0180\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0084\n",
            "  Grad Norm GS:    0.0081\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5930\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1508\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4032\n",
            "  Loss_Cycle Speech:     1.5403\n",
            "  Loss_Identity Vocal:     2.3240\n",
            "  Loss_Identity Speech:     2.9998\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.4088\n",
            "  Loss_Cycle Speech:     1.5511\n",
            "  Loss_Identity Vocal:     2.3525\n",
            "  Loss_Identity Speech:     3.0194\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1273\n",
            "  Loss_Cycle Vocal:     1.3992\n",
            "  Loss_Cycle Speech:     1.5428\n",
            "  Loss_Identity Vocal:     2.3370\n",
            "  Loss_Identity Speech:     3.0473\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.4411\n",
            "  Loss_Cycle Speech:     1.5638\n",
            "  Loss_Identity Vocal:     2.3636\n",
            "  Loss_Identity Speech:     3.0152\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5876\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4285\n",
            "  Loss_Cycle Speech:     1.5605\n",
            "  Loss_Identity Vocal:     2.3824\n",
            "  Loss_Identity Speech:     3.0250\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1511\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.3673\n",
            "  Loss_Cycle Speech:     1.5238\n",
            "  Loss_Identity Vocal:     2.3248\n",
            "  Loss_Identity Speech:     3.0630\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0067\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5881\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3884\n",
            "  Loss_Cycle Speech:     1.5589\n",
            "  Loss_Identity Vocal:     2.3180\n",
            "  Loss_Identity Speech:     3.0929\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5886\n",
            "  Loss_adv_vocal:     0.1508\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4154\n",
            "  Loss_Cycle Speech:     1.5691\n",
            "  Loss_Identity Vocal:     2.3519\n",
            "  Loss_Identity Speech:     3.0425\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5889\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3933\n",
            "  Loss_Cycle Speech:     1.5439\n",
            "  Loss_Identity Vocal:     2.3433\n",
            "  Loss_Identity Speech:     3.0300\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5935\n",
            "  Loss_DS:         0.5886\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.4077\n",
            "  Loss_Cycle Speech:     1.5388\n",
            "  Loss_Identity Vocal:     2.3213\n",
            "  Loss_Identity Speech:     3.0047\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5884\n",
            "  Loss_adv_vocal:     0.1510\n",
            "  Loss_adv_speech:     0.1264\n",
            "  Loss_Cycle Vocal:     1.3657\n",
            "  Loss_Cycle Speech:     1.5375\n",
            "  Loss_Identity Vocal:     2.3208\n",
            "  Loss_Identity Speech:     2.9866\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3921\n",
            "  Loss_Cycle Speech:     1.5434\n",
            "  Loss_Identity Vocal:     2.3057\n",
            "  Loss_Identity Speech:     2.9798\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5934\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1509\n",
            "  Loss_adv_speech:     0.1271\n",
            "  Loss_Cycle Vocal:     1.5511\n",
            "  Loss_Cycle Speech:     1.7488\n",
            "  Loss_Identity Vocal:     3.6508\n",
            "  Loss_Identity Speech:     3.0925\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0082\n",
            "  Grad Norm GS:    0.0079\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5937\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.4991\n",
            "  Loss_Cycle Speech:     1.6047\n",
            "  Loss_Identity Vocal:     5.6606\n",
            "  Loss_Identity Speech:     3.0880\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0066\n",
            "  Grad Norm GS:    0.0064\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5931\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1512\n",
            "  Loss_adv_speech:     0.1272\n",
            "  Loss_Cycle Vocal:     1.4229\n",
            "  Loss_Cycle Speech:     1.5624\n",
            "  Loss_Identity Vocal:     4.0527\n",
            "  Loss_Identity Speech:     3.2047\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5938\n",
            "  Loss_DS:         0.5862\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.4104\n",
            "  Loss_Cycle Speech:     1.5598\n",
            "  Loss_Identity Vocal:     3.1900\n",
            "  Loss_Identity Speech:     4.7664\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5872\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1276\n",
            "  Loss_Cycle Vocal:     1.4112\n",
            "  Loss_Cycle Speech:     1.5598\n",
            "  Loss_Identity Vocal:     2.8942\n",
            "  Loss_Identity Speech:     3.6401\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    audio_files = cycle_train_rand_accomp(\n",
        "        generator_vocal,\n",
        "        generator_speech,\n",
        "        discriminator_vocal,\n",
        "        discriminator_speech,\n",
        "        optimizer_DV,\n",
        "        optimizer_DS,\n",
        "        optimizer_GV,\n",
        "        optimizer_GS,\n",
        "        acc_voc_loader,\n",
        "        speech_loader,\n",
        "        acc_loader,\n",
        "        l1_loss,\n",
        "        mse_loss,\n",
        "        train_parameters[\"lambda_l1\"],\n",
        "        train_parameters[\"lambda_cycle\"],\n",
        "        train_parameters[\"lambda_identity\"],\n",
        "        bce_loss,\n",
        "        device,\n",
        "        num_epochs          = train_parameters[\"num_epochs\"],\n",
        "        virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "        log_dir             = train_parameters[\"log_dir\"],\n",
        "        clip_length = train_parameters[\"clip_length\"],\n",
        "        input_size_generators = train_parameters[\"input_size_generators\"],\n",
        "        batch_size = train_parameters[\"batch_size\"]\n",
        "    )\n",
        "    now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    log_dir = \"runs/\" + \"cycleGAN_experiment_\" + now\n",
        "    # assert False\n",
        "    path = \"models/\"\n",
        "    torch.save(generator_vocal.state_dict(), path + \"generator_state_vocal_dict_\" + now + \".pt\")\n",
        "    torch.save(generator_speech.state_dict(), path + \"generator_state_speech_dict_\" + now + \".pt\")\n",
        "    torch.save(discriminator_speech.state_dict(), path + \"discriminator_speech_state_dict_\" + now + \".pt\")\n",
        "    torch.save(discriminator_vocal.state_dict(), path + \"discriminator_vocal_state_dict_\" + now + \".pt\")\n",
        "\n",
        "    # ------------- package everything to save -------------\n",
        "    export_dict = {\n",
        "        \"train_parameters\": train_parameters,\n",
        "        \"model_config_gen_speech\": model_config_gen_speech,      # Wave‑U‑Net (speech+accomp → vocal)\n",
        "        \"model_config_gen_vocal\": model_config_gen_vocal,    # Wave‑U‑Net (vocal → speech)\n",
        "    }\n",
        "    import json\n",
        "\n",
        "    # (optional) ensure JSON‑serialisable: convert tuples → lists\n",
        "    def _convert(obj):\n",
        "        if isinstance(obj, tuple):\n",
        "            return list(obj)\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: _convert(v) for k, v in obj.items()}\n",
        "        if isinstance(obj, list):\n",
        "            return [_convert(x) for x in obj]\n",
        "        return obj\n",
        "\n",
        "    export_dict = _convert(export_dict)\n",
        "\n",
        "    with open(f\"{path}/training_record_{now}.json\", \"w\") as fp:\n",
        "        json.dump(export_dict, fp, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E400uDkrrStq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1274\n",
            "  Loss_Cycle Vocal:     1.4000\n",
            "  Loss_Cycle Speech:     1.5400\n",
            "  Loss_Identity Vocal:     2.7559\n",
            "  Loss_Identity Speech:     3.3922\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5868\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3859\n",
            "  Loss_Cycle Speech:     1.5357\n",
            "  Loss_Identity Vocal:     2.6469\n",
            "  Loss_Identity Speech:     3.2554\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4013\n",
            "  Loss_Cycle Speech:     1.5437\n",
            "  Loss_Identity Vocal:     2.5942\n",
            "  Loss_Identity Speech:     3.1783\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5888\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3666\n",
            "  Loss_Cycle Speech:     1.5382\n",
            "  Loss_Identity Vocal:     2.5268\n",
            "  Loss_Identity Speech:     3.1693\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3847\n",
            "  Loss_Cycle Speech:     1.5501\n",
            "  Loss_Identity Vocal:     2.4967\n",
            "  Loss_Identity Speech:     3.1304\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3798\n",
            "  Loss_Cycle Speech:     1.5326\n",
            "  Loss_Identity Vocal:     2.4650\n",
            "  Loss_Identity Speech:     3.0571\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5941\n",
            "  Loss_DS:         0.5877\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3547\n",
            "  Loss_Cycle Speech:     1.5010\n",
            "  Loss_Identity Vocal:     2.4255\n",
            "  Loss_Identity Speech:     3.0406\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5881\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3660\n",
            "  Loss_Cycle Speech:     1.5017\n",
            "  Loss_Identity Vocal:     2.4172\n",
            "  Loss_Identity Speech:     3.0177\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5882\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3718\n",
            "  Loss_Cycle Speech:     1.5153\n",
            "  Loss_Identity Vocal:     2.4107\n",
            "  Loss_Identity Speech:     3.0017\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5878\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3819\n",
            "  Loss_Cycle Speech:     1.5282\n",
            "  Loss_Identity Vocal:     2.4114\n",
            "  Loss_Identity Speech:     3.0164\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 11/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5875\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.4066\n",
            "  Loss_Cycle Speech:     1.5447\n",
            "  Loss_Identity Vocal:     2.4274\n",
            "  Loss_Identity Speech:     3.0435\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 12/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3721\n",
            "  Loss_Cycle Speech:     1.5260\n",
            "  Loss_Identity Vocal:     2.4118\n",
            "  Loss_Identity Speech:     3.0195\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 13/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3752\n",
            "  Loss_Cycle Speech:     1.5039\n",
            "  Loss_Identity Vocal:     2.3958\n",
            "  Loss_Identity Speech:     2.9875\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 14/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5881\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3199\n",
            "  Loss_Cycle Speech:     1.4785\n",
            "  Loss_Identity Vocal:     2.3705\n",
            "  Loss_Identity Speech:     3.0034\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0063\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 15/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Metrics:\n",
            "  Loss_DV:         0.5933\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3571\n",
            "  Loss_Cycle Speech:     1.5050\n",
            "  Loss_Identity Vocal:     2.3672\n",
            "  Loss_Identity Speech:     3.0171\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 16/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5888\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.4000\n",
            "  Loss_Cycle Speech:     1.5391\n",
            "  Loss_Identity Vocal:     2.3799\n",
            "  Loss_Identity Speech:     3.0391\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 17/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3717\n",
            "  Loss_Cycle Speech:     1.5136\n",
            "  Loss_Identity Vocal:     2.3639\n",
            "  Loss_Identity Speech:     2.9769\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 18/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5874\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3831\n",
            "  Loss_Cycle Speech:     1.5332\n",
            "  Loss_Identity Vocal:     2.3757\n",
            "  Loss_Identity Speech:     2.9881\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 19/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5873\n",
            "  Loss_adv_vocal:     0.1507\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3772\n",
            "  Loss_Cycle Speech:     1.5368\n",
            "  Loss_Identity Vocal:     2.3698\n",
            "  Loss_Identity Speech:     3.0080\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 20/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:10,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3863\n",
            "  Loss_Cycle Speech:     1.5282\n",
            "  Loss_Identity Vocal:     2.3777\n",
            "  Loss_Identity Speech:     3.0255\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 21/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1502\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3807\n",
            "  Loss_Cycle Speech:     1.5322\n",
            "  Loss_Identity Vocal:     2.3811\n",
            "  Loss_Identity Speech:     2.9921\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 22/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Metrics:\n",
            "  Loss_DV:         0.5951\n",
            "  Loss_DS:         0.5887\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.3810\n",
            "  Loss_Cycle Speech:     1.5345\n",
            "  Loss_Identity Vocal:     2.3551\n",
            "  Loss_Identity Speech:     2.9763\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 23/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Metrics:\n",
            "  Loss_DV:         0.5940\n",
            "  Loss_DS:         0.5879\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3462\n",
            "  Loss_Cycle Speech:     1.5105\n",
            "  Loss_Identity Vocal:     2.3241\n",
            "  Loss_Identity Speech:     3.1547\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 24/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5880\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3660\n",
            "  Loss_Cycle Speech:     1.5130\n",
            "  Loss_Identity Vocal:     2.3508\n",
            "  Loss_Identity Speech:     2.9993\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0071\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 25/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5877\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3750\n",
            "  Loss_Cycle Speech:     1.5255\n",
            "  Loss_Identity Vocal:     2.3284\n",
            "  Loss_Identity Speech:     2.9720\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 26/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:09,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5884\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3358\n",
            "  Loss_Cycle Speech:     1.4890\n",
            "  Loss_Identity Vocal:     2.3187\n",
            "  Loss_Identity Speech:     2.9520\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 27/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5900\n",
            "  Loss_adv_vocal:     0.1506\n",
            "  Loss_adv_speech:     0.1264\n",
            "  Loss_Cycle Vocal:     1.3616\n",
            "  Loss_Cycle Speech:     1.5061\n",
            "  Loss_Identity Vocal:     2.3300\n",
            "  Loss_Identity Speech:     3.0127\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 28/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5887\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3924\n",
            "  Loss_Cycle Speech:     1.5209\n",
            "  Loss_Identity Vocal:     2.3258\n",
            "  Loss_Identity Speech:     2.9929\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 29/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Metrics:\n",
            "  Loss_DV:         0.5946\n",
            "  Loss_DS:         0.5887\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3467\n",
            "  Loss_Cycle Speech:     1.4846\n",
            "  Loss_Identity Vocal:     2.2971\n",
            "  Loss_Identity Speech:     2.9724\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 30/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5885\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3839\n",
            "  Loss_Cycle Speech:     1.5174\n",
            "  Loss_Identity Vocal:     2.3034\n",
            "  Loss_Identity Speech:     2.9572\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0078\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 31/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5882\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3161\n",
            "  Loss_Cycle Speech:     1.4780\n",
            "  Loss_Identity Vocal:     2.2732\n",
            "  Loss_Identity Speech:     2.9202\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0068\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 32/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3092\n",
            "  Loss_Cycle Speech:     1.4736\n",
            "  Loss_Identity Vocal:     2.2911\n",
            "  Loss_Identity Speech:     2.9097\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0063\n",
            "  Grad Norm GS:    0.0060\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 33/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1502\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3454\n",
            "  Loss_Cycle Speech:     1.4952\n",
            "  Loss_Identity Vocal:     2.2632\n",
            "  Loss_Identity Speech:     2.9277\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0077\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 34/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5890\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3548\n",
            "  Loss_Cycle Speech:     1.5240\n",
            "  Loss_Identity Vocal:     2.2750\n",
            "  Loss_Identity Speech:     2.9491\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 35/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5888\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3545\n",
            "  Loss_Cycle Speech:     1.5133\n",
            "  Loss_Identity Vocal:     2.3128\n",
            "  Loss_Identity Speech:     2.9736\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 36/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5895\n",
            "  Loss_adv_vocal:     0.1505\n",
            "  Loss_adv_speech:     0.1264\n",
            "  Loss_Cycle Vocal:     1.3367\n",
            "  Loss_Cycle Speech:     1.4789\n",
            "  Loss_Identity Vocal:     2.3146\n",
            "  Loss_Identity Speech:     2.9516\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0064\n",
            "  Grad Norm GS:    0.0061\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 37/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5889\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.3394\n",
            "  Loss_Cycle Speech:     1.4892\n",
            "  Loss_Identity Vocal:     2.2832\n",
            "  Loss_Identity Speech:     2.9268\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 38/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Metrics:\n",
            "  Loss_DV:         0.5939\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3550\n",
            "  Loss_Cycle Speech:     1.4979\n",
            "  Loss_Identity Vocal:     2.3114\n",
            "  Loss_Identity Speech:     2.9273\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 39/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Metrics:\n",
            "  Loss_DV:         0.5945\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1502\n",
            "  Loss_adv_speech:     0.1269\n",
            "  Loss_Cycle Vocal:     1.3536\n",
            "  Loss_Cycle Speech:     1.4959\n",
            "  Loss_Identity Vocal:     2.2945\n",
            "  Loss_Identity Speech:     2.9421\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 40/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Metrics:\n",
            "  Loss_DV:         0.5952\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1264\n",
            "  Loss_Cycle Vocal:     1.3077\n",
            "  Loss_Cycle Speech:     1.4528\n",
            "  Loss_Identity Vocal:     2.2590\n",
            "  Loss_Identity Speech:     2.9232\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0067\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 41/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5888\n",
            "  Loss_adv_vocal:     0.1502\n",
            "  Loss_adv_speech:     0.1267\n",
            "  Loss_Cycle Vocal:     1.3437\n",
            "  Loss_Cycle Speech:     1.4899\n",
            "  Loss_Identity Vocal:     2.2633\n",
            "  Loss_Identity Speech:     2.9296\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 42/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5885\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3601\n",
            "  Loss_Cycle Speech:     1.5127\n",
            "  Loss_Identity Vocal:     2.2797\n",
            "  Loss_Identity Speech:     2.9302\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0080\n",
            "  Grad Norm GS:    0.0076\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 43/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:11,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5890\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1268\n",
            "  Loss_Cycle Vocal:     1.3685\n",
            "  Loss_Cycle Speech:     1.5118\n",
            "  Loss_Identity Vocal:     2.2748\n",
            "  Loss_Identity Speech:     2.9274\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 44/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3532\n",
            "  Loss_Cycle Speech:     1.4936\n",
            "  Loss_Identity Vocal:     2.2774\n",
            "  Loss_Identity Speech:     2.9289\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 45/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5888\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3081\n",
            "  Loss_Cycle Speech:     1.4653\n",
            "  Loss_Identity Vocal:     2.2622\n",
            "  Loss_Identity Speech:     2.8994\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0073\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 46/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5893\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3067\n",
            "  Loss_Cycle Speech:     1.4699\n",
            "  Loss_Identity Vocal:     2.2455\n",
            "  Loss_Identity Speech:     3.1022\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 47/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Metrics:\n",
            "  Loss_DV:         0.5943\n",
            "  Loss_DS:         0.5891\n",
            "  Loss_adv_vocal:     0.1503\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.3217\n",
            "  Loss_Cycle Speech:     1.4666\n",
            "  Loss_Identity Vocal:     2.2464\n",
            "  Loss_Identity Speech:     2.9409\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 48/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Metrics:\n",
            "  Loss_DV:         0.5951\n",
            "  Loss_DS:         0.5892\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1262\n",
            "  Loss_Cycle Vocal:     1.3031\n",
            "  Loss_Cycle Speech:     1.4515\n",
            "  Loss_Identity Vocal:     2.2616\n",
            "  Loss_Identity Speech:     2.9284\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 49/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5891\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3254\n",
            "  Loss_Cycle Speech:     1.4690\n",
            "  Loss_Identity Vocal:     2.2676\n",
            "  Loss_Identity Speech:     2.9153\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0070\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 50/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Metrics:\n",
            "  Loss_DV:         0.5953\n",
            "  Loss_DS:         0.5894\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1270\n",
            "  Loss_Cycle Vocal:     1.3264\n",
            "  Loss_Cycle Speech:     1.4724\n",
            "  Loss_Identity Vocal:     2.2596\n",
            "  Loss_Identity Speech:     2.8932\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0069\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 1/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5882\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.3309\n",
            "  Loss_Cycle Speech:     1.4686\n",
            "  Loss_Identity Vocal:     2.2617\n",
            "  Loss_Identity Speech:     2.8847\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0074\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 2/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Metrics:\n",
            "  Loss_DV:         0.5944\n",
            "  Loss_DS:         0.5889\n",
            "  Loss_adv_vocal:     0.1502\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.2965\n",
            "  Loss_Cycle Speech:     1.4565\n",
            "  Loss_Identity Vocal:     2.2496\n",
            "  Loss_Identity Speech:     2.9186\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0072\n",
            "  Grad Norm GS:    0.0070\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 3/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Metrics:\n",
            "  Loss_DV:         0.5942\n",
            "  Loss_DS:         0.5890\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.1266\n",
            "  Loss_Cycle Vocal:     1.3260\n",
            "  Loss_Cycle Speech:     1.4894\n",
            "  Loss_Identity Vocal:     2.2520\n",
            "  Loss_Identity Speech:     2.9142\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0073\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 4/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Metrics:\n",
            "  Loss_DV:         0.5949\n",
            "  Loss_DS:         0.5883\n",
            "  Loss_adv_vocal:     0.1500\n",
            "  Loss_adv_speech:     0.1262\n",
            "  Loss_Cycle Vocal:     1.3413\n",
            "  Loss_Cycle Speech:     1.5000\n",
            "  Loss_Identity Vocal:     2.2791\n",
            "  Loss_Identity Speech:     2.9177\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0076\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 5/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Metrics:\n",
            "  Loss_DV:         0.5948\n",
            "  Loss_DS:         0.5890\n",
            "  Loss_adv_vocal:     0.1504\n",
            "  Loss_adv_speech:     0.1263\n",
            "  Loss_Cycle Vocal:     1.3447\n",
            "  Loss_Cycle Speech:     1.4946\n",
            "  Loss_Identity Vocal:     2.2682\n",
            "  Loss_Identity Speech:     2.9309\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0078\n",
            "  Grad Norm GS:    0.0075\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 6/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Metrics:\n",
            "  Loss_DV:         0.5947\n",
            "  Loss_DS:         0.5894\n",
            "  Loss_adv_vocal:     0.1501\n",
            "  Loss_adv_speech:     0.1264\n",
            "  Loss_Cycle Vocal:     1.3418\n",
            "  Loss_Cycle Speech:     1.4891\n",
            "  Loss_Identity Vocal:     2.2745\n",
            "  Loss_Identity Speech:     2.9171\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0077\n",
            "  Grad Norm GS:    0.0074\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 7/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Metrics:\n",
            "  Loss_DV:         0.5956\n",
            "  Loss_DS:         0.5893\n",
            "  Loss_adv_vocal:     0.1498\n",
            "  Loss_adv_speech:     0.1262\n",
            "  Loss_Cycle Vocal:     1.3335\n",
            "  Loss_Cycle Speech:     1.4685\n",
            "  Loss_Identity Vocal:     2.2647\n",
            "  Loss_Identity Speech:     2.9041\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0069\n",
            "  Grad Norm GS:    0.0066\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 8/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Metrics:\n",
            "  Loss_DV:         0.5950\n",
            "  Loss_DS:         0.5889\n",
            "  Loss_adv_vocal:     0.1498\n",
            "  Loss_adv_speech:     0.1265\n",
            "  Loss_Cycle Vocal:     1.3091\n",
            "  Loss_Cycle Speech:     1.4572\n",
            "  Loss_Identity Vocal:     2.2360\n",
            "  Loss_Identity Speech:     2.8848\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0071\n",
            "  Grad Norm GS:    0.0068\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 9/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 65it [01:12,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Metrics:\n",
            "  Loss_DV:         0.5959\n",
            "  Loss_DS:         0.5894\n",
            "  Loss_adv_vocal:     0.1495\n",
            "  Loss_adv_speech:     0.1262\n",
            "  Loss_Cycle Vocal:     1.3310\n",
            "  Loss_Cycle Speech:     1.4759\n",
            "  Loss_Identity Vocal:     2.2384\n",
            "  Loss_Identity Speech:     2.8916\n",
            "  Grad Norm DV:    0.0000\n",
            "  Grad Norm DS:    0.0000\n",
            "  Grad Norm GV:    0.0075\n",
            "  Grad Norm GS:    0.0072\n",
            "  num_DV_updates:    0.0000\n",
            "  num_DS_updates:    0.0000\n",
            "\n",
            "=== Epoch 10/50 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Batches: 59it [01:05,  1.14s/it]"
          ]
        }
      ],
      "source": [
        "for _ in range(4):\n",
        "    audio_files = cycle_train_rand_accomp(\n",
        "        generator_vocal,\n",
        "        generator_speech,\n",
        "        discriminator_vocal,\n",
        "        discriminator_speech,\n",
        "        optimizer_DV,\n",
        "        optimizer_DS,\n",
        "        optimizer_GV,\n",
        "        optimizer_GS,\n",
        "        acc_voc_loader,\n",
        "        speech_loader,\n",
        "        acc_loader,\n",
        "        l1_loss,\n",
        "        mse_loss,\n",
        "        train_parameters[\"lambda_l1\"],\n",
        "        train_parameters[\"lambda_cycle\"],\n",
        "        train_parameters[\"lambda_identity\"],\n",
        "        bce_loss,\n",
        "        device,\n",
        "        num_epochs          = train_parameters[\"num_epochs\"],\n",
        "        virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "        log_dir             = train_parameters[\"log_dir\"],\n",
        "        clip_length = train_parameters[\"clip_length\"],\n",
        "        input_size_generators = train_parameters[\"input_size_generators\"],\n",
        "        batch_size = train_parameters[\"batch_size\"]\n",
        "    )\n",
        "    now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    log_dir = \"runs/\" + \"cycleGAN_experiment_\" + now\n",
        "    # assert False\n",
        "    path = \"models/\"\n",
        "    torch.save(generator_vocal.state_dict(), path + \"generator_state_vocal_dict_\" + now + \".pt\")\n",
        "    torch.save(generator_speech.state_dict(), path + \"generator_state_speech_dict_\" + now + \".pt\")\n",
        "    torch.save(discriminator_speech.state_dict(), path + \"discriminator_speech_state_dict_\" + now + \".pt\")\n",
        "    torch.save(discriminator_vocal.state_dict(), path + \"discriminator_vocal_state_dict_\" + now + \".pt\")\n",
        "\n",
        "    # ------------- package everything to save -------------\n",
        "    export_dict = {\n",
        "        \"train_parameters\": train_parameters,\n",
        "        \"model_config_gen_speech\": model_config_gen_speech,      # Wave‑U‑Net (speech+accomp → vocal)\n",
        "        \"model_config_gen_vocal\": model_config_gen_vocal,    # Wave‑U‑Net (vocal → speech)\n",
        "    }\n",
        "    import json\n",
        "\n",
        "    # (optional) ensure JSON‑serialisable: convert tuples → lists\n",
        "    def _convert(obj):\n",
        "        if isinstance(obj, tuple):\n",
        "            return list(obj)\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: _convert(v) for k, v in obj.items()}\n",
        "        if isinstance(obj, list):\n",
        "            return [_convert(x) for x in obj]\n",
        "        return obj\n",
        "\n",
        "    export_dict = _convert(export_dict)\n",
        "\n",
        "    with open(f\"{path}/training_record_{now}.json\", \"w\") as fp:\n",
        "        json.dump(export_dict, fp, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIh9jZMNx9A6",
        "outputId": "924b8201-e36f-40e9-bb87-0e71948dbcc9"
      },
      "outputs": [],
      "source": [
        "# state_time = \"20250424-0024\"\n",
        "# model_dir  = \"models\"\n",
        "\n",
        "# # ----  load the raw weight dictionaries ----\n",
        "# disc_state = torch.load(f\"{model_dir}/discriminator_state_dict_{state_time}.pt\", map_location=device)\n",
        "# gen_state  = torch.load(f\"{model_dir}/generator_state_dict_{state_time}.pt\",         map_location=device)\n",
        "# gen2_state = torch.load(f\"{model_dir}/generator_2_state_dict_{state_time}.pt\",       map_location=device)\n",
        "\n",
        "# # ----   rebuild the model objects ----\n",
        "# discriminator = TsaiMiniRocketDiscriminator().to(device)\n",
        "# generator     = Waveunet(**model_config_gen_vocal).to(device)\n",
        "# generator_2   = Waveunet(**model_config_gen_).to(device)\n",
        "\n",
        "# # ---- load the weights into those models ----\n",
        "# discriminator.load_state_dict(disc_state)\n",
        "# generator.load_state_dict(gen_state)\n",
        "# generator_2.load_state_dict(gen2_state)\n",
        "\n",
        "# state_time = \"20250424-031428\"\n",
        "# model_dir  = \"models\"# ----  load the raw weight dictionaries ----\n",
        "# disc_speech_state = torch.load(f\"{model_dir}/discriminator_speech_state_dict_{state_time}.pt\", map_location=device)\n",
        "# disc_vocal_state = torch.load(f\"{model_dir}/discriminator_vocal_state_dict_{state_time}.pt\", map_location=device)\n",
        "# gen_speech_state  = torch.load(f\"{model_dir}/generator_state_speech_dict_{state_time}.pt\",         map_location=device)\n",
        "# gen_vocal_state = torch.load(f\"{model_dir}/generator_state_vocal_dict_{state_time}.pt\",       map_location=device)# ----   rebuild the model objects ----\n",
        "# discriminator_vocal = TsaiMiniRocketDiscriminator().to(device)\n",
        "# discriminator_speech = TsaiMiniRocketDiscriminator(freq_bins = 128,\n",
        "#                                                    hidden_dim = 512,\n",
        "#                                                    accompaniment = False).to(device)\n",
        "# generator_vocal     = Waveunet(**model_config_gen_vocal).to(device)\n",
        "# generator_speech   = Waveunet(**model_config_gen_speech).to(device)# ---- load the weights into those models ----\n",
        "# discriminator_speech.load_state_dict(disc_speech_state)\n",
        "# discriminator_vocal.load_state_dict(disc_vocal_state)\n",
        "# generator_speech.load_state_dict(gen_speech_state)\n",
        "# generator_vocal.load_state_dict(gen_vocal_state)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YX7YAzA9NGrn"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/librispeech_longClip_test.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m librispeech_test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/librispeech_longClip_test.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m musdb_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/musdb_noOverlap_test.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m acc_data_test \u001b[38;5;241m=\u001b[39m AccompanimentVocalData(musdb_test)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/librispeech_longClip_test.pt'"
          ]
        }
      ],
      "source": [
        "librispeech_test = torch.load(\"/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/librispeech_longClip_test.pt\", weights_only = False)\n",
        "musdb_test = torch.load(\"/content/drive/MyDrive/git_projects/spring_2025_dl_audio_project_data/musdb_noOverlap_test.pt\", weights_only = False)\n",
        "acc_data_test = AccompanimentVocalData(musdb_test)\n",
        "speech_data_test = SpeechData(librispeech_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuCNJJvzNxK9"
      },
      "outputs": [],
      "source": [
        "def mel_to_audio(spec, sr = 44100):\n",
        "  return librosa.feature.inverse.mel_to_audio(M = librosa.db_to_power(spec.detach().cpu().numpy()), sr = sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d4Mi7eWNhd-"
      },
      "outputs": [],
      "source": [
        "test_acc = acc_data_test[115][\"acc_pad\"].float().to(device)\n",
        "test_voc = acc_data_test[115][\"voc_pad\"].float().to(device)\n",
        "test_speech = librispeech_test[128][0][:,0:289].float().to(device)\n",
        "\n",
        "\n",
        "sr = 44100\n",
        "test_acc_np = test_acc.detach().cpu().numpy()\n",
        "test_voc_np = test_voc.detach().cpu().numpy()\n",
        "test_speech_np = test_speech.detach().cpu().numpy()\n",
        "\n",
        "acc = mel_to_audio(test_acc)\n",
        "voc = mel_to_audio(test_voc)\n",
        "speech = mel_to_audio(test_speech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "m9VtuMkSN3CG",
        "outputId": "1ec69f67-7b24-47de-b88a-2e78a65fc29e"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "gen_vocal = generator_vocal(torch.cat([torch.unsqueeze(test_speech, 0), torch.unsqueeze(test_acc, 0)], dim=1))[\"vocal\"]\n",
        "gen_vocal_audio = mel_to_audio(gen_vocal)[0]\n",
        "\n",
        "\n",
        "Audio(data = speech, rate = sr)\n",
        "#Audio(data=gen_vocal_audio*100, rate=sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "Bw-1jbv6TKIi",
        "outputId": "e42e7586-a7ba-4750-c717-b2cc42482768"
      },
      "outputs": [],
      "source": [
        "Audio(data=voc, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "WpOQ9gpVTgqe",
        "outputId": "d8301ee9-8651-4f63-ede4-bc3eba09ebc1"
      },
      "outputs": [],
      "source": [
        "generated_vocal = generator_vocal(torch.cat([torch.unsqueeze(test_speech, 0), torch.unsqueeze(test_acc, 0)], dim=1))[\"vocal\"]\n",
        "generated_vocal_pad = transform_for_gen_2(generated_vocal)\n",
        "rec_speech = generator_speech(generated_vocal_pad)[\"speech\"]\n",
        "rec_speech_audio = mel_to_audio(rec_speech)[0]\n",
        "\n",
        "Audio(data = rec_speech_audio, rate = sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "Qazfw6gIUFBw",
        "outputId": "29311f6c-243b-47a9-8aaa-8c18df279e78"
      },
      "outputs": [],
      "source": [
        "generated_speech = transform_for_gen_2(generator_speech(torch.unsqueeze(test_voc, 0))[\"speech\"])\n",
        "\n",
        "reconstructed_vocal = generator_vocal(torch.cat([generated_speech, torch.unsqueeze(test_acc, 0)], dim=1))[\"vocal\"]\n",
        "rec_vocal_audio = mel_to_audio(reconstructed_vocal)\n",
        "\n",
        "gen_speech_audio = mel_to_audio(generated_speech)\n",
        "\n",
        "Audio(data = gen_speech_audio, rate = sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "leif4bcWULHW",
        "outputId": "86e065a3-bcdb-4e7c-f5d2-2382de38c2dd"
      },
      "outputs": [],
      "source": [
        "Audio(data = voc, rate = sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfH9exL5pYjM"
      },
      "outputs": [],
      "source": [
        "# # display the converted audios\n",
        "# print(audio_files)\n",
        "# for audio in audio_files:\n",
        "#     print(audio)\n",
        "#     display_audio(audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-zG21ZKfArk",
        "outputId": "086a2ebb-5906-4280-e91f-f3cec3294a47"
      },
      "outputs": [],
      "source": [
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# # Start training.\n",
        "# train(\n",
        "#     generator,\n",
        "#     generator_2,\n",
        "#     discriminator,\n",
        "#     optimizer_D,\n",
        "#     optimizer_G,\n",
        "#     optimizer_G2,\n",
        "#     accompaniment_loader,\n",
        "#     vocal_loader,\n",
        "#     speech_loader,\n",
        "#     l1_loss,\n",
        "#     train_parameters[\"lambda_l1\"],\n",
        "#     train_parameters[\"lambda_cycle\"],\n",
        "#     adversarial_loss,\n",
        "#     device,\n",
        "#     num_epochs          = 50, #train_parameters[\"num_epochs\"],\n",
        "#     virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "#     log_dir             = train_parameters[\"log_dir\"],\n",
        "# )\n",
        "print(now)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWffnPNExV3-"
      },
      "source": [
        "## Save the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6dDyxJmxV3-"
      },
      "outputs": [],
      "source": [
        "# assert False\n",
        "path = \"models/\"\n",
        "torch.save(generator_vocal.state_dict(), path + \"generator_state_vocal_dict_\" + now + \".pt\")\n",
        "torch.save(generator_speech.state_dict(), path + \"generator_state_speech_dict_\" + now + \".pt\")\n",
        "torch.save(discriminator_speech.state_dict(), path + \"discriminator_speech_state_dict_\" + now + \".pt\")\n",
        "torch.save(discriminator_vocal.state_dict(), path + \"discriminator_vocal_state_dict_\" + now + \".pt\")\n",
        "\n",
        "# ------------- package everything to save -------------\n",
        "export_dict = {\n",
        "    \"train_parameters\": train_parameters,\n",
        "    \"model_config_gen_speech\": model_config_gen_speech,      # Wave‑U‑Net (speech+accomp → vocal)\n",
        "    \"model_config_gen_vocal\": model_config_gen_vocal,    # Wave‑U‑Net (vocal → speech)\n",
        "}\n",
        "import json\n",
        "\n",
        "# (optional) ensure JSON‑serialisable: convert tuples → lists\n",
        "def _convert(obj):\n",
        "    if isinstance(obj, tuple):\n",
        "        return list(obj)\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: _convert(v) for k, v in obj.items()}\n",
        "    if isinstance(obj, list):\n",
        "        return [_convert(x) for x in obj]\n",
        "    return obj\n",
        "\n",
        "export_dict = _convert(export_dict)\n",
        "\n",
        "with open(f\"{path}/training_record_{now}.json\", \"w\") as fp:\n",
        "    json.dump(export_dict, fp, indent=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJfpzB2GfAr2"
      },
      "outputs": [],
      "source": [
        "# now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# log_dir = \"runs/\" + \"cycleGAN_experiment_\" + now\n",
        "\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# # Start training.\n",
        "# train(\n",
        "#     generator_vocal,\n",
        "#     generator_speech,\n",
        "#     discriminator,\n",
        "#     optimizer_D,\n",
        "#     optimizer_G,\n",
        "#     optimizer_G2,\n",
        "#     accompaniment_loader,\n",
        "#     vocal_loader,\n",
        "#     speech_loader,\n",
        "#     l1_loss,\n",
        "#     train_parameters[\"lambda_l1\"],\n",
        "#     train_parameters[\"lambda_cycle\"],\n",
        "#     adversarial_loss,\n",
        "#     device,\n",
        "#     num_epochs          = 50, #train_parameters[\"num_epochs\"],\n",
        "#     virtual_batch_size  = train_parameters[\"virtual_batch_size\"],\n",
        "#     log_dir             = train_parameters[\"log_dir\"],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thUAy9le-XWV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
